Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000.pkl
File:  conv.train2019
Description:  parent_wloaded_teacher_trainingscratch
2021-03-25 18:29:19.151269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-25 18:29:28.424133: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-25 18:29:28.450951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-25 18:29:28.564381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.565558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-25 18:29:28.565958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-25 18:29:28.620189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-25 18:29:28.620382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-25 18:29:28.642657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-25 18:29:28.655609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-25 18:29:28.675956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-25 18:29:28.696494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-25 18:29:28.701241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-25 18:29:28.701474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.702427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.703136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-25 18:29:28.711344: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-25 18:29:28.711525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.712291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-25 18:29:28.712316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-25 18:29:28.712347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-25 18:29:28.712362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-25 18:29:28.712376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-25 18:29:28.712390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-25 18:29:28.712413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-25 18:29:28.712427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-25 18:29:28.712441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-25 18:29:28.712549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.713243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:28.713892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-25 18:29:28.715387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-25 18:29:30.904721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-25 18:29:30.904769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-25 18:29:30.904778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-25 18:29:30.905086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:30.905942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:30.906722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-25 18:29:30.907405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-03-25 18:29:31.478166: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-25 18:29:31.478231: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-25 18:29:31.481564: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-03-25 18:29:31.482067: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-03-25 18:29:31.509721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-03-25 18:29:31.768454: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-25 18:29:31.771233: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2019.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___03_1757___all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000___parent_wloaded_teacher_trainingscratch___2019/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 2, 'SR': 8000, 'BATCH_SIZE': 32, 'LR': 0.001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.5, 'patience': 3, 'min_lr': 1e-05}
Early Stopping Patience and Delta: 8, 1.0%
-----------------------
Size of training set: 13945
Size of validation set: 3486
Initializing weights...
weights = {0: 0.6399045521292217, 1: 1.2145345596432553, 2: 1.1234209847898944, 3: 1.3816582117945466}
Model: "teacher"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 3) 12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 3) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________2021-03-25 18:29:33.581695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-03-25 18:29:33.587117: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-03-25 18:29:36.427363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-25 18:29:38.604402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-25 18:29:38.648641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8

global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            1026        global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,201,262
Trainable params: 6,159,752
Non-trainable params: 41,510
__________________________________________________________________________________________________
Model: "student"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 1250, 3) 12          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 1250, 8) 32          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 128, 1250, 8) 32          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 1250, 3) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 128, 1250, 8) 584         conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 1250, 8) 1608        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 1250, 8) 32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 1250, 24 0           conv2d_6[0][0]                   
                                                                 conv2d_8[0][0]                   
                                                                 conv2d_9[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 64, 625, 24)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 625, 24)  96          average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 625, 16)  400         batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 64, 625, 16)  400         batch_normalization_7[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 625, 24)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 625, 16)  2320        conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 625, 16)  6416        conv2d_12[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 625, 16)  400         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 625, 48)  0           conv2d_11[0][0]                  
                                                                 conv2d_13[0][0]                  
                                                                 conv2d_14[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 32, 313, 48)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 313, 48)  192         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 313, 32)  1568        batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 313, 32)  1568        batch_normalization_8[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 313, 48)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 313, 32)  9248        conv2d_15[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 313, 32)  25632       conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 313, 32)  1568        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 313, 96)  0           conv2d_16[0][0]                  
                                                                 conv2d_18[0][0]                  
                                                                 conv2d_19[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 16, 157, 96)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 157, 96)  384         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 96)           0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            194         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 52,686
Trainable params: 52,344
Non-trainable params: 342
__________________________________________________________________________________________________
Epoch 1/40
436/436 - 402s - calc_accuracy: 0.5249 - student_loss: 0.5789 - distillation_loss: -6.2684e-03 - val_calc_accuracy: 0.2593 - val_student_loss: 0.7961
Epoch 2/40
436/436 - 379s - calc_accuracy: 0.6508 - student_loss: 0.4761 - distillation_loss: -6.6607e-03 - val_calc_accuracy: 0.5467 - val_student_loss: 0.4995
Epoch 3/40
436/436 - 386s - calc_accuracy: 0.6832 - student_loss: 0.4395 - distillation_loss: -7.0994e-03 - val_calc_accuracy: 0.7278 - val_student_loss: 0.2771
Epoch 4/40
436/436 - 383s - calc_accuracy: 0.7026 - student_loss: 0.4431 - distillation_loss: -9.4692e-03 - val_calc_accuracy: 0.6911 - val_student_loss: 0.4068
Epoch 5/40
436/436 - 383s - calc_accuracy: 0.7084 - student_loss: 0.3634 - distillation_loss: -6.8988e-03 - val_calc_accuracy: 0.3838 - val_student_loss: 0.7929
Epoch 6/40
436/436 - 389s - calc_accuracy: 0.7170 - student_loss: 0.3916 - distillation_loss: -3.6747e-03 - val_calc_accuracy: 0.4590 - val_student_loss: 0.8233
Epoch 7/40
436/436 - 387s - calc_accuracy: 0.7259 - student_loss: 0.2949 - distillation_loss: -2.0924e-03 - val_calc_accuracy: 0.7407 - val_student_loss: 0.3740
Epoch 8/40
436/436 - 426s - calc_accuracy: 0.7329 - student_loss: 0.3760 - distillation_loss: -5.9700e-03 - val_calc_accuracy: 0.6744 - val_student_loss: 0.3217
Epoch 9/40
436/436 - 404s - calc_accuracy: 0.7412 - student_loss: 0.2645 - distillation_loss: -5.4889e-03 - val_calc_accuracy: 0.6290 - val_student_loss: 0.4921
Epoch 10/40
436/436 - 419s - calc_accuracy: 0.7456 - student_loss: 0.3902 - distillation_loss: -1.0204e-02 - val_calc_accuracy: 0.6371 - val_student_loss: 0.5138
Epoch 11/40
436/436 - 384s - calc_accuracy: 0.7501 - student_loss: 0.3586 - distillation_loss: -4.3617e-03 - val_calc_accuracy: 0.7346 - val_student_loss: 0.3979
Epoch 12/40
436/436 - 387s - calc_accuracy: 0.7538 - student_loss: 0.2782 - distillation_loss: 0.0021 - val_calc_accuracy: 0.7216 - val_student_loss: 0.2470
Epoch 13/40
436/436 - 380s - calc_accuracy: 0.7557 - student_loss: 0.3111 - distillation_loss: -3.9681e-03 - val_calc_accuracy: 0.5210 - val_student_loss: 0.4877
Epoch 14/40
436/436 - 385s - calc_accuracy: 0.7575 - student_loss: 0.2986 - distillation_loss: -4.6023e-04 - val_calc_accuracy: 0.7699 - val_student_loss: 0.3442
Epoch 15/40
436/436 - 385s - calc_accuracy: 0.7638 - student_loss: 0.2547 - distillation_loss: 2.4333e-04 - val_calc_accuracy: 0.6635 - val_student_loss: 0.3882
Epoch 16/40
436/436 - 383s - calc_accuracy: 0.7645 - student_loss: 0.4840 - distillation_loss: -1.0355e-02 - val_calc_accuracy: 0.6864 - val_student_loss: 0.3527
Epoch 17/40
436/436 - 395s - calc_accuracy: 0.7732 - student_loss: 0.3262 - distillation_loss: -2.3263e-03 - val_calc_accuracy: 0.7375 - val_student_loss: 0.3179
Epoch 18/40
436/436 - 384s - calc_accuracy: 0.7713 - student_loss: 0.3319 - distillation_loss: 0.0026 - val_calc_accuracy: 0.7384 - val_student_loss: 0.2923
Epoch 19/40
436/436 - 397s - calc_accuracy: 0.7818 - student_loss: 0.4544 - distillation_loss: -1.4252e-02 - val_calc_accuracy: 0.7776 - val_student_loss: 0.3994
Epoch 20/40
436/436 - 383s - calc_accuracy: 0.7863 - student_loss: 0.2451 - distillation_loss: -6.0425e-03 - val_calc_accuracy: 0.7827 - val_student_loss: 0.3827
Epoch 21/40
436/436 - 395s - calc_accuracy: 0.7894 - student_loss: 0.2701 - distillation_loss: 5.9611e-05 - val_calc_accuracy: 0.7707 - val_student_loss: 0.3779
Epoch 22/40
436/436 - 384s - calc_accuracy: 0.7848 - student_loss: 0.2667 - distillation_loss: -5.8237e-04 - val_calc_accuracy: 0.7835 - val_student_loss: 0.1850
Epoch 23/40
436/436 - 389s - calc_accuracy: 0.7860 - student_loss: 0.3152 - distillation_loss: -8.4935e-03 - val_calc_accuracy: 0.7662 - val_student_loss: 0.5855
Epoch 24/40
436/436 - 382s - calc_accuracy: 0.7969 - student_loss: 0.2184 - distillation_loss: 0.0011 - val_calc_accuracy: 0.7516 - val_student_loss: 0.2797
Epoch 25/40
436/436 - 390s - calc_accuracy: 0.7984 - student_loss: 0.2353 - distillation_loss: -4.9468e-03 - val_calc_accuracy: 0.7272 - val_student_loss: 0.3384
Epoch 26/40
436/436 - 382s - calc_accuracy: 0.8023 - student_loss: 0.2878 - distillation_loss: -3.4254e-03 - val_calc_accuracy: 0.5462 - val_student_loss: 0.5344
Epoch 27/40
436/436 - 384s - calc_accuracy: 0.8025 - student_loss: 0.3121 - distillation_loss: -9.3993e-03 - val_calc_accuracy: 0.7648 - val_student_loss: 0.3073
Epoch 28/40
436/436 - 386s - calc_accuracy: 0.8048 - student_loss: 0.2999 - distillation_loss: -2.5015e-03 - val_calc_accuracy: 0.6793 - val_student_loss: 0.4883
Epoch 29/40
436/436 - 381s - calc_accuracy: 0.8106 - student_loss: 0.2586 - distillation_loss: -2.4522e-03 - val_calc_accuracy: 0.7725 - val_student_loss: 0.2807
Epoch 30/40
436/436 - 390s - calc_accuracy: 0.8151 - student_loss: 0.2053 - distillation_loss: -3.7103e-03 - val_calc_accuracy: 0.7774 - val_student_loss: 0.3553
Epoch 31/40
436/436 - 385s - calc_accuracy: 0.8165 - student_loss: 0.2803 - distillation_loss: -2.7699e-04 - val_calc_accuracy: 0.7088 - val_student_loss: 0.3467
Epoch 32/40
436/436 - 396s - calc_accuracy: 0.8203 - student_loss: 0.3200 - distillation_loss: 0.0011 - val_calc_accuracy: 0.7211 - val_student_loss: 0.4278
Epoch 33/40
436/436 - 383s - calc_accuracy: 0.8187 - student_loss: 0.2815 - distillation_loss: -1.0497e-03 - val_calc_accuracy: 0.6953 - val_student_loss: 0.4021
Epoch 34/40
436/436 - 393s - calc_accuracy: 0.8288 - student_loss: 0.1956 - distillation_loss: -4.2609e-03 - val_calc_accuracy: 0.7702 - val_student_loss: 0.4209
Epoch 35/40
436/436 - 383s - calc_accuracy: 0.8270 - student_loss: 0.1358 - distillation_loss: -4.2514e-03 - val_calc_accuracy: 0.7668 - val_student_loss: 0.3184
Epoch 36/40
436/436 - 390s - calc_accuracy: 0.8321 - student_loss: 0.1987 - distillation_loss: 6.0816e-04 - val_calc_accuracy: 0.6380 - val_student_loss: 0.3909
Epoch 37/40
436/436 - 380s - calc_accuracy: 0.8312 - student_loss: 0.1401 - distillation_loss: -1.3860e-03 - val_calc_accuracy: 0.7265 - val_student_loss: 0.4141
Epoch 38/40
436/436 - 387s - calc_accuracy: 0.8382 - student_loss: 0.2259 - distillation_loss: -8.4058e-04 - val_calc_accuracy: 0.7997 - val_student_loss: 0.3859
Epoch 39/40
436/436 - 386s - calc_accuracy: 0.8380 - student_loss: 0.1428 - distillation_loss: -2.1026e-03 - val_calc_accuracy: 0.7587 - val_student_loss: 0.3518
Epoch 40/40
436/436 - 384s - calc_accuracy: 0.8417 - student_loss: 0.2667 - distillation_loss: -7.0088e-03 - val_calc_accuracy: 0.7831 - val_student_loss: 0.3858
Training student model alone.
Epoch 1/40
436/436 - 391s - loss: 0.5129 - calc_accuracy: 0.5933 - val_loss: 0.5429 - val_calc_accuracy: 0.5907
Epoch 2/40
436/436 - 383s - loss: 0.4204 - calc_accuracy: 0.6828 - val_loss: 0.4920 - val_calc_accuracy: 0.6130
Epoch 3/40
436/436 - 395s - loss: 0.3967 - calc_accuracy: 0.7018 - val_loss: 0.4268 - val_calc_accuracy: 0.6997
Epoch 4/40
436/436 - 383s - loss: 0.3817 - calc_accuracy: 0.7137 - val_loss: 0.4202 - val_calc_accuracy: 0.6622
Epoch 5/40
436/436 - 391s - loss: 0.3685 - calc_accuracy: 0.7273 - val_loss: 0.4176 - val_calc_accuracy: 0.6759
Epoch 6/40
436/436 - 382s - loss: 0.3599 - calc_accuracy: 0.7285 - val_loss: 0.4249 - val_calc_accuracy: 0.6796
Epoch 7/40
436/436 - 390s - loss: 0.3517 - calc_accuracy: 0.7301 - val_loss: 0.4585 - val_calc_accuracy: 0.6463
Epoch 8/40
436/436 - 379s - loss: 0.3481 - calc_accuracy: 0.7382 - val_loss: 0.3483 - val_calc_accuracy: 0.7456
Epoch 9/40
436/436 - 383s - loss: 0.3444 - calc_accuracy: 0.7411 - val_loss: 0.3399 - val_calc_accuracy: 0.7433
Epoch 10/40
436/436 - 374s - loss: 0.3376 - calc_accuracy: 0.7433 - val_loss: 0.3504 - val_calc_accuracy: 0.7493
Epoch 11/40
436/436 - 384s - loss: 0.3334 - calc_accuracy: 0.7499 - val_loss: 0.3391 - val_calc_accuracy: 0.7469
Epoch 12/40
436/436 - 380s - loss: 0.3294 - calc_accuracy: 0.7507 - val_loss: 0.3435 - val_calc_accuracy: 0.7335
Epoch 13/40
436/436 - 380s - loss: 0.3280 - calc_accuracy: 0.7504 - val_loss: 0.3633 - val_calc_accuracy: 0.7065
Epoch 14/40
436/436 - 386s - loss: 0.3247 - calc_accuracy: 0.7526 - val_loss: 0.3271 - val_calc_accuracy: 0.7370
Epoch 15/40
436/436 - 380s - loss: 0.3214 - calc_accuracy: 0.7559 - val_loss: 0.3466 - val_calc_accuracy: 0.7363
Epoch 16/40
436/436 - 379s - loss: 0.3184 - calc_accuracy: 0.7618 - val_loss: 0.3533 - val_calc_accuracy: 0.7395
Epoch 17/40
436/436 - 296s - loss: 0.3143 - calc_accuracy: 0.7613 - val_loss: 0.6509 - val_calc_accuracy: 0.4498
Epoch 18/40
436/436 - 301s - loss: 0.3135 - calc_accuracy: 0.7579 - val_loss: 0.3331 - val_calc_accuracy: 0.7462
Epoch 19/40
436/436 - 302s - loss: 0.3106 - calc_accuracy: 0.7632 - val_loss: 0.3037 - val_calc_accuracy: 0.7614
Epoch 20/40
436/436 - 302s - loss: 0.3058 - calc_accuracy: 0.7655 - val_loss: 0.4667 - val_calc_accuracy: 0.5776
Epoch 21/40
436/436 - 302s - loss: 0.3058 - calc_accuracy: 0.7652 - val_loss: 0.3312 - val_calc_accuracy: 0.7441
Epoch 22/40
436/436 - 303s - loss: 0.3021 - calc_accuracy: 0.7687 - val_loss: 0.3021 - val_calc_accuracy: 0.7639
Epoch 23/40
436/436 - 300s - loss: 0.2986 - calc_accuracy: 0.7740 - val_loss: 0.3410 - val_calc_accuracy: 0.7263
Epoch 24/40
436/436 - 303s - loss: 0.2964 - calc_accuracy: 0.7736 - val_loss: 0.3818 - val_calc_accuracy: 0.7051
Epoch 25/40
436/436 - 302s - loss: 0.2938 - calc_accuracy: 0.7760 - val_loss: 0.3099 - val_calc_accuracy: 0.7499
Epoch 26/40
436/436 - 301s - loss: 0.2924 - calc_accuracy: 0.7790 - val_loss: 0.4325 - val_calc_accuracy: 0.6991
Epoch 27/40
436/436 - 300s - loss: 0.2907 - calc_accuracy: 0.7795 - val_loss: 0.3102 - val_calc_accuracy: 0.7384
Epoch 28/40
436/436 - 302s - loss: 0.2904 - calc_accuracy: 0.7775 - val_loss: 0.3585 - val_calc_accuracy: 0.7258
Epoch 29/40
436/436 - 302s - loss: 0.2870 - calc_accuracy: 0.7819 - val_loss: 0.3260 - val_calc_accuracy: 0.7421
Epoch 30/40
436/436 - 302s - loss: 0.2844 - calc_accuracy: 0.7822 - val_loss: 0.3796 - val_calc_accuracy: 0.6962
Epoch 31/40
436/436 - 301s - loss: 0.2831 - calc_accuracy: 0.7835 - val_loss: 0.2932 - val_calc_accuracy: 0.7728
Epoch 32/40
436/436 - 302s - loss: 0.2793 - calc_accuracy: 0.7867 - val_loss: 0.2987 - val_calc_accuracy: 0.7662
Epoch 33/40
436/436 - 301s - loss: 0.2783 - calc_accuracy: 0.7861 - val_loss: 0.2879 - val_calc_accuracy: 0.7857
Epoch 34/40
436/436 - 303s - loss: 0.2760 - calc_accuracy: 0.7861 - val_loss: 0.3794 - val_calc_accuracy: 0.7060
Epoch 35/40
436/436 - 302s - loss: 0.2723 - calc_accuracy: 0.7918 - val_loss: 0.3083 - val_calc_accuracy: 0.7564
Epoch 36/40
436/436 - 300s - loss: 0.2731 - calc_accuracy: 0.7939 - val_loss: 0.3317 - val_calc_accuracy: 0.7487
Epoch 37/40
436/436 - 302s - loss: 0.2730 - calc_accuracy: 0.7942 - val_loss: 0.3249 - val_calc_accuracy: 0.7527
Epoch 38/40
436/436 - 302s - loss: 0.2695 - calc_accuracy: 0.7937 - val_loss: 0.3793 - val_calc_accuracy: 0.7252
Epoch 39/40
436/436 - 301s - loss: 0.2691 - calc_accuracy: 0.7924 - val_loss: 0.2999 - val_calc_accuracy: 0.7797
Epoch 40/40
436/436 - 301s - loss: 0.2661 - calc_accuracy: 0.7951 - val_loss: 0.5848 - val_calc_accuracy: 0.6415

 See logs at ../../cache/conv___03_1757___all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000___parent_wloaded_teacher_trainingscratch___2019/logs/
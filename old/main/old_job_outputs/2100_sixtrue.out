Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2100
Description:  first_run_sixtrue
2021-05-06 04:09:07.648771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-06 04:09:09.953177: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-06 04:09:09.954111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-06 04:09:10.004683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:10.005443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-06 04:09:10.005475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-06 04:09:10.009368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-06 04:09:10.009457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-06 04:09:10.010625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-06 04:09:10.010922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-06 04:09:10.011898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-06 04:09:10.012744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-06 04:09:10.012920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-06 04:09:10.013035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:10.013776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:10.014417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
wandb: Currently logged in as: arachid1 (use `wandb login --relogin` to force relogin)
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2100.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___05_0407___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___first_run_sixtrue___2100/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.0001, 'SHAPE': (128, 1250, 1), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0.4}
Learning Rate Parameters: {'factor': 0.75, 'patience': 5, 'min_lr': 1e-08}
Early Stopping Patience and Delta: 18, 2.0%
Six: True and Concat: False
-----------------------
wandb: Tracking run with wandb version 0.10.29
wandb: Syncing run firm-bee-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/arachid1/tensorboard-integration
wandb: üöÄ View run at https://wandb.ai/arachid1/tensorboard-integration/runs/2o0h363a
wandb: Run data is saved locally in /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210506_040910-2o0h363a
wandb: Run `wandb offline` to turn off syncing.
2021-05-06 04:09:15.191426: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-06 04:09:15.191728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.192928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-06 04:09:15.192998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-06 04:09:15.193098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-06 04:09:15.193153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-06 04:09:15.193191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-06 04:09:15.193226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-06 04:09:15.193261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-06 04:09:15.193295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-06 04:09:15.193328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-06 04:09:15.193469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.194707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.195684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-06 04:09:15.195775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-06 04:09:15.927829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-06 04:09:15.927889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-05-06 04:09:15.927898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-05-06 04:09:15.928179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.929154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.929981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-06 04:09:15.930761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
2021-05-06 04:09:52.541225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-06 04:09:52.543294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-05-06 04:09:55.523894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-06 04:09:56.209816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-06 04:09:56.217838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8

Original number of folders: 453
here
With concat = False and six = True, size of training set: 1824...
...and size of validation set: 450
Initializing weights...
weights = {0: 0.7018518518518518, 1: 1.738532110091743}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 1 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 1) 4           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 32          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 32          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 1) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 32          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            513         global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,200,645
Trainable params: 6,159,139
Non-trainable params: 41,506
__________________________________________________________________________________________________
Epoch 1/30
114/114 - 230s - loss: 0.7721 - accuracy: 0.5164 - val_loss: 0.6482 - val_accuracy: 0.8000
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.26373204823605295
Validation class accuracies: [0.0, 1.0]
Epoch 2/30
114/114 - 222s - loss: 0.7205 - accuracy: 0.5132 - val_loss: 0.6407 - val_accuracy: 0.8000
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.21239594504539963
Validation class accuracies: [0.0, 1.0]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 1 epochs
Epoch 3/30
114/114 - 222s - loss: 0.7097 - accuracy: 0.5378 - val_loss: 0.6480 - val_accuracy: 0.8000
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.2810698881868444
Validation class accuracies: [0.0, 1.0]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 2 epochs
Epoch 4/30
114/114 - 222s - loss: 0.7075 - accuracy: 0.5225 - val_loss: 0.6548 - val_accuracy: 0.8000
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.2569367262739383
Validation class accuracies: [0.0, 1.0]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 3 epochs
Epoch 5/30
114/114 - 224s - loss: 0.7128 - accuracy: 0.5444 - val_loss: 0.6819 - val_accuracy: 0.8044
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.23527174904616072
Validation class accuracies: [0.0, 1.0]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 4 epochs
Epoch 6/30
114/114 - 222s - loss: 0.7069 - accuracy: 0.5362 - val_loss: 0.6666 - val_accuracy: 0.7578
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.2545390803760069
Validation class accuracies: [0.0, 1.0]
Lr has been adjusted to 7.499999628635123e-05
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 5 epochs
Epoch 7/30
114/114 - 222s - loss: 0.7003 - accuracy: 0.5559 - val_loss: 0.6632 - val_accuracy: 0.7511
Confusion matrix: 
 [[ 27 333]
 [ 11  79]]
Validation accuracy: 23.56
Validation recall: 87.78
Validation precision: 19.17
Validation f1: 31.47
Validation AUC: 0.19984823119207432
Validation class accuracies: [0.075, 0.8777777777777778]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 6 epochs
Epoch 8/30
114/114 - 222s - loss: 0.6937 - accuracy: 0.5866 - val_loss: 0.7342 - val_accuracy: 0.5689
Confusion matrix: 
 [[ 57 303]
 [  8  82]]
Validation accuracy: 30.89
Validation recall: 91.11
Validation precision: 21.30
Validation f1: 34.53
Validation AUC: 0.25358933401184247
Validation class accuracies: [0.15833333333333333, 0.9111111111111111]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 7 epochs
Epoch 9/30
114/114 - 221s - loss: 0.6904 - accuracy: 0.5943 - val_loss: 0.6618 - val_accuracy: 0.7400
Confusion matrix: 
 [[118 242]
 [ 25  65]]
Validation accuracy: 40.67
Validation recall: 72.22
Validation precision: 21.17
Validation f1: 32.75
Validation AUC: 0.2302675526396738
Validation class accuracies: [0.3277777777777778, 0.7222222222222222]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 8 epochs
Epoch 10/30
114/114 - 223s - loss: 0.6906 - accuracy: 0.5954 - val_loss: 0.6644 - val_accuracy: 0.7200
Confusion matrix: 
 [[109 251]
 [ 26  64]]
Validation accuracy: 38.44
Validation recall: 71.11
Validation precision: 20.32
Validation f1: 31.60
Validation AUC: 0.2166229988964017
Validation class accuracies: [0.30277777777777776, 0.7111111111111111]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 9 epochs
Epoch 11/30
114/114 - 222s - loss: 0.6839 - accuracy: 0.6146 - val_loss: 0.7118 - val_accuracy: 0.5844
Confusion matrix: 
 [[ 74 286]
 [ 11  79]]
Validation accuracy: 34.00
Validation recall: 87.78
Validation precision: 21.64
Validation f1: 34.73
Validation AUC: 0.2180197208557571
Validation class accuracies: [0.20555555555555555, 0.8777777777777778]
Lr has been adjusted to 5.624999903375283e-05
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 10 epochs
Epoch 12/30
114/114 - 225s - loss: 0.6821 - accuracy: 0.6245 - val_loss: 0.6570 - val_accuracy: 0.7200
Confusion matrix: 
 [[185 175]
 [ 42  48]]
Validation accuracy: 51.78
Validation recall: 53.33
Validation precision: 21.52
Validation f1: 30.67
Validation AUC: 0.2187400998248843
Validation class accuracies: [0.5138888888888888, 0.5333333333333333]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 11 epochs
Epoch 13/30
114/114 - 222s - loss: 0.6751 - accuracy: 0.6310 - val_loss: 0.6938 - val_accuracy: 0.5844
Confusion matrix: 
 [[ 92 268]
 [ 19  71]]
Validation accuracy: 36.22
Validation recall: 78.89
Validation precision: 20.94
Validation f1: 33.10
Validation AUC: 0.18421776788488647
Validation class accuracies: [0.25555555555555554, 0.7888888888888889]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 12 epochs
Epoch 14/30
114/114 - 223s - loss: 0.6760 - accuracy: 0.6310 - val_loss: 0.8668 - val_accuracy: 0.3622
Confusion matrix: 
 [[ 31 329]
 [  3  87]]
Validation accuracy: 26.22
Validation recall: 96.67
Validation precision: 20.91
Validation f1: 34.39
Validation AUC: 0.22575803941700867
Validation class accuracies: [0.08611111111111111, 0.9666666666666667]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 13 epochs
Epoch 15/30
114/114 - 222s - loss: 0.6689 - accuracy: 0.6595 - val_loss: 0.8755 - val_accuracy: 0.2978
Confusion matrix: 
 [[ 11 349]
 [  1  89]]
Validation accuracy: 22.22
Validation recall: 98.89
Validation precision: 20.32
Validation f1: 33.71
Validation AUC: 0.2343840537042954
Validation class accuracies: [0.030555555555555555, 0.9888888888888889]
The validation AUC at 0.33333333333333337 hasn't increased by 0.02 in 14 epochs
Epoch 16/30
114/114 - 222s - loss: 0.6618 - accuracy: 0.7001 - val_loss: 0.7617 - val_accuracy: 0.5556
Confusion matrix: 
 [[102 258]
 [ 14  76]]
Validation accuracy: 39.56
Validation recall: 84.44
Validation precision: 22.75
Validation f1: 35.85
Validation AUC: 0.24033361438740694
Validation class accuracies: [0.2833333333333333, 0.8444444444444444]
Epoch 17/30
114/114 - 222s - loss: 0.6596 - accuracy: 0.6946 - val_loss: 0.7263 - val_accuracy: 0.5200
Confusion matrix: 
 [[ 95 265]
 [ 21  69]]
Validation accuracy: 36.44
Validation recall: 76.67
Validation precision: 20.66
Validation f1: 32.55
Validation AUC: 0.23074479591847902
Validation class accuracies: [0.2638888888888889, 0.7666666666666667]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 1 epochs
Epoch 18/30
114/114 - 222s - loss: 0.6538 - accuracy: 0.7149 - val_loss: 1.2861 - val_accuracy: 0.1978
Confusion matrix: 
 [[  0 360]
 [  0  90]]
Validation accuracy: 20.00
Validation recall: 100.00
Validation precision: 20.00
Validation f1: 33.33
Validation AUC: 0.23044580654744484
Validation class accuracies: [0.0, 1.0]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 2 epochs
Epoch 19/30
114/114 - 225s - loss: 0.6481 - accuracy: 0.7330 - val_loss: 0.7071 - val_accuracy: 0.6156
Confusion matrix: 
 [[171 189]
 [ 46  44]]
Validation accuracy: 47.78
Validation recall: 48.89
Validation precision: 18.88
Validation f1: 27.24
Validation AUC: 0.17263860011375473
Validation class accuracies: [0.475, 0.4888888888888889]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 3 epochs
Epoch 20/30
114/114 - 222s - loss: 0.6416 - accuracy: 0.7478 - val_loss: 0.7949 - val_accuracy: 0.4156
Confusion matrix: 
 [[ 42 318]
 [ 12  78]]
Validation accuracy: 26.67
Validation recall: 86.67
Validation precision: 19.70
Validation f1: 32.10
Validation AUC: 0.20378855749149122
Validation class accuracies: [0.11666666666666667, 0.8666666666666667]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 4 epochs
Epoch 21/30
114/114 - 223s - loss: 0.6348 - accuracy: 0.7571 - val_loss: 1.2173 - val_accuracy: 0.2178
Confusion matrix: 
 [[  0 360]
 [  1  89]]
Validation accuracy: 19.78
Validation recall: 98.89
Validation precision: 19.82
Validation f1: 33.02
Validation AUC: 0.23457668856854214
Validation class accuracies: [0.0, 0.9888888888888889]
Lr has been adjusted to 4.2187501094304025e-05
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 5 epochs
Epoch 22/30
114/114 - 222s - loss: 0.6179 - accuracy: 0.7982 - val_loss: 0.7037 - val_accuracy: 0.6533
Confusion matrix: 
 [[174 186]
 [ 47  43]]
Validation accuracy: 48.22
Validation recall: 47.78
Validation precision: 18.78
Validation f1: 26.96
Validation AUC: 0.19393285408517874
Validation class accuracies: [0.48333333333333334, 0.4777777777777778]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 6 epochs
Epoch 23/30
114/114 - 222s - loss: 0.6183 - accuracy: 0.8109 - val_loss: 0.8272 - val_accuracy: 0.4422
Confusion matrix: 
 [[ 66 294]
 [ 10  80]]
Validation accuracy: 32.44
Validation recall: 88.89
Validation precision: 21.39
Validation f1: 34.48
Validation AUC: 0.2530041616489977
Validation class accuracies: [0.18333333333333332, 0.8888888888888888]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 7 epochs
Epoch 24/30
114/114 - 223s - loss: 0.6126 - accuracy: 0.8207 - val_loss: 1.0674 - val_accuracy: 0.2333
Confusion matrix: 
 [[  3 357]
 [  2  88]]
Validation accuracy: 20.22
Validation recall: 97.78
Validation precision: 19.78
Validation f1: 32.90
Validation AUC: 0.22030952817076976
Validation class accuracies: [0.008333333333333333, 0.9777777777777777]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 8 epochs
Epoch 25/30
114/114 - 223s - loss: 0.6073 - accuracy: 0.8279 - val_loss: 0.7295 - val_accuracy: 0.5978
Confusion matrix: 
 [[129 231]
 [ 26  64]]
Validation accuracy: 42.89
Validation recall: 71.11
Validation precision: 21.69
Validation f1: 33.25
Validation AUC: 0.23659794815322746
Validation class accuracies: [0.35833333333333334, 0.7111111111111111]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 9 epochs
Epoch 26/30
114/114 - 230s - loss: 0.6040 - accuracy: 0.8427 - val_loss: 0.7508 - val_accuracy: 0.5378
Confusion matrix: 
 [[107 253]
 [ 18  72]]
Validation accuracy: 39.78
Validation recall: 80.00
Validation precision: 22.15
Validation f1: 34.70
Validation AUC: 0.23478340068622544
Validation class accuracies: [0.2972222222222222, 0.8]
Lr has been adjusted to 3.164062582072802e-05
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 10 epochs
Epoch 27/30
114/114 - 227s - loss: 0.5990 - accuracy: 0.8487 - val_loss: 1.1642 - val_accuracy: 0.2467
Confusion matrix: 
 [[ 11 349]
 [  1  89]]
Validation accuracy: 22.22
Validation recall: 98.89
Validation precision: 20.32
Validation f1: 33.71
Validation AUC: 0.2203071475187135
Validation class accuracies: [0.030555555555555555, 0.9888888888888889]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 11 epochs
Epoch 28/30
114/114 - 228s - loss: 0.5954 - accuracy: 0.8662 - val_loss: 0.8013 - val_accuracy: 0.4533
Confusion matrix: 
 [[ 84 276]
 [ 19  71]]
Validation accuracy: 34.44
Validation recall: 78.89
Validation precision: 20.46
Validation f1: 32.49
Validation AUC: 0.20585598303335723
Validation class accuracies: [0.23333333333333334, 0.7888888888888889]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 12 epochs
Epoch 29/30
114/114 - 222s - loss: 0.5888 - accuracy: 0.8761 - val_loss: 0.9512 - val_accuracy: 0.3178
Confusion matrix: 
 [[ 21 339]
 [  3  87]]
Validation accuracy: 24.00
Validation recall: 96.67
Validation precision: 20.42
Validation f1: 33.72
Validation AUC: 0.22080246082358412
Validation class accuracies: [0.058333333333333334, 0.9666666666666667]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 13 epochs
Epoch 30/30
114/114 - 222s - loss: 0.5909 - accuracy: 0.8706 - val_loss: 0.9938 - val_accuracy: 0.3000
Confusion matrix: 
 [[ 23 337]
 [  5  85]]
Validation accuracy: 24.00
Validation recall: 94.44
Validation precision: 20.14
Validation f1: 33.20
Validation AUC: 0.23667604179062585
Validation class accuracies: [0.06388888888888888, 0.9444444444444444]
The validation AUC at 0.3584905660377359 hasn't increased by 0.02 in 14 epochs
The metrics for the epoch with the best target metric are: 

Best f1: 0.3584905660377359
Best AUC: 0.24033361438740694
Best accuracy: 0.39555555555555555
Best precision: 0.2275449101796407
Best recall: 0.8444444444444444
Starting...
Accuracy (of 75 elements): 0.2
Ended. Saving the Excel Sheet ../../cache/conv___05_0407___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___first_run_sixtrue___2100/validation_sheet.xls...
Done.
wandb: Waiting for W&B process to finish, PID 7728
wandb: Program ended successfully.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)wandb: \ 0.02MB of 0.03MB uploaded (0.00MB deduped)wandb: | 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: / 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: - 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: \ 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: | 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210506_040910-2o0h363a/logs/debug.log
wandb: Find internal logs for this run at: /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210506_040910-2o0h363a/logs/debug-internal.log
wandb: Run summary:
wandb:             _runtime 7059
wandb:           _timestamp 1620281209
wandb:                _step 239
wandb:       train_accuracy 0.87061
wandb:         val_accuracy 0.3
wandb:           train_loss 0.59087
wandb:             val_loss 0.9938
wandb:           val_recall 0.94444
wandb:        val_precision 0.20142
wandb:               val_f1 0.33203
wandb:              val_auc 0.23668
wandb:                   lr 3e-05
wandb:          best_val_f1 0.35849
wandb:    best_val_accuracy 0.39556
wandb:   best_val_precision 0.22754
wandb:      best_val_recall 0.84444
wandb:             best_auc 0.24033
wandb: Run history:
wandb:         _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:       _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:            _step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     val_accuracy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÇ
wandb:       train_loss ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñÑ‚ñÖ
wandb:       val_recall ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñá‚ñà‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñà‚ñá
wandb:    val_precision ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:           val_f1 ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÜ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb:          val_auc ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb:               lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Synced 6 W&B file(s), 30 media file(s), 23 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced firm-bee-166: https://wandb.ai/arachid1/tensorboard-integration/runs/2o0h363a


 See logs at ../../cache/conv___05_0407___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___first_run_sixtrue___2100/logs/
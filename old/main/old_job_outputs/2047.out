Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2047
Description:  redo
2021-04-13 01:27:22.220108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:27:24.729462: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-13 01:27:24.730779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-13 01:27:24.794357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.795174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-13 01:27:24.795217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:27:24.798853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:27:24.798950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:27:24.800075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-13 01:27:24.800406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-13 01:27:24.801466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-13 01:27:24.802348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-13 01:27:24.802509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:27:24.802640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.803390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.804040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-13 01:27:24.806019: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-13 01:27:24.806210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.806892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-13 01:27:24.806917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:27:24.806947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:27:24.806961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:27:24.806974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-13 01:27:24.806987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-13 01:27:24.807011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-13 01:27:24.807025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-13 01:27:24.807038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:27:24.807120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.807850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:24.808481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-13 01:27:24.808515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:27:25.637583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-13 01:27:25.637627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-13 01:27:25.637636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-13 01:27:25.637900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:25.638714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:25.639423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:27:25.640195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2021-04-13 01:27:26.114427: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-13 01:27:26.114476: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-13 01:27:26.114510: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-13 01:27:26.114707: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-13 01:27:26.115497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-13 01:27:26.345587: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-13 01:27:26.348328: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2047.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_0126___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___redo___2047/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.75, 'patience': 4, 'min_lr': 1e-05}
Early Stopping Patience and Delta: 15, 1.0%
-----------------------
Size of training set: 4316
Size of validation set: 1078
Initializing weights...
weights = {0: 0.6776381909547738, 1: 1.9073550212164074}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 3) 12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 3) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        2021-04-13 01:27:27.493498: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-13 01:27:27.495701: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-13 01:27:31.477590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:27:32.089322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:27:32.102825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:27:36.244908: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-13 01:27:36.244958: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-13 01:27:37.605843: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-13 01:27:37.609210: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-13 01:27:37.652770: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 1419 callback api events and 1415 activity events. 
2021-04-13 01:27:37.692845: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1208s vs `on_train_batch_end` time: 0.5710s). Check your callbacks.

__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            513         global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,200,749
Trainable params: 6,159,239
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
270/270 - 231s - loss: 0.7671 - accuracy: 0.5243 - val_loss: 0.6321 - val_accuracy: 0.7254
Epoch 2/40
270/270 - 220s - loss: 0.6990 - accuracy: 0.5366 - val_loss: 0.5968 - val_accuracy: 0.7254
Epoch 3/40
270/270 - 220s - loss: 0.6969 - accuracy: 0.5257 - val_loss: 0.7102 - val_accuracy: 0.4712
Epoch 4/40
270/270 - 218s - loss: 0.6887 - accuracy: 0.5447 - val_loss: 0.6382 - val_accuracy: 0.6521
Epoch 5/40
270/270 - 220s - loss: 0.6890 - accuracy: 0.5452 - val_loss: 0.6131 - val_accuracy: 0.7022

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.
Epoch 6/40
270/270 - 218s - loss: 0.6785 - accuracy: 0.5704 - val_loss: 0.7132 - val_accuracy: 0.5334
Epoch 7/40
270/270 - 215s - loss: 0.6795 - accuracy: 0.5565 - val_loss: 0.6145 - val_accuracy: 0.6994
Epoch 8/40
270/270 - 216s - loss: 0.6762 - accuracy: 0.5626 - val_loss: 0.5881 - val_accuracy: 0.7245
Epoch 9/40
270/270 - 219s - loss: 0.6761 - accuracy: 0.5792 - val_loss: 0.6706 - val_accuracy: 0.6132

Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.
Epoch 10/40
270/270 - 216s - loss: 0.6739 - accuracy: 0.5707 - val_loss: 0.6002 - val_accuracy: 0.7143
Epoch 11/40
270/270 - 215s - loss: 0.6719 - accuracy: 0.5651 - val_loss: 1.2387 - val_accuracy: 0.6948
Epoch 12/40
270/270 - 216s - loss: 0.6672 - accuracy: 0.5829 - val_loss: 0.6072 - val_accuracy: 0.6948
Epoch 13/40
270/270 - 218s - loss: 0.6670 - accuracy: 0.5918 - val_loss: 0.5832 - val_accuracy: 0.7208

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.
Epoch 14/40
270/270 - 217s - loss: 0.6606 - accuracy: 0.6057 - val_loss: 0.6006 - val_accuracy: 0.7022
Epoch 15/40
270/270 - 217s - loss: 0.6541 - accuracy: 0.6175 - val_loss: 0.6026 - val_accuracy: 0.7236
Epoch 16/40
270/270 - 216s - loss: 0.6549 - accuracy: 0.6052 - val_loss: 0.5971 - val_accuracy: 0.7041
2021-04-13 02:25:56.198289: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-13 02:25:56.198354: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-13 02:25:57.228350: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-13 02:25:57.232805: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-13 02:25:57.277443: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 1419 callback api events and 1415 activity events. 
2021-04-13 02:25:57.314845: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1148s vs `on_train_batch_end` time: 0.6155s). Check your callbacks.
Epoch 00016: early stopping
Transitioning to the 2nd model. 
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 1250, 3) 12          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 1250, 3) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 128, 1250, 16 2320        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 1250, 48 0           conv2d_6[0][0]                   
                                                                 conv2d_8[0][0]                   
                                                                 conv2d_9[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 64, 625, 48)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 625, 48)  192         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 64, 625, 48)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
inverted_residual_10 (InvertedR (None, 64, 625, 32)  35840       dropout_5[0][0]                  
__________________________________________________________________________________________________
inverted_residual_11 (InvertedR (None, 64, 625, 32)  20864       inverted_residual_10[0][0]       
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
inverted_residual_12 (InvertedR (None, 32, 312, 64)  27136       dropout_6[0][0]                  
__________________________________________________________________________________________________
inverted_residual_13 (InvertedR (None, 32, 312, 64)  66304       inverted_residual_12[0][0]       
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
inverted_residual_14 (InvertedR (None, 16, 156, 128) 91136       dropout_7[0][0]                  
__________________________________________________________________________________________________
inverted_residual_15 (InvertedR (None, 16, 156, 128) 230912      inverted_residual_14[0][0]       
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 78, 128)   512         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
inverted_residual_16 (InvertedR (None, 8, 78, 256)   329728      dropout_8[0][0]                  
__________________________________________________________________________________________________
inverted_residual_17 (InvertedR (None, 8, 78, 256)   855040      inverted_residual_16[0][0]       
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 4, 39, 256)   1024        average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
inverted_residual_18 (InvertedR (None, 4, 39, 512)   1249280     dropout_9[0][0]                  
__________________________________________________________________________________________________
inverted_residual_19 (InvertedR (None, 4, 39, 512)   3282944     inverted_residual_18[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           inverted_residual_19[0][0]       
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            513         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 6,200,749
Trainable params: 6,159,239
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
270/270 - 222s - loss: 0.7525 - accuracy: 0.5350 - val_loss: 1.8400 - val_accuracy: 0.2746
Epoch 2/40
270/270 - 218s - loss: 0.6998 - accuracy: 0.5586 - val_loss: 0.7313 - val_accuracy: 0.4314
Epoch 3/40
270/270 - 219s - loss: 0.6956 - accuracy: 0.5222 - val_loss: 0.7765 - val_accuracy: 0.3293
Epoch 4/40
270/270 - 219s - loss: 0.6867 - accuracy: 0.5679 - val_loss: 0.6730 - val_accuracy: 0.6837
Epoch 5/40
270/270 - 217s - loss: 0.6923 - accuracy: 0.5447 - val_loss: 11.0434 - val_accuracy: 0.2755
Epoch 6/40
270/270 - 217s - loss: 0.6847 - accuracy: 0.5602 - val_loss: 0.6928 - val_accuracy: 0.5158
Epoch 7/40
270/270 - 218s - loss: 0.6826 - accuracy: 0.5637 - val_loss: 0.7069 - val_accuracy: 0.4610
Epoch 8/40
270/270 - 218s - loss: 0.6760 - accuracy: 0.5855 - val_loss: 0.6976 - val_accuracy: 0.6197

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.
Epoch 9/40
270/270 - 216s - loss: 0.6739 - accuracy: 0.5651 - val_loss: 0.7374 - val_accuracy: 0.3312
Epoch 10/40
270/270 - 217s - loss: 0.6863 - accuracy: 0.5361 - val_loss: 0.5839 - val_accuracy: 0.7254
Epoch 11/40
270/270 - 219s - loss: 0.6877 - accuracy: 0.5734 - val_loss: 0.6612 - val_accuracy: 0.7254
Epoch 12/40
270/270 - 220s - loss: 0.6817 - accuracy: 0.5635 - val_loss: 0.6565 - val_accuracy: 0.6141
Epoch 13/40
270/270 - 220s - loss: 0.6795 - accuracy: 0.5656 - val_loss: 0.7579 - val_accuracy: 0.6011
Epoch 14/40
270/270 - 218s - loss: 0.6812 - accuracy: 0.5684 - val_loss: 0.6346 - val_accuracy: 0.6577

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.
Epoch 15/40
270/270 - 218s - loss: 0.6719 - accuracy: 0.5637 - val_loss: 0.7039 - val_accuracy: 0.5056
Epoch 16/40
270/270 - 218s - loss: 0.6699 - accuracy: 0.5748 - val_loss: 0.6403 - val_accuracy: 0.7022
Epoch 17/40
270/270 - 218s - loss: 0.6739 - accuracy: 0.5781 - val_loss: 0.6111 - val_accuracy: 0.6763
Epoch 18/40
270/270 - 218s - loss: 0.6599 - accuracy: 0.5848 - val_loss: 0.5933 - val_accuracy: 0.7106

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.
Epoch 19/40
270/270 - 219s - loss: 0.6644 - accuracy: 0.5878 - val_loss: 0.6578 - val_accuracy: 0.5974
Epoch 20/40
270/270 - 217s - loss: 0.6521 - accuracy: 0.6063 - val_loss: 0.7129 - val_accuracy: 0.5223
Epoch 21/40
270/270 - 216s - loss: 0.6604 - accuracy: 0.5901 - val_loss: 0.7889 - val_accuracy: 0.4814
Epoch 22/40
270/270 - 218s - loss: 0.6529 - accuracy: 0.6103 - val_loss: 0.6204 - val_accuracy: 0.6929

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.
Epoch 23/40
270/270 - 217s - loss: 0.6451 - accuracy: 0.6207 - val_loss: 0.6955 - val_accuracy: 0.6317
Epoch 24/40
270/270 - 216s - loss: 0.6407 - accuracy: 0.6138 - val_loss: 0.6314 - val_accuracy: 0.6373
Epoch 25/40
270/270 - 219s - loss: 0.6362 - accuracy: 0.6216 - val_loss: 0.7409 - val_accuracy: 0.4944
Epoch 00025: early stopping

 See logs at ../../cache/conv___04_0126___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___redo___2047/logs/
Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2066
Description:  test_multi
2021-04-19 12:20:55.179551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 12:20:57.134493: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-19 12:20:57.135431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-19 12:20:57.191239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.192064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-19 12:20:57.192092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 12:20:57.195793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 12:20:57.195874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 12:20:57.197050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-19 12:20:57.197356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-19 12:20:57.198454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-19 12:20:57.199415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-19 12:20:57.199577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 12:20:57.199679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.200501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.201243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-19 12:20:57.203331: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-19 12:20:57.203502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.204273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-19 12:20:57.204299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 12:20:57.204331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 12:20:57.204360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 12:20:57.204377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-19 12:20:57.204392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-19 12:20:57.204418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-19 12:20:57.204435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-19 12:20:57.204451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 12:20:57.204514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.205307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.206023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-19 12:20:57.206062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 12:20:57.938969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-19 12:20:57.939015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-19 12:20:57.939024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-19 12:20:57.939343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.940145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.940865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 12:20:57.941538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-04-19 12:21:34.754696: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-19 12:21:34.754747: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-19 12:21:34.754785: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-19 12:21:34.755013: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-19 12:21:34.755852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-19 12:21:34.931147: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-19 12:21:34.933667: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2066.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_1204___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___test_multi___2066/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 4, 'LR': 1e-05, 'SHAPE': (1, 128, 1250), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.75, 'patience': 6, 'min_lr': 1e-08}
Early Stopping Patience and Delta: 22, 1.0%
-----------------------
Original number of folders: 453
here
here
here
Number of 1-indexed chunks: 1737
Actual number of folders: 379
Size of training set: 304
Size of validation set: 75
[[ 0 51]
 [ 1 24]]
Initializing weights...
weights = {0: 0.7018518518518518, 1: 1.738532110091743}
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 8, 128, 1250) 80          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 8, 128, 1250) 80          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 8, 128, 1250) 80          input_3[0][0]                    
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 128, 1250) 80          input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 128, 1250) 80          input_5[0][0]                    
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 128, 1250) 80          input_6[0][0]                    
__________________________________________________________________________________________________
mix_depth_group_convolution2d ( (None, 8, 128, 1250) 1080        conv2d[0][0]                     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_5 (None, 8, 128, 1250) 1080        conv2d_5[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 1250) 1080        conv2d_10[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 1250) 1080        conv2d_15[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 1250) 1080        conv2d_20[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 1250) 1080        conv2d_25[0][0]                  
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 8, 64, 625)   0           mix_depth_group_convolution2d[0][
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_5[0
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_10[
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_15[
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_20[
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_25[
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 8, 64, 625)   2500        average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 64, 625)   2500        average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 64, 625)  1168        batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 64, 625)  1168        batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_1[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_6 (None, 16, 64, 625)  2160        conv2d_6[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_11[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_16[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 625)  2160        conv2d_21[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 625)  2160        conv2d_26[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_1[0
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_6[0
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_11[
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_16[
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_21[
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_26[
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 32, 313)  1252        average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16, 32, 313)  1252        average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 313)  4640        batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 313)  4640        batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_26[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_2[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_7 (None, 32, 32, 313)  4320        conv2d_7[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 313)  4320        conv2d_12[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 313)  4320        conv2d_17[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_22[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_27[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_2[0
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_7[0
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_12[
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_17[
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_22[
__________________________________________________________________________________________________
average_pooling2d_27 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_27[
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 157)  628         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 16, 157)  628         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_27[0][0]       
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 16, 157)  18496       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 64, 16, 157)  18496       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_27[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_3 (None, 64, 16, 157)  8640        conv2d_3[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_8 (None, 64, 16, 157)  8640        conv2d_8[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 157)  8640        conv2d_13[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 157)  8640        conv2d_18[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 157)  8640        conv2d_23[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 157)  8640        conv2d_28[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_3[0
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_8[0
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_13[
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_18[
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_23[
__________________________________________________________________________________________________
average_pooling2d_28 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_28[
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 8, 79)    316         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 8, 79)    316         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_28[0][0]       
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 8, 79)   73856       batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 8, 79)   73856       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_28[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_4 (None, 128, 8, 79)   17280       conv2d_4[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_9 (None, 128, 8, 79)   17280       conv2d_9[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 79)   17280       conv2d_14[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 79)   17280       conv2d_19[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 79)   17280       conv2d_24[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 79)   17280       conv2d_29[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_4[0
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_9[0
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_14[
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_19[
__________________________________________________________________________________________________2021-04-19 12:21:37.000927: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-19 12:21:37.001980: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-19 12:21:46.138496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 12:21:46.790178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 12:21:46.854407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 12:21:49.722615: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-19 12:21:49.722655: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-19 12:21:51.119709: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-19 12:21:51.123062: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-19 12:21:51.173953: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 2465 callback api events and 2461 activity events. 
2021-04-19 12:21:51.251576: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
[[51 0]
 [24 0]]

average_pooling2d_24 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_24[
__________________________________________________________________________________________________
average_pooling2d_29 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_29[
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 4, 40)   160         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 128, 4, 40)   160         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_29[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 128)          0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 128)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 128)          0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 128)          0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 128)          0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 768)          0           global_average_pooling2d[0][0]   
                                                                 global_average_pooling2d_1[0][0] 
                                                                 global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense (Dense)                   (None, 32)           24608       concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      
==================================================================================================
Total params: 844,097
Trainable params: 829,529
Non-trainable params: 14,568
__________________________________________________________________________________________________
Epoch 1/40
76/76 - 79s - loss: 0.7043 - accuracy: 0.4901 - precision: 0.2034 - recall: 0.2824 - gen_confusion_matrix: 1.0305 - val_loss: 0.6916 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 2/40
76/76 - 62s - loss: 0.6873 - accuracy: 0.5789 - precision: 0.3097 - recall: 0.4118 - gen_confusion_matrix: 1.0201 - val_loss: 0.6898 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 3/40
76/76 - 63s - loss: 0.6814 - accuracy: 0.5888 - precision: 0.3413 - recall: 0.5059 - gen_confusion_matrix: 1.0411 - val_loss: 0.6874 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 4/40
76/76 - 62s - loss: 0.6800 - accuracy: 0.5658 - precision: 0.3259 - recall: 0.5176 - gen_confusion_matrix: 1.0100 - val_loss: 0.6835 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 5/40
76/76 - 61s - loss: 0.6695 - accuracy: 0.6283 - precision: 0.3889 - recall: 0.5765 - gen_confusion_matrix: 1.0100 - val_loss: 0.6788 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 6/40
76/76 - 62s - loss: 0.6753 - accuracy: 0.6612 - precision: 0.4043 - recall: 0.4471 - gen_confusion_matrix: 1.0411 - val_loss: 0.6743 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [23 1]]
Epoch 7/40
76/76 - 60s - loss: 0.6742 - accuracy: 0.5526 - precision: 0.3265 - recall: 0.5647 - gen_confusion_matrix: 1.0100 - val_loss: 0.6650 - val_accuracy: 0.6933 - val_precision: 1.0000 - val_recall: 0.0417 - val_gen_confusion_matrix: 18.7500
[[46 5]
 [17 7]]
Epoch 8/40
76/76 - 62s - loss: 0.6572 - accuracy: 0.6941 - precision: 0.4545 - recall: 0.4706 - gen_confusion_matrix: 1.0411 - val_loss: 0.6519 - val_accuracy: 0.7067 - val_precision: 0.5833 - val_recall: 0.2917 - val_gen_confusion_matrix: 18.7500
[[44 7]
 [16 8]]
Epoch 9/40
76/76 - 62s - loss: 0.6648 - accuracy: 0.5625 - precision: 0.3500 - recall: 0.6588 - gen_confusion_matrix: 1.0100 - val_loss: 0.6325 - val_accuracy: 0.6933 - val_precision: 0.5333 - val_recall: 0.3333 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [6 18]]
Epoch 10/40
76/76 - 62s - loss: 0.6658 - accuracy: 0.6513 - precision: 0.3871 - recall: 0.4235 - gen_confusion_matrix: 1.0742 - val_loss: 0.6854 - val_accuracy: 0.6267 - val_precision: 0.4500 - val_recall: 0.7500 - val_gen_confusion_matrix: 18.7500
[[33 18]
 [7 17]]
Epoch 11/40
76/76 - 61s - loss: 0.6562 - accuracy: 0.6349 - precision: 0.3898 - recall: 0.5412 - gen_confusion_matrix: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.6667 - val_precision: 0.4857 - val_recall: 0.7083 - val_gen_confusion_matrix: 18.7500
[[34 17]
 [7 17]]
Epoch 12/40
76/76 - 62s - loss: 0.6596 - accuracy: 0.6316 - precision: 0.3884 - recall: 0.5529 - gen_confusion_matrix: 1.0100 - val_loss: 0.6746 - val_accuracy: 0.6800 - val_precision: 0.5000 - val_recall: 0.7083 - val_gen_confusion_matrix: 18.7500
[[24 27]
 [5 19]]
Epoch 13/40
76/76 - 62s - loss: 0.6631 - accuracy: 0.6513 - precision: 0.3939 - recall: 0.4588 - gen_confusion_matrix: 1.0742 - val_loss: 0.7162 - val_accuracy: 0.5733 - val_precision: 0.4130 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[23 28]
 [3 21]]
Epoch 14/40
76/76 - 62s - loss: 0.6479 - accuracy: 0.6645 - precision: 0.4274 - recall: 0.5882 - gen_confusion_matrix: 1.0305 - val_loss: 0.7284 - val_accuracy: 0.5867 - val_precision: 0.4286 - val_recall: 0.8750 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [6 18]]

Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.
Epoch 15/40
76/76 - 61s - loss: 0.6443 - accuracy: 0.6020 - precision: 0.3831 - recall: 0.6941 - gen_confusion_matrix: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.6267 - val_precision: 0.4500 - val_recall: 0.7500 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 16/40
76/76 - 60s - loss: 0.6476 - accuracy: 0.6974 - precision: 0.4568 - recall: 0.4353 - gen_confusion_matrix: 1.0411 - val_loss: 0.7151 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 17/40
76/76 - 60s - loss: 0.6423 - accuracy: 0.6250 - precision: 0.3986 - recall: 0.6706 - gen_confusion_matrix: 1.0100 - val_loss: 0.7162 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 18/40
76/76 - 62s - loss: 0.6484 - accuracy: 0.6579 - precision: 0.4128 - recall: 0.5294 - gen_confusion_matrix: 1.0201 - val_loss: 0.7025 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 19/40
76/76 - 61s - loss: 0.6421 - accuracy: 0.6546 - precision: 0.4194 - recall: 0.6118 - gen_confusion_matrix: 1.0100 - val_loss: 0.7194 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 20/40
76/76 - 61s - loss: 0.6499 - accuracy: 0.6480 - precision: 0.4098 - recall: 0.5882 - gen_confusion_matrix: 1.0100 - val_loss: 0.7288 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[23 28]
 [5 19]]

Epoch 00020: ReduceLROnPlateau reducing learning rate to 5.624999857900548e-06.
Epoch 21/40
76/76 - 66s - loss: 0.6406 - accuracy: 0.6908 - precision: 0.4563 - recall: 0.5529 - gen_confusion_matrix: 1.0305 - val_loss: 0.7422 - val_accuracy: 0.5600 - val_precision: 0.4043 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[23 28]
 [4 20]]
Epoch 22/40
76/76 - 76s - loss: 0.6456 - accuracy: 0.6118 - precision: 0.3759 - recall: 0.5882 - gen_confusion_matrix: 1.0100 - val_loss: 0.7416 - val_accuracy: 0.5733 - val_precision: 0.4167 - val_recall: 0.8333 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 23/40
76/76 - 76s - loss: 0.6419 - accuracy: 0.6612 - precision: 0.4250 - recall: 0.6000 - gen_confusion_matrix: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 24/40
76/76 - 76s - loss: 0.6400 - accuracy: 0.6480 - precision: 0.4154 - recall: 0.6353 - gen_confusion_matrix: 1.0100 - val_loss: 0.7093 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [6 18]]
Epoch 25/40
76/76 - 77s - loss: 0.6211 - accuracy: 0.7072 - precision: 0.4808 - recall: 0.5882 - gen_confusion_matrix: 1.0411 - val_loss: 0.7041 - val_accuracy: 0.6267 - val_precision: 0.4500 - val_recall: 0.7500 - val_gen_confusion_matrix: 18.7500
[[27 24]
 [6 18]]
Epoch 26/40
76/76 - 72s - loss: 0.6274 - accuracy: 0.6480 - precision: 0.4083 - recall: 0.5765 - gen_confusion_matrix: 1.0305 - val_loss: 0.7155 - val_accuracy: 0.6000 - val_precision: 0.4286 - val_recall: 0.7500 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]

Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.2187500639556674e-06.
Epoch 27/40
76/76 - 60s - loss: 0.6410 - accuracy: 0.6645 - precision: 0.4158 - recall: 0.4941 - gen_confusion_matrix: 1.0305 - val_loss: 0.7368 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 28/40
76/76 - 61s - loss: 0.6373 - accuracy: 0.6546 - precision: 0.4123 - recall: 0.5529 - gen_confusion_matrix: 1.0201 - val_loss: 0.7259 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 29/40
76/76 - 61s - loss: 0.6297 - accuracy: 0.6875 - precision: 0.4554 - recall: 0.6000 - gen_confusion_matrix: 1.0100 - val_loss: 0.7380 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 30/40
76/76 - 61s - loss: 0.6374 - accuracy: 0.6546 - precision: 0.4180 - recall: 0.6000 - gen_confusion_matrix: 1.0305 - val_loss: 0.7365 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 31/40
76/76 - 61s - loss: 0.6339 - accuracy: 0.6513 - precision: 0.4118 - recall: 0.5765 - gen_confusion_matrix: 1.0305 - val_loss: 0.7294 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]
Epoch 32/40
76/76 - 60s - loss: 0.6399 - accuracy: 0.6513 - precision: 0.4118 - recall: 0.5765 - gen_confusion_matrix: 1.0201 - val_loss: 0.7345 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [5 19]]

Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.164062718497007e-06.
Epoch 33/40
76/76 - 60s - loss: 0.6344 - accuracy: 0.7039 - precision: 0.4771 - recall: 0.6118 - gen_confusion_matrix: 1.0305 - val_loss: 0.7264 - val_accuracy: 0.6000 - val_precision: 0.4318 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [4 20]]
Epoch 34/40
76/76 - 61s - loss: 0.6377 - accuracy: 0.6579 - precision: 0.4264 - recall: 0.6471 - gen_confusion_matrix: 1.0201 - val_loss: 0.7297 - val_accuracy: 0.6133 - val_precision: 0.4444 - val_recall: 0.8333 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 35/40
76/76 - 61s - loss: 0.6346 - accuracy: 0.6743 - precision: 0.4375 - recall: 0.5765 - gen_confusion_matrix: 1.0100 - val_loss: 0.7285 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 36/40
76/76 - 60s - loss: 0.6267 - accuracy: 0.6776 - precision: 0.4454 - recall: 0.6235 - gen_confusion_matrix: 1.0305 - val_loss: 0.7358 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 37/40
76/76 - 61s - loss: 0.6135 - accuracy: 0.6711 - precision: 0.4427 - recall: 0.6824 - gen_confusion_matrix: 1.0201 - val_loss: 0.7335 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 38/40
76/76 - 60s - loss: 0.6339 - accuracy: 0.6875 - precision: 0.4490 - recall: 0.5176 - gen_confusion_matrix: 1.0201 - val_loss: 0.7435 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]

Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.3730470388727554e-06.
Epoch 39/40
76/76 - 61s - loss: 0.6251 - accuracy: 0.6645 - precision: 0.4286 - recall: 0.6000 - gen_confusion_matrix: 1.0201 - val_loss: 0.7416 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [5 19]]
Epoch 40/40
76/76 - 61s - loss: 0.6264 - accuracy: 0.6809 - precision: 0.4500 - recall: 0.6353 - gen_confusion_matrix: 1.0201 - val_loss: 0.7405 - val_accuracy: 0.5867 - val_precision: 0.4222 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500

 See logs at ../../cache/conv___04_1204___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___test_multi___2066/logs/
Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000.pkl
File:  conv.train2015
Description:  test
2021-03-19 05:46:41.577145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-19 05:46:43.525517: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-19 05:46:43.526346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-19 05:46:43.622973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.623764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-19 05:46:43.623895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.624596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-19 05:46:43.624625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-19 05:46:43.628095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-19 05:46:43.628181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-19 05:46:43.629262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-19 05:46:43.629538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-19 05:46:43.630609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-19 05:46:43.631598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-19 05:46:43.631763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-19 05:46:43.631872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.632724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.633453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.634214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:43.634895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-03-19 05:46:43.636943: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-19 05:46:44.059087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.059834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-19 05:46:44.060031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.060699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-19 05:46:44.060729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-19 05:46:44.060768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-19 05:46:44.060782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-19 05:46:44.060796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-19 05:46:44.060809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-19 05:46:44.060822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-19 05:46:44.060836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-19 05:46:44.060849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-19 05:46:44.060935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.061677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.062479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.063232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.063935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-03-19 05:46:44.063975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-19 05:46:44.962348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-19 05:46:44.962401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2021-03-19 05:46:44.962411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y 
2021-03-19 05:46:44.962418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N 
2021-03-19 05:46:44.962801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.963620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.964364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.965127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.965784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2021-03-19 05:46:44.966287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.967091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-19 05:46:44.967767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14760 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-03-19 05:46:45.436883: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-19 05:46:45.436920: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-19 05:46:45.436962: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs
2021-03-19 05:46:45.437179: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-03-19 05:46:45.437887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-03-19 05:46:45.814905: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-19 05:46:45.819801: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  2
-----------------------
Using module located at /main/models/conv/train2015.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___03_0544___all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000___test___2015/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 2, 'SR': 8000, 'BATCH_SIZE': 32, 'LR': 0.001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0.4}
Learning Rate Parameters: {'factor': 0.5, 'patience': 4, 'min_lr': 1e-05, 'min_delta': 0.01}
Early Stopping Patience: 8 and Delta: 1.0 %
-----------------------
Size of training set: 13945
Size of validation set: 3486
Initializing weights...
weights = {0: 0.6399045521292217, 1: 1.2145345596432553, 2: 1.1234209847898944, 3: 1.3816582117945466}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 3) 12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 3) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            1026        global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,201,262
Trainable params: 6,159,752
Non-trainable params: 41,510
__________________________________________________________________________________________________
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 1250, 3) 12          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 1250, 3) 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 128, 1250, 16 2320        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 1250, 48 0           conv2d_6[0][0]                   
                                                                 conv2d_8[0][0]                   
                                                                 conv2d_9[0][0]                   
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 64, 625, 48)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 64, 625, 48)  192         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 64, 625, 48)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
inverted_residual_10 (InvertedR (None, 64, 625, 32)  35840       dropout_5[0][0]                  
__________________________________________________________________________________________________
inverted_residual_11 (InvertedR (None, 64, 625, 32)  20864       inverted_residual_10[0][0]       
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
inverted_residual_12 (InvertedR (None, 32, 312, 64)  27136       dropout_6[0][0]                  
__________________________________________________________________________________________________
inverted_residual_13 (InvertedR (None, 32, 312, 64)  66304       inverted_residual_12[0][0]       
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
inverted_residual_14 (InvertedR (None, 16, 156, 128) 91136       dropout_7[0][0]                  
__________________________________________________________________________________________________
inverted_residual_15 (InvertedR (None, 16, 156, 128) 230912      inverted_residual_14[0][0]       
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 78, 128)   512         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
inverted_residual_16 (InvertedR (None, 8, 78, 256)   329728      dropout_8[0][0]                  
__________________________________________________________________________________________________
inverted_residual_17 (InvertedR (None, 8, 78, 256)   855040      inverted_residual_16[0][0]       
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 4, 39, 256)   1024        average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
inverted_residual_18 (InvertedR (None, 4, 39, 512)   1249280     dropout_9[0][0]                  
__________________________________________________________________________________________________
inverted_residual_19 (InvertedR (None, 4, 39, 512)   3282944     inverted_residual_18[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           inverted_residual_19[0][0]       
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            1026        global_average_pooling2d_1[0][0] 
==================================================================================================2021-03-19 05:46:48.129781: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
      type: DT_FLOAT
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
      shape {
        dim {
          size: 2
        }
      }
    }
  }
}

2021-03-19 05:46:48.166696: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-03-19 05:46:48.168381: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-03-19 05:47:09.038833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-19 05:47:09.329816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-19 05:47:09.970196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-19 05:47:20.539156: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-19 05:47:20.539220: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-19 05:47:22.401146: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-03-19 05:47:22.407383: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-03-19 05:47:22.484827: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 3152 callback api events and 3149 activity events. 
2021-03-19 05:47:22.560305: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-19 05:52:55.267256: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
      type: DT_FLOAT
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
      shape {
        dim {
          size: 2
        }
      }
    }
  }
}


Total params: 6,201,262
Trainable params: 6,159,752
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
436/436 - 432s - loss: 0.4953 - calc_accuracy: 0.5981 - val_loss: 0.8860 - val_calc_accuracy: 0.3944
Epoch 2/40
436/436 - 396s - loss: 0.4565 - calc_accuracy: 0.7101 - val_loss: 0.6206 - val_calc_accuracy: 0.6738
Epoch 3/40
436/436 - 395s - loss: 0.4503 - calc_accuracy: 0.7329 - val_loss: 0.7152 - val_calc_accuracy: 0.5606
Epoch 4/40
436/436 - 394s - loss: 0.4452 - calc_accuracy: 0.7575 - val_loss: 0.5942 - val_calc_accuracy: 0.7186
Epoch 5/40
436/436 - 396s - loss: 0.4390 - calc_accuracy: 0.7859 - val_loss: 0.5776 - val_calc_accuracy: 0.7797
Epoch 6/40
436/436 - 397s - loss: 0.4356 - calc_accuracy: 0.8050 - val_loss: 0.5836 - val_calc_accuracy: 0.7465
Epoch 7/40
436/436 - 395s - loss: 0.4313 - calc_accuracy: 0.8200 - val_loss: 0.5595 - val_calc_accuracy: 0.8282
Epoch 8/40
436/436 - 395s - loss: 0.4292 - calc_accuracy: 0.8278 - val_loss: 0.6252 - val_calc_accuracy: 0.6615
Epoch 9/40
436/436 - 395s - loss: 0.4280 - calc_accuracy: 0.8363 - val_loss: 0.5736 - val_calc_accuracy: 0.8015
Epoch 10/40
436/436 - 394s - loss: 0.4264 - calc_accuracy: 0.8450 - val_loss: 0.5584 - val_calc_accuracy: 0.8528
Epoch 11/40
436/436 - 395s - loss: 0.4249 - calc_accuracy: 0.8528 - val_loss: 0.5548 - val_calc_accuracy: 0.8523
Epoch 12/40
436/436 - 394s - loss: 0.4225 - calc_accuracy: 0.8642 - val_loss: 0.5528 - val_calc_accuracy: 0.8560
Epoch 13/40
436/436 - 394s - loss: 0.4222 - calc_accuracy: 0.8643 - val_loss: 0.5494 - val_calc_accuracy: 0.8732
Epoch 14/40
436/436 - 395s - loss: 0.4204 - calc_accuracy: 0.8738 - val_loss: 0.5603 - val_calc_accuracy: 0.8227
Epoch 15/40
436/436 - 395s - loss: 0.4190 - calc_accuracy: 0.8773 - val_loss: 0.5423 - val_calc_accuracy: 0.8893
Epoch 16/40
436/436 - 395s - loss: 0.4188 - calc_accuracy: 0.8802 - val_loss: 0.5462 - val_calc_accuracy: 0.8862
Epoch 17/40
436/436 - 395s - loss: 0.4167 - calc_accuracy: 0.8883 - val_loss: 0.5507 - val_calc_accuracy: 0.8729
Epoch 18/40
436/436 - 395s - loss: 0.4159 - calc_accuracy: 0.8921 - val_loss: 0.5464 - val_calc_accuracy: 0.8704
Epoch 19/40
436/436 - 395s - loss: 0.4138 - calc_accuracy: 0.9022 - val_loss: 0.5518 - val_calc_accuracy: 0.8634

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 20/40
436/436 - 396s - loss: 0.4089 - calc_accuracy: 0.9242 - val_loss: 0.5372 - val_calc_accuracy: 0.9039
Epoch 21/40
436/436 - 395s - loss: 0.4071 - calc_accuracy: 0.9342 - val_loss: 0.5338 - val_calc_accuracy: 0.9159
Epoch 22/40
436/436 - 396s - loss: 0.4070 - calc_accuracy: 0.9348 - val_loss: 0.5330 - val_calc_accuracy: 0.9171
Epoch 23/40
436/436 - 395s - loss: 0.4059 - calc_accuracy: 0.9402 - val_loss: 0.5459 - val_calc_accuracy: 0.8830
Epoch 24/40
436/436 - 395s - loss: 0.4042 - calc_accuracy: 0.9477 - val_loss: 0.5376 - val_calc_accuracy: 0.9050
Epoch 25/40
436/436 - 395s - loss: 0.4037 - calc_accuracy: 0.9513 - val_loss: 0.5328 - val_calc_accuracy: 0.9162

Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 26/40
436/436 - 396s - loss: 0.4010 - calc_accuracy: 0.9653 - val_loss: 0.5312 - val_calc_accuracy: 0.9228
Epoch 27/40
436/436 - 394s - loss: 0.4000 - calc_accuracy: 0.9679 - val_loss: 0.5304 - val_calc_accuracy: 0.9254
Epoch 28/40
436/436 - 396s - loss: 0.3999 - calc_accuracy: 0.9723 - val_loss: 0.5293 - val_calc_accuracy: 0.9268
Epoch 29/40
436/436 - 395s - loss: 0.3991 - calc_accuracy: 0.9731 - val_loss: 0.5320 - val_calc_accuracy: 0.9255
Epoch 30/40
436/436 - 395s - loss: 0.3982 - calc_accuracy: 0.9767 - val_loss: 0.5292 - val_calc_accuracy: 0.9308
Epoch 31/40
436/436 - 395s - loss: 0.3985 - calc_accuracy: 0.9792 - val_loss: 0.5298 - val_calc_accuracy: 0.9277
Epoch 32/40
436/436 - 396s - loss: 0.3981 - calc_accuracy: 0.9798 - val_loss: 0.5282 - val_calc_accuracy: 0.9295

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 33/40
436/436 - 394s - loss: 0.3969 - calc_accuracy: 0.9847 - val_loss: 0.5282 - val_calc_accuracy: 0.9291
Epoch 34/40
436/436 - 394s - loss: 0.3967 - calc_accuracy: 0.9837 - val_loss: 0.5275 - val_calc_accuracy: 0.9343
Epoch 35/40
436/436 - 400s - loss: 0.3962 - calc_accuracy: 0.9863 - val_loss: 0.5284 - val_calc_accuracy: 0.9303
Epoch 36/40
436/436 - 396s - loss: 0.3960 - calc_accuracy: 0.9874 - val_loss: 0.5278 - val_calc_accuracy: 0.9306

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 00036: early stopping

 See logs at ../../cache/conv___03_0544___all_sw_coch_preprocessed_v2_param_v26_augm_v0_cleaned_8000___test___2015/logs/
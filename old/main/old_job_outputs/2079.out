Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2079
Description:  multi_with_add
2021-04-24 15:53:56.422211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 15:53:58.532347: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-24 15:53:58.533285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-24 15:53:58.595173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.595905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-24 15:53:58.595933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 15:53:58.599363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-24 15:53:58.599426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-24 15:53:58.600519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-24 15:53:58.600788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-24 15:53:58.601732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-24 15:53:58.602562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-24 15:53:58.602702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-24 15:53:58.602801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.603539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.604214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-24 15:53:58.606028: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-24 15:53:58.606157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.606957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-24 15:53:58.606981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 15:53:58.607007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-24 15:53:58.607022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-24 15:53:58.607037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-24 15:53:58.607052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-24 15:53:58.607078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-24 15:53:58.607094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-24 15:53:58.607109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-24 15:53:58.607182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.607983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:58.608721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-24 15:53:58.608760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-24 15:53:59.349717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-24 15:53:59.349759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-24 15:53:59.349768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-24 15:53:59.350037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:59.350844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:59.351559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-24 15:53:59.352264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-04-24 15:54:40.502412: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-24 15:54:40.502484: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-24 15:54:40.502524: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-24 15:54:40.502782: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-24 15:54:40.503789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-24 15:54:40.696651: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-24 15:54:40.699204: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2079.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_1553___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___multi_with_add___2079/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.0001, 'SHAPE': (1, 128, 1250), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0.4}
Learning Rate Parameters: {'factor': 0.75, 'patience': 4, 'min_lr': 1e-08}
Early Stopping Patience and Delta: 25, 1.0%
-----------------------
Original number of folders: 453
here
here
here
Number of 1-indexed chunks: 1737
Actual number of folders: 379
Size of training set: 304
Size of validation set: 75
[[ 0 51]
 [ 1 24]]
Initializing weights...
weights = {0: 0.7018518518518518, 1: 1.738532110091743}
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            [(None, 1, 128, 1250 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 8, 128, 1250) 80          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 8, 128, 1250) 80          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 8, 128, 1250) 80          input_3[0][0]                    
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 128, 1250) 80          input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 128, 1250) 80          input_5[0][0]                    
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 128, 1250) 80          input_6[0][0]                    
__________________________________________________________________________________________________
mix_depth_group_convolution2d ( (None, 8, 128, 1250) 1080        conv2d[0][0]                     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_5 (None, 8, 128, 1250) 1080        conv2d_5[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 1250) 1080        conv2d_10[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 1250) 1080        conv2d_15[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 1250) 1080        conv2d_20[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 1250) 1080        conv2d_25[0][0]                  
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 8, 64, 625)   0           mix_depth_group_convolution2d[0][
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_5[0
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_10[
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_15[
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_20[
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 8, 64, 625)   0           mix_depth_group_convolution2d_25[
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 8, 64, 625)   2500        average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 64, 625)   2500        average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 64, 625)   2500        average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 64, 625)  1168        batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 64, 625)  1168        batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 64, 625)  1168        batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_1[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_6 (None, 16, 64, 625)  2160        conv2d_6[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_11[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 625)  2160        conv2d_16[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 625)  2160        conv2d_21[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 625)  2160        conv2d_26[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_1[0
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_6[0
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_11[
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_16[
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_21[
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 16, 32, 313)  0           mix_depth_group_convolution2d_26[
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 32, 313)  1252        average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16, 32, 313)  1252        average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 32, 313)  1252        average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 313)  4640        batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 313)  4640        batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 32, 32, 313)  4640        batch_normalization_26[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_2[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_7 (None, 32, 32, 313)  4320        conv2d_7[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 313)  4320        conv2d_12[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 313)  4320        conv2d_17[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_22[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 313)  4320        conv2d_27[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_2[0
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_7[0
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_12[
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_17[
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_22[
__________________________________________________________________________________________________
average_pooling2d_27 (AveragePo (None, 32, 16, 157)  0           mix_depth_group_convolution2d_27[
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 157)  628         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 16, 157)  628         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 32, 16, 157)  628         average_pooling2d_27[0][0]       
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 16, 157)  18496       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 64, 16, 157)  18496       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 64, 16, 157)  18496       batch_normalization_27[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_3 (None, 64, 16, 157)  8640        conv2d_3[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_8 (None, 64, 16, 157)  8640        conv2d_8[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 157)  8640        conv2d_13[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 157)  8640        conv2d_18[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 157)  8640        conv2d_23[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 157)  8640        conv2d_28[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_3[0
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_8[0
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_13[
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_18[
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_23[
__________________________________________________________________________________________________
average_pooling2d_28 (AveragePo (None, 64, 8, 79)    0           mix_depth_group_convolution2d_28[
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 8, 79)    316         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 8, 79)    316         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 64, 8, 79)    316         average_pooling2d_28[0][0]       
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 8, 79)   73856       batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 8, 79)   73856       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 128, 8, 79)   73856       batch_normalization_28[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_4 (None, 128, 8, 79)   17280       conv2d_4[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_9 (None, 128, 8, 79)   17280       conv2d_9[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 79)   17280       conv2d_14[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 79)   17280       conv2d_19[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 79)   17280       conv2d_24[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 79)   17280       conv2d_29[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_4[0
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_9[0
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_14[
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_19[
__________________________________________________________________________________________________2021-04-24 15:54:43.032510: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-24 15:54:43.033370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-24 15:54:52.500080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-24 15:54:53.656959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-24 15:54:54.040429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-24 15:54:59.359101: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-24 15:54:59.359146: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-24 15:55:02.097341: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-24 15:55:02.100655: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-24 15:55:02.147538: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 2454 callback api events and 2450 activity events. 
2021-04-24 15:55:02.220613: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
[[51 0]
 [24 0]]

average_pooling2d_24 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_24[
__________________________________________________________________________________________________
average_pooling2d_29 (AveragePo (None, 128, 4, 40)   0           mix_depth_group_convolution2d_29[
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 4, 40)   160         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 128, 4, 40)   160         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 128, 4, 40)   160         average_pooling2d_29[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 128)          0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 128)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 128)          0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 128)          0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 128)          0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
add (Add)                       (None, 128)          0           global_average_pooling2d[0][0]   
                                                                 global_average_pooling2d_1[0][0] 
                                                                 global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense (Dense)                   (None, 32)           4128        add[0][0]                        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      
==================================================================================================
Total params: 823,617
Trainable params: 809,049
Non-trainable params: 14,568
__________________________________________________________________________________________________
Epoch 1/40
19/19 - 66s - loss: 0.7273 - accuracy: 0.5164 - precision: 0.2961 - recall: 0.5294 - gen_confusion_matrix: 4.0000 - val_loss: 0.6925 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 2/40
19/19 - 50s - loss: 0.7050 - accuracy: 0.6020 - precision: 0.3163 - recall: 0.3647 - gen_confusion_matrix: 4.0000 - val_loss: 0.6916 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 3/40
19/19 - 48s - loss: 0.6926 - accuracy: 0.5493 - precision: 0.3333 - recall: 0.6118 - gen_confusion_matrix: 4.0000 - val_loss: 0.6905 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 4/40
19/19 - 48s - loss: 0.6797 - accuracy: 0.5855 - precision: 0.3459 - recall: 0.5412 - gen_confusion_matrix: 4.0000 - val_loss: 0.6899 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 5/40
19/19 - 49s - loss: 0.6643 - accuracy: 0.6743 - precision: 0.4444 - recall: 0.6588 - gen_confusion_matrix: 4.0000 - val_loss: 0.6886 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00005: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-05.
Epoch 6/40
19/19 - 49s - loss: 0.6586 - accuracy: 0.7303 - precision: 0.5152 - recall: 0.6000 - gen_confusion_matrix: 4.0000 - val_loss: 0.6882 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 7/40
19/19 - 49s - loss: 0.6460 - accuracy: 0.7533 - precision: 0.5510 - recall: 0.6353 - gen_confusion_matrix: 4.0000 - val_loss: 0.6873 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 8/40
19/19 - 48s - loss: 0.6458 - accuracy: 0.7566 - precision: 0.5579 - recall: 0.6235 - gen_confusion_matrix: 4.0000 - val_loss: 0.6863 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 9/40
19/19 - 48s - loss: 0.6388 - accuracy: 0.7434 - precision: 0.5299 - recall: 0.7294 - gen_confusion_matrix: 4.0000 - val_loss: 0.6856 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00009: ReduceLROnPlateau reducing learning rate to 5.6249997214763425e-05.
Epoch 10/40
19/19 - 49s - loss: 0.6458 - accuracy: 0.7072 - precision: 0.4839 - recall: 0.7059 - gen_confusion_matrix: 4.0000 - val_loss: 0.6845 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 11/40
19/19 - 49s - loss: 0.6350 - accuracy: 0.8092 - precision: 0.6421 - recall: 0.7176 - gen_confusion_matrix: 4.0000 - val_loss: 0.6839 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 12/40
19/19 - 48s - loss: 0.6354 - accuracy: 0.7599 - precision: 0.5556 - recall: 0.7059 - gen_confusion_matrix: 4.0000 - val_loss: 0.6837 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 13/40
19/19 - 48s - loss: 0.6329 - accuracy: 0.7730 - precision: 0.5714 - recall: 0.7529 - gen_confusion_matrix: 4.0000 - val_loss: 0.6827 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.218749927531462e-05.
Epoch 14/40
19/19 - 49s - loss: 0.6240 - accuracy: 0.8355 - precision: 0.6842 - recall: 0.7647 - gen_confusion_matrix: 4.0000 - val_loss: 0.6820 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 15/40
19/19 - 49s - loss: 0.6228 - accuracy: 0.8092 - precision: 0.6286 - recall: 0.7765 - gen_confusion_matrix: 4.0000 - val_loss: 0.6808 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 16/40
19/19 - 50s - loss: 0.6229 - accuracy: 0.8322 - precision: 0.7024 - recall: 0.6941 - gen_confusion_matrix: 4.0000 - val_loss: 0.6793 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 17/40
19/19 - 49s - loss: 0.6180 - accuracy: 0.8257 - precision: 0.6481 - recall: 0.8235 - gen_confusion_matrix: 4.0000 - val_loss: 0.6798 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.164062582072802e-05.
Epoch 18/40
19/19 - 48s - loss: 0.6161 - accuracy: 0.8553 - precision: 0.7204 - recall: 0.7882 - gen_confusion_matrix: 4.0000 - val_loss: 0.6789 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 19/40
19/19 - 48s - loss: 0.6122 - accuracy: 0.8289 - precision: 0.6514 - recall: 0.8353 - gen_confusion_matrix: 4.0000 - val_loss: 0.6780 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 20/40
19/19 - 49s - loss: 0.6177 - accuracy: 0.8322 - precision: 0.6700 - recall: 0.7882 - gen_confusion_matrix: 4.0000 - val_loss: 0.6772 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 21/40
19/19 - 48s - loss: 0.6152 - accuracy: 0.8651 - precision: 0.7340 - recall: 0.8118 - gen_confusion_matrix: 4.0000 - val_loss: 0.6772 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.3730469365546014e-05.
Epoch 22/40
19/19 - 48s - loss: 0.6142 - accuracy: 0.8289 - precision: 0.6514 - recall: 0.8353 - gen_confusion_matrix: 4.0000 - val_loss: 0.6757 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 23/40
19/19 - 48s - loss: 0.6091 - accuracy: 0.8750 - precision: 0.7640 - recall: 0.8000 - gen_confusion_matrix: 4.0000 - val_loss: 0.6752 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 24/40
19/19 - 48s - loss: 0.6109 - accuracy: 0.8289 - precision: 0.6410 - recall: 0.8824 - gen_confusion_matrix: 4.0000 - val_loss: 0.6748 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 25/40
19/19 - 50s - loss: 0.6108 - accuracy: 0.8586 - precision: 0.7500 - recall: 0.7412 - gen_confusion_matrix: 4.0000 - val_loss: 0.6735 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.7797852706280537e-05.
Epoch 26/40
19/19 - 48s - loss: 0.6078 - accuracy: 0.8553 - precision: 0.7071 - recall: 0.8235 - gen_confusion_matrix: 4.0000 - val_loss: 0.6728 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 27/40
19/19 - 48s - loss: 0.6095 - accuracy: 0.8586 - precision: 0.7561 - recall: 0.7294 - gen_confusion_matrix: 4.0000 - val_loss: 0.6736 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 28/40
19/19 - 48s - loss: 0.6076 - accuracy: 0.8717 - precision: 0.7255 - recall: 0.8706 - gen_confusion_matrix: 4.0000 - val_loss: 0.6732 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[50 1]
 [24 0]]
Epoch 29/40
19/19 - 50s - loss: 0.6062 - accuracy: 0.8750 - precision: 0.7374 - recall: 0.8588 - gen_confusion_matrix: 4.0000 - val_loss: 0.6740 - val_accuracy: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[50 1]
 [23 1]]

Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.3348389529710403e-05.
Epoch 30/40
19/19 - 49s - loss: 0.6056 - accuracy: 0.8651 - precision: 0.7075 - recall: 0.8824 - gen_confusion_matrix: 4.0000 - val_loss: 0.6739 - val_accuracy: 0.6800 - val_precision: 0.5000 - val_recall: 0.0417 - val_gen_confusion_matrix: 18.7500
[[50 1]
 [23 1]]
Epoch 31/40
19/19 - 48s - loss: 0.6035 - accuracy: 0.8914 - precision: 0.7766 - recall: 0.8588 - gen_confusion_matrix: 4.0000 - val_loss: 0.6732 - val_accuracy: 0.6800 - val_precision: 0.5000 - val_recall: 0.0417 - val_gen_confusion_matrix: 18.7500
[[50 1]
 [21 3]]
Epoch 32/40
19/19 - 49s - loss: 0.6040 - accuracy: 0.8783 - precision: 0.7264 - recall: 0.9059 - gen_confusion_matrix: 4.0000 - val_loss: 0.6747 - val_accuracy: 0.7067 - val_precision: 0.7500 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[49 2]
 [21 3]]
Epoch 33/40
19/19 - 47s - loss: 0.6040 - accuracy: 0.8914 - precision: 0.7826 - recall: 0.8471 - gen_confusion_matrix: 4.0000 - val_loss: 0.6733 - val_accuracy: 0.6933 - val_precision: 0.6000 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[48 3]
 [21 3]]
Epoch 34/40
19/19 - 49s - loss: 0.6068 - accuracy: 0.8487 - precision: 0.6789 - recall: 0.8706 - gen_confusion_matrix: 4.0000 - val_loss: 0.6760 - val_accuracy: 0.6800 - val_precision: 0.5000 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[48 3]
 [21 3]]
Epoch 35/40
19/19 - 49s - loss: 0.6011 - accuracy: 0.9013 - precision: 0.8395 - recall: 0.8000 - gen_confusion_matrix: 4.0000 - val_loss: 0.6753 - val_accuracy: 0.6800 - val_precision: 0.5000 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[47 4]
 [21 3]]
Epoch 36/40
19/19 - 48s - loss: 0.6014 - accuracy: 0.8849 - precision: 0.7604 - recall: 0.8588 - gen_confusion_matrix: 4.0000 - val_loss: 0.6755 - val_accuracy: 0.6667 - val_precision: 0.4286 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[45 6]
 [17 7]]

Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0011292488343315e-05.
Epoch 37/40
19/19 - 49s - loss: 0.5988 - accuracy: 0.8849 - precision: 0.7604 - recall: 0.8588 - gen_confusion_matrix: 4.0000 - val_loss: 0.6785 - val_accuracy: 0.6933 - val_precision: 0.5385 - val_recall: 0.2917 - val_gen_confusion_matrix: 18.7500
[[42 9]
 [17 7]]
Epoch 38/40
19/19 - 48s - loss: 0.6016 - accuracy: 0.8882 - precision: 0.8000 - recall: 0.8000 - gen_confusion_matrix: 4.0000 - val_loss: 0.6791 - val_accuracy: 0.6533 - val_precision: 0.4375 - val_recall: 0.2917 - val_gen_confusion_matrix: 18.7500
[[39 12]
 [15 9]]
Epoch 39/40
19/19 - 50s - loss: 0.5992 - accuracy: 0.8849 - precision: 0.7500 - recall: 0.8824 - gen_confusion_matrix: 4.0000 - val_loss: 0.6864 - val_accuracy: 0.6400 - val_precision: 0.4286 - val_recall: 0.3750 - val_gen_confusion_matrix: 18.7500
[[39 12]
 [16 8]]
Epoch 40/40
19/19 - 49s - loss: 0.6002 - accuracy: 0.8947 - precision: 0.7978 - recall: 0.8353 - gen_confusion_matrix: 4.0000 - val_loss: 0.6862 - val_accuracy: 0.6267 - val_precision: 0.4000 - val_recall: 0.3333 - val_gen_confusion_matrix: 18.7500

Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.508469025196973e-06.

 See logs at ../../cache/conv___04_1553___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___multi_with_add___2079/logs/
Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2049
Description:  test
2021-04-13 01:21:27.318439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:21:29.319667: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-13 01:21:29.320641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-13 01:21:29.372819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.373531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-13 01:21:29.373559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:21:29.377015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:21:29.377093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:21:29.378218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-13 01:21:29.378522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-13 01:21:29.379552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-13 01:21:29.380427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-13 01:21:29.380598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:21:29.380707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.381435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.382140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-13 01:21:29.384429: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-13 01:21:29.384614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.385309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-13 01:21:29.385336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:21:29.385365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:21:29.385380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:21:29.385394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-13 01:21:29.385408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-13 01:21:29.385434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-13 01:21:29.385448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-13 01:21:29.385462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:21:29.385529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.386208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:29.386900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-13 01:21:29.386936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-13 01:21:30.100107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-13 01:21:30.100153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-13 01:21:30.100162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-13 01:21:30.100444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:30.101244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:30.101946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-13 01:21:30.102611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-04-13 01:21:30.466895: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-13 01:21:30.466932: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-13 01:21:30.466967: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-13 01:21:30.467163: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-13 01:21:30.468050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-13 01:21:30.661448: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-13 01:21:30.664045: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-13 01:21:31.184185: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-13 01:21:31.185814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-13 01:21:32.488587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-13 01:21:32.891461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-13 01:21:32.898648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-13 01:21:35.586307: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-13 01:21:35.586346: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-13 01:21:36.197276: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-13 01:21:36.200808: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-13 01:21:36.253889: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 1452 callback api events and 1448 activity events. 
2021-04-13 01:21:36.290582: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0532s vs `on_train_batch_begin` time: 0.0909s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0532s vs `on_train_batch_end` time: 0.0577s). Check your callbacks.
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2049.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_0121___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___test___2049/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.0001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0.4}
Learning Rate Parameters: {'factor': 0.75, 'patience': 4, 'min_lr': 1e-05}
Early Stopping Patience and Delta: 15, 1.0%
-----------------------
Size of training set: 4316
Size of validation set: 1078
Initializing weights...
weights = {0: 0.6776381909547738, 1: 1.9073550212164074}
Model: "other"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 128, 1250, 3) 12          input_3[0][0]                    
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 1250, 16 64          batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 128, 1250, 16 64          batch_normalization_12[0][0]     
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 1250, 3) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 128, 1250, 16 2320        conv2d_19[0][0]                  
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 128, 1250, 16 6416        conv2d_21[0][0]                  
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 128, 1250, 16 64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 1250, 48 0           conv2d_20[0][0]                  
                                                                 conv2d_22[0][0]                  
                                                                 conv2d_23[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 64, 625, 48)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 625, 48)  192         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 64, 625, 48)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
inverted_residual_10 (InvertedR (None, 64, 625, 32)  35840       dropout_10[0][0]                 
__________________________________________________________________________________________________
inverted_residual_11 (InvertedR (None, 64, 625, 32)  20864       inverted_residual_10[0][0]       
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 32, 312, 32)  0           inverted_residual_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 312, 32)  128         average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 32, 312, 32)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
inverted_residual_12 (InvertedR (None, 32, 312, 64)  27136       dropout_11[0][0]                 
__________________________________________________________________________________________________
inverted_residual_13 (InvertedR (None, 32, 312, 64)  66304       inverted_residual_12[0][0]       
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 16, 156, 64)  0           inverted_residual_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 156, 64)  256         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 16, 156, 64)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
inverted_residual_14 (InvertedR (None, 16, 156, 128) 91136       dropout_12[0][0]                 
__________________________________________________________________________________________________
inverted_residual_15 (InvertedR (None, 16, 156, 128) 230912      inverted_residual_14[0][0]       
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 8, 78, 128)   0           inverted_residual_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 78, 128)   512         average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 8, 78, 128)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
inverted_residual_16 (InvertedR (None, 8, 78, 256)   329728      dropout_13[0][0]                 
__________________________________________________________________________________________________
inverted_residual_17 (InvertedR (None, 8, 78, 256)   855040      inverted_residual_16[0][0]       
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 4, 39, 256)   0           inverted_residual_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 4, 39, 256)   1024        average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 4, 39, 256)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
inverted_residual_18 (InvertedR (None, 4, 39, 512)   1249280     dropout_14[0][0]                 
__________________________________________________________________________________________________
inverted_residual_19 (InvertedR (None, 4, 39, 512)   3282944     inverted_residual_18[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 512)          0           inverted_residual_19[0][0]       
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 6,200,749
Trainable params: 6,159,239
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
270/270 - 216s - loss: 0.7295 - accuracy: 0.5317 - val_loss: 0.6997 - val_accuracy: 0.2746
Epoch 2/40
270/270 - 213s - loss: 0.6939 - accuracy: 0.5677 - val_loss: 0.7015 - val_accuracy: 0.2755
Epoch 3/40
270/270 - 213s - loss: 0.6875 - accuracy: 0.5843 - val_loss: 0.6718 - val_accuracy: 0.7254
Epoch 4/40
270/270 - 212s - loss: 0.6869 - accuracy: 0.5843 - val_loss: 0.6694 - val_accuracy: 0.7078
Epoch 5/40
270/270 - 212s - loss: 0.6781 - accuracy: 0.6033 - val_loss: 0.6709 - val_accuracy: 0.6596
Epoch 6/40
270/270 - 212s - loss: 0.6773 - accuracy: 0.6223 - val_loss: 0.6716 - val_accuracy: 0.6920
Epoch 7/40
270/270 - 213s - loss: 0.6731 - accuracy: 0.6103 - val_loss: 0.6576 - val_accuracy: 0.7161

Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-05.
Epoch 8/40
270/270 - 215s - loss: 0.6662 - accuracy: 0.6404 - val_loss: 0.7026 - val_accuracy: 0.5965
Epoch 9/40
270/270 - 213s - loss: 0.6598 - accuracy: 0.6842 - val_loss: 0.6773 - val_accuracy: 0.6967
Epoch 10/40
270/270 - 213s - loss: 0.6574 - accuracy: 0.6777 - val_loss: 0.6770 - val_accuracy: 0.6577
Epoch 11/40
270/270 - 213s - loss: 0.6520 - accuracy: 0.6949 - val_loss: 0.6607 - val_accuracy: 0.6967

Epoch 00011: ReduceLROnPlateau reducing learning rate to 5.6249997214763425e-05.
Epoch 12/40
270/270 - 212s - loss: 0.6389 - accuracy: 0.7076 - val_loss: 0.6753 - val_accuracy: 0.6939
Epoch 13/40
270/270 - 212s - loss: 0.6302 - accuracy: 0.7396 - val_loss: 0.6576 - val_accuracy: 0.7319
Epoch 14/40
270/270 - 212s - loss: 0.6242 - accuracy: 0.7572 - val_loss: 0.6603 - val_accuracy: 0.7440
Epoch 15/40
270/270 - 213s - loss: 0.6152 - accuracy: 0.7806 - val_loss: 0.6476 - val_accuracy: 0.7523
Epoch 16/40
270/270 - 210s - loss: 0.6099 - accuracy: 0.7968 - val_loss: 0.6726 - val_accuracy: 0.6902
Epoch 17/40
270/270 - 212s - loss: 0.6021 - accuracy: 0.8146 - val_loss: 0.6433 - val_accuracy: 0.7607
Epoch 18/40
270/270 - 212s - loss: 0.5933 - accuracy: 0.8299 - val_loss: 0.6786 - val_accuracy: 0.7189
Epoch 19/40
270/270 - 212s - loss: 0.5892 - accuracy: 0.8443 - val_loss: 0.6912 - val_accuracy: 0.7607
Epoch 20/40
270/270 - 213s - loss: 0.5850 - accuracy: 0.8503 - val_loss: 0.6765 - val_accuracy: 0.7597
Epoch 21/40
270/270 - 206s - loss: 0.5794 - accuracy: 0.8747 - val_loss: 0.6688 - val_accuracy: 0.7403

Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.218749927531462e-05.
Epoch 22/40
270/270 - 206s - loss: 0.5742 - accuracy: 0.8809 - val_loss: 0.6816 - val_accuracy: 0.6781
Epoch 23/40
270/270 - 207s - loss: 0.5696 - accuracy: 0.8902 - val_loss: 0.7236 - val_accuracy: 0.6243
Epoch 24/40
270/270 - 208s - loss: 0.5677 - accuracy: 0.8948 - val_loss: 0.6658 - val_accuracy: 0.7449
Epoch 25/40
270/270 - 207s - loss: 0.5624 - accuracy: 0.9133 - val_loss: 0.6638 - val_accuracy: 0.7597

Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.164062582072802e-05.
Epoch 26/40
270/270 - 206s - loss: 0.5613 - accuracy: 0.9078 - val_loss: 0.6701 - val_accuracy: 0.7690
Epoch 27/40
270/270 - 205s - loss: 0.5615 - accuracy: 0.9092 - val_loss: 0.6594 - val_accuracy: 0.7273
Epoch 28/40
270/270 - 206s - loss: 0.5589 - accuracy: 0.9136 - val_loss: 0.6580 - val_accuracy: 0.7644
Epoch 29/40
270/270 - 207s - loss: 0.5574 - accuracy: 0.9194 - val_loss: 0.6533 - val_accuracy: 0.7625
Epoch 30/40
270/270 - 206s - loss: 0.5573 - accuracy: 0.9226 - val_loss: 0.6782 - val_accuracy: 0.7644

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.3730469365546014e-05.
Epoch 31/40
270/270 - 209s - loss: 0.5556 - accuracy: 0.9224 - val_loss: 0.6524 - val_accuracy: 0.7727
Epoch 32/40
270/270 - 207s - loss: 0.5519 - accuracy: 0.9377 - val_loss: 0.6583 - val_accuracy: 0.7690
Epoch 33/40
270/270 - 208s - loss: 0.5529 - accuracy: 0.9307 - val_loss: 0.6569 - val_accuracy: 0.7699
Epoch 34/40
270/270 - 206s - loss: 0.5518 - accuracy: 0.9316 - val_loss: 0.6598 - val_accuracy: 0.7495
Epoch 35/40
270/270 - 207s - loss: 0.5542 - accuracy: 0.9314 - val_loss: 0.6594 - val_accuracy: 0.7737
Epoch 36/40
270/270 - 207s - loss: 0.5503 - accuracy: 0.9421 - val_loss: 0.6590 - val_accuracy: 0.7579
Epoch 37/40
270/270 - 206s - loss: 0.5518 - accuracy: 0.9321 - val_loss: 0.6555 - val_accuracy: 0.7254
Epoch 38/40
270/270 - 206s - loss: 0.5499 - accuracy: 0.9407 - val_loss: 0.6540 - val_accuracy: 0.7468
Epoch 39/40
270/270 - 206s - loss: 0.5486 - accuracy: 0.9472 - val_loss: 0.6509 - val_accuracy: 0.7607

Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.7797852706280537e-05.
Epoch 40/40
270/270 - 207s - loss: 0.5488 - accuracy: 0.9435 - val_loss: 0.6511 - val_accuracy: 0.7727

 See logs at ../../cache/conv___04_0121___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___test___2049/logs/
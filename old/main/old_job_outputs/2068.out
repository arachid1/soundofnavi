Category:  mel
Dataset:  all_sw_mel_preprocessed_v2_param_v30_augm_v0_cleaned_8000.pkl
File:  conv.train2068
Description:  multi_mel
2021-04-19 13:07:21.487175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 13:07:23.392798: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-19 13:07:23.393744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-19 13:07:23.447253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.447970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-19 13:07:23.447997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 13:07:23.451595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 13:07:23.451666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 13:07:23.452774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-19 13:07:23.453060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-19 13:07:23.454107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-19 13:07:23.455007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-19 13:07:23.455180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 13:07:23.455285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.456051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.456726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-19 13:07:23.458746: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-19 13:07:23.458938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.459727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-19 13:07:23.459757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 13:07:23.459790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 13:07:23.459810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 13:07:23.459829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-19 13:07:23.459847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-19 13:07:23.459896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-19 13:07:23.459914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-19 13:07:23.459931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 13:07:23.460009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.460706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:23.461430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-19 13:07:23.461470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-19 13:07:24.165120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-19 13:07:24.165167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-19 13:07:24.165176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-19 13:07:24.165451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:24.166264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:24.166982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-19 13:07:24.167672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2021-04-19 13:07:59.734373: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-19 13:07:59.734425: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-19 13:07:59.734461: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-19 13:07:59.734676: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-19 13:07:59.735594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-19 13:07:59.905217: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-19 13:07:59.907706: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2068.py
Using train_file located at ../../data/datasets/all_sw_mel_preprocessed_v2_param_v30_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_1303___all_sw_mel_preprocessed_v2_param_v30_augm_v0_cleaned_8000___multi_mel___2068/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 4, 'LR': 1e-05, 'SHAPE': (1, 128, 313), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.75, 'patience': 6, 'min_lr': 1e-08}
Early Stopping Patience and Delta: 22, 1.0%
-----------------------
Original number of folders: 453
here
here
here
Number of 1-indexed chunks: 1737
Actual number of folders: 379
Size of training set: 304
Size of validation set: 75
[[ 0 51]
 [ 1 24]]
Initializing weights...
weights = {0: 0.7018518518518518, 1: 1.738532110091743}
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            [(None, 1, 128, 313) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 8, 128, 313)  80          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 8, 128, 313)  80          input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 8, 128, 313)  80          input_3[0][0]                    
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 128, 313)  80          input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 128, 313)  80          input_5[0][0]                    
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 128, 313)  80          input_6[0][0]                    
__________________________________________________________________________________________________
mix_depth_group_convolution2d ( (None, 8, 128, 313)  1080        conv2d[0][0]                     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_5 (None, 8, 128, 313)  1080        conv2d_5[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 313)  1080        conv2d_10[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 8, 128, 313)  1080        conv2d_15[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 313)  1080        conv2d_20[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 8, 128, 313)  1080        conv2d_25[0][0]                  
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 8, 64, 157)   0           mix_depth_group_convolution2d[0][
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 8, 64, 157)   0           mix_depth_group_convolution2d_5[0
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 8, 64, 157)   0           mix_depth_group_convolution2d_10[
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 8, 64, 157)   0           mix_depth_group_convolution2d_15[
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 8, 64, 157)   0           mix_depth_group_convolution2d_20[
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 8, 64, 157)   0           mix_depth_group_convolution2d_25[
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 8, 64, 157)   628         average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 64, 157)   628         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 64, 157)   628         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 64, 157)   628         average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 64, 157)   628         average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 64, 157)   628         average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 64, 157)  1168        batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 64, 157)  1168        batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 64, 157)  1168        batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 64, 157)  1168        batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 64, 157)  1168        batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 64, 157)  1168        batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 157)  2160        conv2d_1[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_6 (None, 16, 64, 157)  2160        conv2d_6[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 157)  2160        conv2d_11[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 16, 64, 157)  2160        conv2d_16[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 157)  2160        conv2d_21[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 16, 64, 157)  2160        conv2d_26[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_1[0
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_6[0
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_11[
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_16[
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_21[
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 16, 32, 79)   0           mix_depth_group_convolution2d_26[
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 32, 79)   316         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16, 32, 79)   316         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 32, 79)   316         average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 32, 79)   316         average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 32, 79)   316         average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 32, 79)   316         average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 79)   4640        batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 79)   4640        batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 79)   4640        batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 79)   4640        batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 79)   4640        batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 32, 32, 79)   4640        batch_normalization_26[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 79)   4320        conv2d_2[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_7 (None, 32, 32, 79)   4320        conv2d_7[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 79)   4320        conv2d_12[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 32, 32, 79)   4320        conv2d_17[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 79)   4320        conv2d_22[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 32, 32, 79)   4320        conv2d_27[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_2[0
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_7[0
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_12[
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_17[
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_22[
__________________________________________________________________________________________________
average_pooling2d_27 (AveragePo (None, 32, 16, 40)   0           mix_depth_group_convolution2d_27[
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 40)   160         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 16, 40)   160         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 16, 40)   160         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 16, 40)   160         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 16, 40)   160         average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 32, 16, 40)   160         average_pooling2d_27[0][0]       
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 16, 40)   18496       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 64, 16, 40)   18496       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 16, 40)   18496       batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 64, 16, 40)   18496       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 64, 16, 40)   18496       batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 64, 16, 40)   18496       batch_normalization_27[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_3 (None, 64, 16, 40)   8640        conv2d_3[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_8 (None, 64, 16, 40)   8640        conv2d_8[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 40)   8640        conv2d_13[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 64, 16, 40)   8640        conv2d_18[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 40)   8640        conv2d_23[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 64, 16, 40)   8640        conv2d_28[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_3[0
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_8[0
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_13[
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_18[
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_23[
__________________________________________________________________________________________________
average_pooling2d_28 (AveragePo (None, 64, 8, 20)    0           mix_depth_group_convolution2d_28[
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 64, 8, 20)    80          average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 8, 20)    80          average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 64, 8, 20)    80          average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 64, 8, 20)    80          average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 64, 8, 20)    80          average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 64, 8, 20)    80          average_pooling2d_28[0][0]       
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 8, 20)   73856       batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 128, 8, 20)   73856       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 8, 20)   73856       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 128, 8, 20)   73856       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 128, 8, 20)   73856       batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 128, 8, 20)   73856       batch_normalization_28[0][0]     
__________________________________________________________________________________________________
mix_depth_group_convolution2d_4 (None, 128, 8, 20)   17280       conv2d_4[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_9 (None, 128, 8, 20)   17280       conv2d_9[0][0]                   
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 20)   17280       conv2d_14[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_1 (None, 128, 8, 20)   17280       conv2d_19[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 20)   17280       conv2d_24[0][0]                  
__________________________________________________________________________________________________
mix_depth_group_convolution2d_2 (None, 128, 8, 20)   17280       conv2d_29[0][0]                  
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_4[0
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_9[0
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_14[
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_19[
__________________________________________________________________________________________________2021-04-19 13:08:01.879071: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-19 13:08:01.879947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-19 13:08:10.344248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-19 13:08:10.774793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-19 13:08:10.795303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-19 13:08:12.832924: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-19 13:08:12.832972: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-19 13:08:13.608060: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-19 13:08:13.612564: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-19 13:08:13.659280: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 2453 callback api events and 2449 activity events. 
2021-04-19 13:08:13.731916: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1335s vs `on_train_batch_end` time: 0.1423s). Check your callbacks.
[[51 0]
 [24 0]]

average_pooling2d_24 (AveragePo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_24[
__________________________________________________________________________________________________
average_pooling2d_29 (AveragePo (None, 128, 4, 10)   0           mix_depth_group_convolution2d_29[
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 4, 10)   40          average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 128, 4, 10)   40          average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 128, 4, 10)   40          average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 128, 4, 10)   40          average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 128, 4, 10)   40          average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 128, 4, 10)   40          average_pooling2d_29[0][0]       
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 128)          0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 128)          0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 128)          0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 128)          0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 128)          0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 768)          0           global_average_pooling2d[0][0]   
                                                                 global_average_pooling2d_1[0][0] 
                                                                 global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense (Dense)                   (None, 32)           24608       concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      
==================================================================================================
Total params: 822,305
Trainable params: 818,633
Non-trainable params: 3,672
__________________________________________________________________________________________________
Epoch 1/40
76/76 - 30s - loss: 0.6989 - accuracy: 0.5757 - precision: 0.2556 - recall: 0.2706 - gen_confusion_matrix: 1.1218 - val_loss: 0.6912 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 2/40
76/76 - 16s - loss: 0.6936 - accuracy: 0.6217 - precision: 0.2917 - recall: 0.2471 - gen_confusion_matrix: 1.1095 - val_loss: 0.6884 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 3/40
76/76 - 16s - loss: 0.6927 - accuracy: 0.4934 - precision: 0.2621 - recall: 0.4471 - gen_confusion_matrix: 1.0975 - val_loss: 0.6852 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 4/40
76/76 - 16s - loss: 0.6892 - accuracy: 0.5164 - precision: 0.2754 - recall: 0.4471 - gen_confusion_matrix: 1.0629 - val_loss: 0.6802 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 5/40
76/76 - 16s - loss: 0.6841 - accuracy: 0.5197 - precision: 0.3007 - recall: 0.5412 - gen_confusion_matrix: 1.0305 - val_loss: 0.6753 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 6/40
76/76 - 16s - loss: 0.6894 - accuracy: 0.5691 - precision: 0.2745 - recall: 0.3294 - gen_confusion_matrix: 1.0975 - val_loss: 0.6683 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 7/40
76/76 - 16s - loss: 0.6799 - accuracy: 0.5066 - precision: 0.3099 - recall: 0.6235 - gen_confusion_matrix: 1.0411 - val_loss: 0.6597 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]

Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.
Epoch 8/40
76/76 - 16s - loss: 0.6761 - accuracy: 0.6645 - precision: 0.3333 - recall: 0.2000 - gen_confusion_matrix: 1.0975 - val_loss: 0.6551 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[51 0]
 [24 0]]
Epoch 9/40
76/76 - 16s - loss: 0.6742 - accuracy: 0.4507 - precision: 0.2950 - recall: 0.6941 - gen_confusion_matrix: 1.0742 - val_loss: 0.6404 - val_accuracy: 0.6800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_gen_confusion_matrix: 18.7500
[[37 14]
 [17 7]]
Epoch 10/40
76/76 - 16s - loss: 0.6794 - accuracy: 0.6184 - precision: 0.3086 - recall: 0.2941 - gen_confusion_matrix: 1.1218 - val_loss: 0.6816 - val_accuracy: 0.5867 - val_precision: 0.3333 - val_recall: 0.2917 - val_gen_confusion_matrix: 18.7500
[[43 8]
 [20 4]]
Epoch 11/40
76/76 - 16s - loss: 0.6705 - accuracy: 0.6743 - precision: 0.4286 - recall: 0.4941 - gen_confusion_matrix: 1.0305 - val_loss: 0.6676 - val_accuracy: 0.6267 - val_precision: 0.3333 - val_recall: 0.1667 - val_gen_confusion_matrix: 18.7500
[[44 7]
 [21 3]]
Epoch 12/40
76/76 - 16s - loss: 0.6717 - accuracy: 0.6480 - precision: 0.4000 - recall: 0.5176 - gen_confusion_matrix: 1.0629 - val_loss: 0.6573 - val_accuracy: 0.6267 - val_precision: 0.3000 - val_recall: 0.1250 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [9 15]]
Epoch 13/40
76/76 - 16s - loss: 0.6690 - accuracy: 0.6842 - precision: 0.4337 - recall: 0.4235 - gen_confusion_matrix: 1.1218 - val_loss: 0.6896 - val_accuracy: 0.5467 - val_precision: 0.3750 - val_recall: 0.6250 - val_gen_confusion_matrix: 18.7500
[[22 29]
 [5 19]]

Epoch 00013: ReduceLROnPlateau reducing learning rate to 5.624999857900548e-06.
Epoch 14/40
76/76 - 16s - loss: 0.6641 - accuracy: 0.6678 - precision: 0.4259 - recall: 0.5412 - gen_confusion_matrix: 1.0201 - val_loss: 0.6942 - val_accuracy: 0.5467 - val_precision: 0.3958 - val_recall: 0.7917 - val_gen_confusion_matrix: 18.7500
[[38 13]
 [18 6]]
Epoch 15/40
76/76 - 16s - loss: 0.6610 - accuracy: 0.5855 - precision: 0.3772 - recall: 0.7412 - gen_confusion_matrix: 1.0305 - val_loss: 0.6664 - val_accuracy: 0.5867 - val_precision: 0.3158 - val_recall: 0.2500 - val_gen_confusion_matrix: 18.7500
[[25 26]
 [9 15]]
Epoch 16/40
76/76 - 16s - loss: 0.6609 - accuracy: 0.7171 - precision: 0.4889 - recall: 0.2588 - gen_confusion_matrix: 1.1343 - val_loss: 0.6910 - val_accuracy: 0.5333 - val_precision: 0.3659 - val_recall: 0.6250 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [11 13]]
Epoch 17/40
76/76 - 16s - loss: 0.6605 - accuracy: 0.6217 - precision: 0.3973 - recall: 0.6824 - gen_confusion_matrix: 1.0201 - val_loss: 0.6811 - val_accuracy: 0.5600 - val_precision: 0.3714 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[27 24]
 [11 13]]
Epoch 18/40
76/76 - 16s - loss: 0.6614 - accuracy: 0.6842 - precision: 0.4382 - recall: 0.4588 - gen_confusion_matrix: 1.0411 - val_loss: 0.6842 - val_accuracy: 0.5333 - val_precision: 0.3514 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [12 12]]
Epoch 19/40
76/76 - 16s - loss: 0.6582 - accuracy: 0.6316 - precision: 0.3969 - recall: 0.6118 - gen_confusion_matrix: 1.0201 - val_loss: 0.6804 - val_accuracy: 0.5467 - val_precision: 0.3529 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[31 20]
 [12 12]]

Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.2187500639556674e-06.
Epoch 20/40
76/76 - 16s - loss: 0.6579 - accuracy: 0.6711 - precision: 0.4312 - recall: 0.5529 - gen_confusion_matrix: 1.0305 - val_loss: 0.6778 - val_accuracy: 0.5733 - val_precision: 0.3750 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[23 28]
 [9 15]]
Epoch 21/40
76/76 - 16s - loss: 0.6550 - accuracy: 0.7039 - precision: 0.4706 - recall: 0.4706 - gen_confusion_matrix: 1.0857 - val_loss: 0.6929 - val_accuracy: 0.5067 - val_precision: 0.3488 - val_recall: 0.6250 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [10 14]]
Epoch 22/40
76/76 - 16s - loss: 0.6596 - accuracy: 0.6480 - precision: 0.4141 - recall: 0.6235 - gen_confusion_matrix: 1.0305 - val_loss: 0.6870 - val_accuracy: 0.5333 - val_precision: 0.3590 - val_recall: 0.5833 - val_gen_confusion_matrix: 18.7500
[[34 17]
 [14 10]]
Epoch 23/40
76/76 - 16s - loss: 0.6565 - accuracy: 0.6842 - precision: 0.4433 - recall: 0.5059 - gen_confusion_matrix: 1.0975 - val_loss: 0.6710 - val_accuracy: 0.5867 - val_precision: 0.3704 - val_recall: 0.4167 - val_gen_confusion_matrix: 18.7500
[[35 16]
 [16 8]]
Epoch 24/40
76/76 - 16s - loss: 0.6549 - accuracy: 0.6184 - precision: 0.3974 - recall: 0.7059 - gen_confusion_matrix: 1.0100 - val_loss: 0.6660 - val_accuracy: 0.5733 - val_precision: 0.3333 - val_recall: 0.3333 - val_gen_confusion_matrix: 18.7500
[[37 14]
 [17 7]]
Epoch 25/40
76/76 - 16s - loss: 0.6541 - accuracy: 0.6842 - precision: 0.4433 - recall: 0.5059 - gen_confusion_matrix: 1.0857 - val_loss: 0.6618 - val_accuracy: 0.5867 - val_precision: 0.3333 - val_recall: 0.2917 - val_gen_confusion_matrix: 18.7500
[[35 16]
 [15 9]]

Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.164062718497007e-06.
Epoch 26/40
76/76 - 17s - loss: 0.6553 - accuracy: 0.6546 - precision: 0.4107 - recall: 0.5412 - gen_confusion_matrix: 1.0305 - val_loss: 0.6682 - val_accuracy: 0.5867 - val_precision: 0.3600 - val_recall: 0.3750 - val_gen_confusion_matrix: 18.7500
[[27 24]
 [11 13]]
Epoch 27/40
76/76 - 17s - loss: 0.6574 - accuracy: 0.6974 - precision: 0.4639 - recall: 0.5294 - gen_confusion_matrix: 1.0975 - val_loss: 0.6827 - val_accuracy: 0.5333 - val_precision: 0.3514 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[31 20]
 [12 12]]
Epoch 28/40
76/76 - 18s - loss: 0.6556 - accuracy: 0.6875 - precision: 0.4528 - recall: 0.5647 - gen_confusion_matrix: 1.0519 - val_loss: 0.6729 - val_accuracy: 0.5733 - val_precision: 0.3750 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [9 15]]
Epoch 29/40
76/76 - 25s - loss: 0.6483 - accuracy: 0.6941 - precision: 0.4615 - recall: 0.5647 - gen_confusion_matrix: 1.0519 - val_loss: 0.6872 - val_accuracy: 0.5467 - val_precision: 0.3750 - val_recall: 0.6250 - val_gen_confusion_matrix: 18.7500
[[27 24]
 [11 13]]
Epoch 30/40
76/76 - 25s - loss: 0.6501 - accuracy: 0.6513 - precision: 0.4186 - recall: 0.6353 - gen_confusion_matrix: 1.0519 - val_loss: 0.6808 - val_accuracy: 0.5333 - val_precision: 0.3514 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[30 21]
 [12 12]]
Epoch 31/40
76/76 - 24s - loss: 0.6507 - accuracy: 0.6875 - precision: 0.4537 - recall: 0.5765 - gen_confusion_matrix: 1.0519 - val_loss: 0.6769 - val_accuracy: 0.5600 - val_precision: 0.3636 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [11 13]]

Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.3730470388727554e-06.
Epoch 32/40
76/76 - 25s - loss: 0.6519 - accuracy: 0.6612 - precision: 0.4286 - recall: 0.6353 - gen_confusion_matrix: 1.0305 - val_loss: 0.6813 - val_accuracy: 0.5200 - val_precision: 0.3421 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[29 22]
 [12 12]]
Epoch 33/40
76/76 - 25s - loss: 0.6475 - accuracy: 0.7105 - precision: 0.4851 - recall: 0.5765 - gen_confusion_matrix: 1.0519 - val_loss: 0.6769 - val_accuracy: 0.5467 - val_precision: 0.3529 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[27 24]
 [12 12]]
Epoch 34/40
76/76 - 25s - loss: 0.6532 - accuracy: 0.6612 - precision: 0.4297 - recall: 0.6471 - gen_confusion_matrix: 1.0411 - val_loss: 0.6798 - val_accuracy: 0.5200 - val_precision: 0.3333 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[30 21]
 [12 12]]
Epoch 35/40
76/76 - 21s - loss: 0.6470 - accuracy: 0.6875 - precision: 0.4561 - recall: 0.6118 - gen_confusion_matrix: 1.0629 - val_loss: 0.6767 - val_accuracy: 0.5600 - val_precision: 0.3636 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[28 23]
 [12 12]]
Epoch 36/40
76/76 - 16s - loss: 0.6446 - accuracy: 0.7039 - precision: 0.4775 - recall: 0.6235 - gen_confusion_matrix: 1.0519 - val_loss: 0.6778 - val_accuracy: 0.5333 - val_precision: 0.3429 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [12 12]]
Epoch 37/40
76/76 - 16s - loss: 0.6462 - accuracy: 0.6711 - precision: 0.4400 - recall: 0.6471 - gen_confusion_matrix: 1.0411 - val_loss: 0.6793 - val_accuracy: 0.5067 - val_precision: 0.3243 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [12 12]]

Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.7797852365220024e-06.
Epoch 38/40
76/76 - 16s - loss: 0.6476 - accuracy: 0.7138 - precision: 0.4886 - recall: 0.5059 - gen_confusion_matrix: 1.0519 - val_loss: 0.6810 - val_accuracy: 0.5067 - val_precision: 0.3243 - val_recall: 0.5000 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [11 13]]
Epoch 39/40
76/76 - 16s - loss: 0.6486 - accuracy: 0.6645 - precision: 0.4309 - recall: 0.6235 - gen_confusion_matrix: 1.0305 - val_loss: 0.6838 - val_accuracy: 0.5200 - val_precision: 0.3421 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500
[[26 25]
 [11 13]]
Epoch 40/40
76/76 - 16s - loss: 0.6452 - accuracy: 0.6941 - precision: 0.4630 - recall: 0.5882 - gen_confusion_matrix: 1.0411 - val_loss: 0.6834 - val_accuracy: 0.5200 - val_precision: 0.3421 - val_recall: 0.5417 - val_gen_confusion_matrix: 18.7500

 See logs at ../../cache/conv___04_1303___all_sw_mel_preprocessed_v2_param_v30_augm_v0_cleaned_8000___multi_mel___2068/logs/
Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2077
Description:  redo_classic_mod9_from2049
2021-04-22 11:25:19.493351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-22 11:25:21.690938: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-22 11:25:21.692000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-04-22 11:25:21.745745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.746510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-22 11:25:21.746543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-22 11:25:21.750325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-22 11:25:21.750433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-22 11:25:21.751681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-22 11:25:21.752031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-22 11:25:21.753010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-22 11:25:21.753893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-22 11:25:21.754056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-22 11:25:21.754211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.755009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.755740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-22 11:25:21.757881: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-04-22 11:25:21.758095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.758837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-04-22 11:25:21.758861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-22 11:25:21.758892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-22 11:25:21.758906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-22 11:25:21.758920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-04-22 11:25:21.758933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-04-22 11:25:21.758957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-04-22 11:25:21.758971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-04-22 11:25:21.758984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-22 11:25:21.759059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.759856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:21.760558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-04-22 11:25:21.760602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-04-22 11:25:22.534430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-22 11:25:22.534476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-04-22 11:25:22.534485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-04-22 11:25:22.534735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:22.535567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:22.536280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-04-22 11:25:22.536962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-04-22 11:25:22.933214: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-22 11:25:22.933270: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-22 11:25:22.933314: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-04-22 11:25:22.933614: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-04-22 11:25:22.934741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-04-22 11:25:23.173703: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-04-22 11:25:23.176272: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2077.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___04_1125___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___redo_classic_mod9_from2049___2077/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.0001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0.4}
Learning Rate Parameters: {'factor': 0.75, 'patience': 4, 'min_lr': 1e-08}
Early Stopping Patience and Delta: 25, 1.0%
-----------------------
Size of training set: 4316
Size of validation set: 1078
Initializing weights...
weights = {0: 0.6776381909547738, 1: 1.9073550212164074}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 3) 12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 3) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        2021-04-22 11:25:24.449065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-04-22 11:25:24.451473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-04-22 11:25:27.908950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-04-22 11:25:28.459052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-04-22 11:25:28.471342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-04-22 11:25:32.415299: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-04-22 11:25:32.415345: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-04-22 11:25:33.721058: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-04-22 11:25:33.724315: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-04-22 11:25:33.762056: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 1421 callback api events and 1417 activity events. 
2021-04-22 11:25:33.790589: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1119s vs `on_train_batch_end` time: 0.5661s). Check your callbacks.

__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            513         global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,200,749
Trainable params: 6,159,239
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
270/270 - 228s - loss: 0.7213 - accuracy: 0.5503 - val_loss: 0.6563 - val_accuracy: 0.7254
Epoch 2/40
270/270 - 216s - loss: 0.6986 - accuracy: 0.5609 - val_loss: 0.6565 - val_accuracy: 0.7254
Epoch 3/40
270/270 - 216s - loss: 0.6863 - accuracy: 0.5725 - val_loss: 0.6627 - val_accuracy: 0.7217
Epoch 4/40
270/270 - 216s - loss: 0.6833 - accuracy: 0.5864 - val_loss: 0.6799 - val_accuracy: 0.6456
Epoch 5/40
270/270 - 216s - loss: 0.6813 - accuracy: 0.6019 - val_loss: 0.6983 - val_accuracy: 0.5371

Epoch 00005: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-05.
Epoch 6/40
270/270 - 217s - loss: 0.6745 - accuracy: 0.6163 - val_loss: 0.6828 - val_accuracy: 0.6262
Epoch 7/40
270/270 - 216s - loss: 0.6728 - accuracy: 0.6284 - val_loss: 0.6711 - val_accuracy: 0.6308
Epoch 8/40
270/270 - 215s - loss: 0.6681 - accuracy: 0.6418 - val_loss: 0.6953 - val_accuracy: 0.7291
Epoch 9/40
270/270 - 217s - loss: 0.6645 - accuracy: 0.6585 - val_loss: 0.7501 - val_accuracy: 0.5455
Epoch 10/40
270/270 - 215s - loss: 0.6617 - accuracy: 0.6589 - val_loss: 0.6582 - val_accuracy: 0.6967
Epoch 11/40
270/270 - 217s - loss: 0.6518 - accuracy: 0.6893 - val_loss: 0.7102 - val_accuracy: 0.6169
Epoch 12/40
270/270 - 218s - loss: 0.6468 - accuracy: 0.7057 - val_loss: 0.7747 - val_accuracy: 0.4629

Epoch 00012: ReduceLROnPlateau reducing learning rate to 5.6249997214763425e-05.
Epoch 13/40
270/270 - 221s - loss: 0.6370 - accuracy: 0.7243 - val_loss: 0.7099 - val_accuracy: 0.6141
Epoch 14/40
270/270 - 217s - loss: 0.6263 - accuracy: 0.7509 - val_loss: 0.6827 - val_accuracy: 0.7078
Epoch 15/40
270/270 - 216s - loss: 0.6187 - accuracy: 0.7713 - val_loss: 0.7297 - val_accuracy: 0.5408
Epoch 16/40
270/270 - 217s - loss: 0.6104 - accuracy: 0.7908 - val_loss: 0.6977 - val_accuracy: 0.6280

Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.218749927531462e-05.
Epoch 17/40
270/270 - 222s - loss: 0.6042 - accuracy: 0.8056 - val_loss: 0.6936 - val_accuracy: 0.6401
Epoch 18/40
270/270 - 216s - loss: 0.5970 - accuracy: 0.8193 - val_loss: 0.6552 - val_accuracy: 0.7384
Epoch 19/40
270/270 - 216s - loss: 0.5916 - accuracy: 0.8348 - val_loss: 0.6693 - val_accuracy: 0.7059
Epoch 20/40
270/270 - 217s - loss: 0.5905 - accuracy: 0.8455 - val_loss: 0.6711 - val_accuracy: 0.7607
Epoch 21/40
270/270 - 218s - loss: 0.5860 - accuracy: 0.8547 - val_loss: 0.6641 - val_accuracy: 0.7458
Epoch 22/40
270/270 - 218s - loss: 0.5810 - accuracy: 0.8608 - val_loss: 0.6513 - val_accuracy: 0.7384
Epoch 23/40
270/270 - 223s - loss: 0.5783 - accuracy: 0.8737 - val_loss: 0.6647 - val_accuracy: 0.7059
Epoch 24/40
270/270 - 212s - loss: 0.5714 - accuracy: 0.8869 - val_loss: 0.6530 - val_accuracy: 0.7486

Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.164062582072802e-05.
Epoch 25/40
270/270 - 211s - loss: 0.5711 - accuracy: 0.8892 - val_loss: 0.6720 - val_accuracy: 0.7059
Epoch 26/40
270/270 - 211s - loss: 0.5676 - accuracy: 0.8955 - val_loss: 0.6695 - val_accuracy: 0.7783
Epoch 27/40
270/270 - 210s - loss: 0.5714 - accuracy: 0.8899 - val_loss: 0.6741 - val_accuracy: 0.6790
Epoch 28/40
270/270 - 210s - loss: 0.5687 - accuracy: 0.8985 - val_loss: 0.6428 - val_accuracy: 0.7542
Epoch 29/40
270/270 - 211s - loss: 0.5668 - accuracy: 0.8950 - val_loss: 0.6484 - val_accuracy: 0.7709
Epoch 30/40
270/270 - 211s - loss: 0.5655 - accuracy: 0.9062 - val_loss: 0.6445 - val_accuracy: 0.7681

Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.3730469365546014e-05.
Epoch 31/40
270/270 - 210s - loss: 0.5598 - accuracy: 0.9164 - val_loss: 0.6427 - val_accuracy: 0.7681
Epoch 32/40
270/270 - 209s - loss: 0.5614 - accuracy: 0.9131 - val_loss: 0.6432 - val_accuracy: 0.7653
Epoch 33/40
270/270 - 212s - loss: 0.5656 - accuracy: 0.9071 - val_loss: 0.6509 - val_accuracy: 0.7542
Epoch 34/40
270/270 - 211s - loss: 0.5587 - accuracy: 0.9173 - val_loss: 0.6395 - val_accuracy: 0.7764

Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.7797852706280537e-05.
Epoch 35/40
270/270 - 212s - loss: 0.5572 - accuracy: 0.9189 - val_loss: 0.6407 - val_accuracy: 0.7783
Epoch 36/40
270/270 - 211s - loss: 0.5581 - accuracy: 0.9208 - val_loss: 0.6491 - val_accuracy: 0.7495
Epoch 37/40
270/270 - 213s - loss: 0.5549 - accuracy: 0.9275 - val_loss: 0.6430 - val_accuracy: 0.7616
Epoch 38/40
270/270 - 212s - loss: 0.5542 - accuracy: 0.9300 - val_loss: 0.6361 - val_accuracy: 0.7839
Epoch 39/40
270/270 - 212s - loss: 0.5536 - accuracy: 0.9319 - val_loss: 0.6417 - val_accuracy: 0.7857
Epoch 40/40
270/270 - 214s - loss: 0.5572 - accuracy: 0.9222 - val_loss: 0.6419 - val_accuracy: 0.7644

 See logs at ../../cache/conv___04_1125___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___redo_classic_mod9_from2049___2077/logs/
Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2104
Description:  model9_newparams
2021-05-07 23:07:06.943379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-07 23:07:09.432037: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-07 23:07:09.432969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-07 23:07:09.483914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:09.484650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-07 23:07:09.484679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-07 23:07:09.488485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-07 23:07:09.488589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-07 23:07:09.491667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-07 23:07:09.491940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-07 23:07:09.492926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-07 23:07:09.493842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-07 23:07:09.494007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-07 23:07:09.494145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:09.494935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:09.495645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
wandb: Currently logged in as: arachid1 (use `wandb login --relogin` to force relogin)
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2104.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___05_2306___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___model9_newparams___2104/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.001, 'SHAPE': (128, 1250, 1), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.5, 'patience': 5, 'min_lr': 1e-10}
Early Stopping Patience and Delta: 20, 1.0%
Six: False and Concat: False
-----------------------
wandb: wandb version 0.10.30 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.29
wandb: Syncing run ethereal-wind-177
wandb: ⭐️ View project at https://wandb.ai/arachid1/tensorboard-integration
wandb: 🚀 View run at https://wandb.ai/arachid1/tensorboard-integration/runs/12ggutzn
wandb: Run data is saved locally in /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210507_230709-12ggutzn
wandb: Run `wandb offline` to turn off syncing.
2021-05-07 23:07:14.730352: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-07 23:07:14.730608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:14.731320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-07 23:07:14.731357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-07 23:07:14.731401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-07 23:07:14.731421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-07 23:07:14.731445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-07 23:07:14.731465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-07 23:07:14.731483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-07 23:07:14.731501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-07 23:07:14.731519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-07 23:07:14.731610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:14.732292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:14.732918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-07 23:07:14.732961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-07 23:07:15.451443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-07 23:07:15.451498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-05-07 23:07:15.451507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-05-07 23:07:15.451850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:15.452718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:15.453502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-07 23:07:15.454244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
2021-05-07 23:07:56.550732: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-07 23:07:56.552766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-05-07 23:08:00.123275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-07 23:08:00.916485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-07 23:08:00.924613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8

Original number of folders: 453
here
With concat = False and six = False, size of training set: 4196...
...and size of validation set: 1088
Initializing weights...
weights = {0: 0.7018518518518518, 1: 1.738532110091743}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 1 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 1) 4           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 32          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 32          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 1) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 32          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            513         global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,200,645
Trainable params: 6,159,139
Non-trainable params: 41,506
__________________________________________________________________________________________________
Epoch 1/30
263/263 - 537s - loss: 0.7469 - accuracy: 0.5808 - val_loss: 0.6106 - val_accuracy: 0.7996
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation f1: 33.38
Validation AUC: 0.26204000079071593
Validation class accuracies: [0.0, 1.0]
Epoch 2/30
263/263 - 525s - loss: 0.6859 - accuracy: 0.6151 - val_loss: 0.5232 - val_accuracy: 0.7996
Confusion matrix: 
 [[868   2]
 [218   0]]
Validation accuracy: 79.78
Validation recall: 0.00
Validation precision: 0.00
Validation f1: 0.00
Validation AUC: 0.2465059911373456
Validation class accuracies: [0.9977011494252873, 0.0]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 1 epochs
Epoch 3/30
263/263 - 523s - loss: 0.6832 - accuracy: 0.6184 - val_loss: 0.6954 - val_accuracy: 0.5211
Confusion matrix: 
 [[271 599]
 [ 68 150]]
Validation accuracy: 38.69
Validation recall: 68.81
Validation precision: 20.03
Validation f1: 31.02
Validation AUC: 0.20335577050733605
Validation class accuracies: [0.3114942528735632, 0.6880733944954128]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 2 epochs
Epoch 4/30
263/263 - 522s - loss: 0.6817 - accuracy: 0.5910 - val_loss: 1.1613 - val_accuracy: 0.7574
Confusion matrix: 
 [[501 369]
 [144  74]]
Validation accuracy: 52.85
Validation recall: 33.94
Validation precision: 16.70
Validation f1: 22.39
Validation AUC: 0.17012002805530518
Validation class accuracies: [0.5758620689655173, 0.3394495412844037]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 3 epochs
Epoch 5/30
263/263 - 521s - loss: 0.6774 - accuracy: 0.6041 - val_loss: 0.8322 - val_accuracy: 0.6434
Confusion matrix: 
 [[138 732]
 [ 26 192]]
Validation accuracy: 30.33
Validation recall: 88.07
Validation precision: 20.78
Validation f1: 33.63
Validation AUC: 0.24334453282317048
Validation class accuracies: [0.15862068965517243, 0.8807339449541285]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 4 epochs
Epoch 6/30
263/263 - 522s - loss: 0.6747 - accuracy: 0.5856 - val_loss: 0.6482 - val_accuracy: 0.6801
Confusion matrix: 
 [[321 549]
 [ 95 123]]
Validation accuracy: 40.81
Validation recall: 56.42
Validation precision: 18.30
Validation f1: 27.64
Validation AUC: 0.1928055752804341
Validation class accuracies: [0.3689655172413793, 0.5642201834862385]
Lr has been adjusted to 0.0005000000237487257
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 5 epochs
Epoch 7/30
263/263 - 522s - loss: 0.6694 - accuracy: 0.6053 - val_loss: 0.5660 - val_accuracy: 0.7408
Confusion matrix: 
 [[662 208]
 [148  70]]
Validation accuracy: 67.28
Validation recall: 32.11
Validation precision: 25.18
Validation f1: 28.23
Validation AUC: 0.2396118062274176
Validation class accuracies: [0.7609195402298851, 0.3211009174311927]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 6 epochs
Epoch 8/30
263/263 - 524s - loss: 0.6621 - accuracy: 0.5920 - val_loss: 0.6057 - val_accuracy: 0.7233
Confusion matrix: 
 [[506 364]
 [131  87]]
Validation accuracy: 54.50
Validation recall: 39.91
Validation precision: 19.29
Validation f1: 26.01
Validation AUC: 0.1875193162149532
Validation class accuracies: [0.5816091954022988, 0.39908256880733944]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 7 epochs
Epoch 9/30
263/263 - 523s - loss: 0.6568 - accuracy: 0.6018 - val_loss: 0.7103 - val_accuracy: 0.4577
Confusion matrix: 
 [[ 77 793]
 [ 37 181]]
Validation accuracy: 23.71
Validation recall: 83.03
Validation precision: 18.58
Validation f1: 30.37
Validation AUC: 0.1924819306065132
Validation class accuracies: [0.08850574712643679, 0.8302752293577982]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 8 epochs
Epoch 10/30
263/263 - 523s - loss: 0.6574 - accuracy: 0.6065 - val_loss: 0.7902 - val_accuracy: 0.4256
Confusion matrix: 
 [[ 67 803]
 [ 21 197]]
Validation accuracy: 24.26
Validation recall: 90.37
Validation precision: 19.70
Validation f1: 32.35
Validation AUC: 0.20570053975216335
Validation class accuracies: [0.07701149425287357, 0.9036697247706422]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 9 epochs
Epoch 11/30
263/263 - 524s - loss: 0.6519 - accuracy: 0.6122 - val_loss: 0.5582 - val_accuracy: 0.7509
Confusion matrix: 
 [[732 138]
 [180  38]]
Validation accuracy: 70.77
Validation recall: 17.43
Validation precision: 21.59
Validation f1: 19.29
Validation AUC: 0.2215198942591719
Validation class accuracies: [0.8413793103448276, 0.1743119266055046]
Lr has been adjusted to 0.0002500000118743628
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 10 epochs
Epoch 12/30
263/263 - 522s - loss: 0.6433 - accuracy: 0.6163 - val_loss: 0.6229 - val_accuracy: 0.7105
Confusion matrix: 
 [[409 461]
 [119  99]]
Validation accuracy: 46.69
Validation recall: 45.41
Validation precision: 17.68
Validation f1: 25.45
Validation AUC: 0.18085591908014995
Validation class accuracies: [0.47011494252873565, 0.4541284403669725]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 11 epochs
Epoch 13/30
263/263 - 523s - loss: 0.6378 - accuracy: 0.6246 - val_loss: 0.6479 - val_accuracy: 0.6204
Confusion matrix: 
 [[343 527]
 [ 93 125]]
Validation accuracy: 43.01
Validation recall: 57.34
Validation precision: 19.17
Validation f1: 28.74
Validation AUC: 0.18636296622955212
Validation class accuracies: [0.39425287356321836, 0.573394495412844]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 12 epochs
Epoch 14/30
263/263 - 522s - loss: 0.6266 - accuracy: 0.6373 - val_loss: 0.8001 - val_accuracy: 0.5156
Confusion matrix: 
 [[258 612]
 [ 59 159]]
Validation accuracy: 38.33
Validation recall: 72.94
Validation precision: 20.62
Validation f1: 32.15
Validation AUC: 0.1983116712570624
Validation class accuracies: [0.296551724137931, 0.7293577981651376]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 13 epochs
Epoch 15/30
263/263 - 524s - loss: 0.6242 - accuracy: 0.6568 - val_loss: 0.7414 - val_accuracy: 0.5487
Confusion matrix: 
 [[338 532]
 [ 67 151]]
Validation accuracy: 44.94
Validation recall: 69.27
Validation precision: 22.11
Validation f1: 33.52
Validation AUC: 0.21304756002747863
Validation class accuracies: [0.38850574712643676, 0.6926605504587156]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 14 epochs
Epoch 16/30
263/263 - 522s - loss: 0.6188 - accuracy: 0.6580 - val_loss: 0.6458 - val_accuracy: 0.6664
Confusion matrix: 
 [[468 402]
 [114 104]]
Validation accuracy: 52.57
Validation recall: 47.71
Validation precision: 20.55
Validation f1: 28.73
Validation AUC: 0.1936773299488977
Validation class accuracies: [0.5379310344827586, 0.47706422018348627]
Lr has been adjusted to 0.0001250000059371814
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 15 epochs
Epoch 17/30
263/263 - 523s - loss: 0.6009 - accuracy: 0.6702 - val_loss: 0.6594 - val_accuracy: 0.6461
Confusion matrix: 
 [[482 388]
 [103 115]]
Validation accuracy: 54.87
Validation recall: 52.75
Validation precision: 22.86
Validation f1: 31.90
Validation AUC: 0.21139738848014916
Validation class accuracies: [0.5540229885057472, 0.5275229357798165]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 16 epochs
Epoch 18/30
263/263 - 524s - loss: 0.6034 - accuracy: 0.6704 - val_loss: 0.7083 - val_accuracy: 0.6048
Confusion matrix: 
 [[371 499]
 [111 107]]
Validation accuracy: 43.93
Validation recall: 49.08
Validation precision: 17.66
Validation f1: 25.97
Validation AUC: 0.18790819829273686
Validation class accuracies: [0.4264367816091954, 0.4908256880733945]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 17 epochs
Epoch 19/30
263/263 - 522s - loss: 0.5895 - accuracy: 0.6761 - val_loss: 0.6933 - val_accuracy: 0.6425
Confusion matrix: 
 [[503 367]
 [132  86]]
Validation accuracy: 54.14
Validation recall: 39.45
Validation precision: 18.98
Validation f1: 25.63
Validation AUC: 0.19776263077317238
Validation class accuracies: [0.5781609195402299, 0.3944954128440367]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 18 epochs
Epoch 20/30
263/263 - 522s - loss: 0.5848 - accuracy: 0.6859 - val_loss: 0.8917 - val_accuracy: 0.4835
Confusion matrix: 
 [[298 572]
 [ 79 139]]
Validation accuracy: 40.17
Validation recall: 63.76
Validation precision: 19.55
Validation f1: 29.92
Validation AUC: 0.1982536074016512
Validation class accuracies: [0.3425287356321839, 0.6376146788990825]
The validation tracker metric at 0.333843797856049 hasn't increased by 0.01 in 19 epochs
Epoch 21/30
263/263 - 522s - loss: 0.5842 - accuracy: 0.6888 - val_loss: 0.6976 - val_accuracy: 0.6268
Confusion matrix: 
 [[464 406]
 [132  86]]
Validation accuracy: 50.55
Validation recall: 39.45
Validation precision: 17.48
Validation f1: 24.23
Validation AUC: 0.19149607392136891
Validation class accuracies: [0.5333333333333333, 0.3944954128440367]
Lr has been adjusted to 6.25000029685907e-05
The number of epochs since last 1% equals the patience
The metrics for the epoch with the best target metric are: 
Best f1: 0.3362521891418564
Best AUC: 0.24334453282317048
Best accuracy: 0.30330882352941174
Best precision: 0.2077922077922078
Best recall: 0.8807339449541285
Starting...
Accuracy (of 75 elements): 0.32
Ended. Saving the Excel Sheet ../../cache/conv___05_2306___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___model9_newparams___2104/validation_sheet.xls...
Done.
wandb: Waiting for W&B process to finish, PID 6864
wandb: Program ended successfully.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)
wandb: \ 0.02MB of 0.03MB uploaded (0.00MB deduped)
wandb: | 0.03MB of 0.03MB uploaded (0.00MB deduped)
wandb: / 0.03MB of 0.03MB uploaded (0.00MB deduped)
wandb: - 0.03MB of 0.03MB uploaded (0.00MB deduped)
wandb: \ 0.03MB of 0.03MB uploaded (0.00MB deduped)
wandb: | 0.03MB of 0.03MB uploaded (0.00MB deduped)
wandb:                                                                                
wandb: Find user logs for this run at: /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210507_230709-12ggutzn/logs/debug.log
wandb: Find internal logs for this run at: /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210507_230709-12ggutzn/logs/debug-internal.log
wandb: Run summary:
wandb:             _runtime 11512
wandb:           _timestamp 1620440341
wandb:                _step 167
wandb:       train_accuracy 0.68875
wandb:         val_accuracy 0.62684
wandb:           train_loss 0.58421
wandb:             val_loss 0.69761
wandb:           val_recall 0.3945
wandb:        val_precision 0.1748
wandb:               val_f1 0.24225
wandb:              val_auc 0.1915
wandb:                   lr 0.00013
wandb:          best_val_f1 0.33625
wandb:    best_val_accuracy 0.30331
wandb:   best_val_precision 0.20779
wandb:      best_val_recall 0.88073
wandb:             best_auc 0.24334
wandb: Run history:
wandb:         _runtime ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb:       _timestamp ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████
wandb:            _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:   train_accuracy ▁▃▃▂▃▁▃▂▂▃▃▃▄▅▆▆▇▇▇██
wandb:     val_accuracy ██▃▇▅▆▇▇▂▁▇▆▅▃▃▆▅▄▅▂▅
wandb:       train_loss █▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▁▁▁
wandb:         val_loss ▂▁▃█▄▂▁▂▃▄▁▂▂▄▃▂▂▃▃▅▃
wandb:       val_recall █▁▆▃▇▅▃▄▇▇▂▄▅▆▆▄▅▄▄▅▄
wandb:    val_precision ▇▁▇▆▇▆█▆▆▆▇▆▆▇▇▇▇▆▆▆▆
wandb:           val_f1 █▁▇▆█▇▇▆▇█▅▆▇██▇█▆▆▇▆
wandb:          val_auc █▇▄▁▇▃▆▂▃▄▅▂▂▃▄▃▄▂▃▃▃
wandb:               lr ██████▄▄▄▄▄▂▂▂▂▂▁▁▁▁▁
wandb: 
wandb: Synced 6 W&B file(s), 21 media file(s), 21 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ethereal-wind-177: https://wandb.ai/arachid1/tensorboard-integration/runs/12ggutzn


 See logs at ../../cache/conv___05_2306___all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000___model9_newparams___2104/logs/
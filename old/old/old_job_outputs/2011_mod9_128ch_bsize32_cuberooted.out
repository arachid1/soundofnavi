Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v22_augm_v0_cleaned_8000.pkl
File:  conv.train2011
Description:  mod9_128ch_bsize32_cuberooted
2021-03-18 09:04:10.725877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-18 09:04:12.676398: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-18 09:04:12.677410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-18 09:04:12.771891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.772651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-18 09:04:12.772765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.773462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-18 09:04:12.773489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-18 09:04:12.776922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-18 09:04:12.777029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-18 09:04:12.778272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-18 09:04:12.778580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-18 09:04:12.779636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-18 09:04:12.780506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-18 09:04:12.780674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-18 09:04:12.780776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.781568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.782294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.783064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:12.783745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-03-18 09:04:12.785743: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-18 09:04:13.206281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.207048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-18 09:04:13.207196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.207960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:00:05.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-18 09:04:13.207995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-18 09:04:13.208051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-18 09:04:13.208077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-18 09:04:13.208090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-18 09:04:13.208103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-18 09:04:13.208116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-18 09:04:13.208129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-18 09:04:13.208142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-18 09:04:13.208205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.208907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.209643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.210427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:13.211110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-03-18 09:04:13.211152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-18 09:04:14.130016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-18 09:04:14.130071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2021-03-18 09:04:14.130081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y 
2021-03-18 09:04:14.130087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N 
2021-03-18 09:04:14.130406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.131236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.131964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.132671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.133346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
2021-03-18 09:04:14.133802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.134536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-18 09:04:14.135209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14760 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)
2021-03-18 09:04:14.623692: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-18 09:04:14.623729: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-18 09:04:14.623762: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs
2021-03-18 09:04:14.623955: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-03-18 09:04:14.624760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-03-18 09:04:15.006477: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-18 09:04:15.011357: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
Tensorflow Version: 2.4.0
Num GPUs Available:  2
-----------------------
Using module located at /main/models/conv/train2011.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v22_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___03_0859___all_sw_coch_preprocessed_v2_param_v22_augm_v0_cleaned_8000___mod9_128ch_bsize32_cuberooted___2011/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 2, 'SR': 8000, 'BATCH_SIZE': 32, 'LR': 0.001, 'SHAPE': (128, 1250, 3), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07}
Learning Rate Parameters: {'factor': 0.5, 'patience': 5, 'min_lr': 1e-05}
Early Stopping Patience and Delta: 7, 1.0%
-----------------------
Size of training set: 15650
Size of validation set: 3912
Initializing weights...
weights = {0: 0.6740868366643694, 1: 1.229695750565753, 2: 1.09874185576275, 3: 1.2607630832688836}
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 1250, 3 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 1250, 3) 12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 128, 1250, 16 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 128, 1250, 3) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 128, 1250, 16 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 1250, 16 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 1250, 16 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 128, 1250, 48 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 64, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 64, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 64, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 64, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 32, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 32, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 16, 156, 64)  0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 156, 64)  256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 156, 64)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 16, 156, 128) 91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 16, 156, 128) 230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 8, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 8, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 8, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 4, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 4, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 4, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 4, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 4, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        2021-03-18 09:04:16.808030: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
      type: DT_FLOAT
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
      shape {
        dim {
          size: 2
        }
      }
    }
  }
}

2021-03-18 09:04:16.843536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-03-18 09:04:16.845107: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-03-18 09:04:36.546309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-18 09:04:36.837419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-18 09:04:37.497112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-18 09:04:43.059675: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-18 09:04:43.059729: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-18 09:04:44.837752: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-03-18 09:04:44.842674: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-03-18 09:04:44.919458: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 3161 callback api events and 3158 activity events. 
2021-03-18 09:04:44.992577: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-18 09:10:58.421401: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_STRING
      type: DT_FLOAT
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
      shape {
        dim {
          size: 2
        }
      }
    }
  }
}


__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            1026        global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,201,262
Trainable params: 6,159,752
Non-trainable params: 41,510
__________________________________________________________________________________________________
Epoch 1/40
490/490 - 471s - loss: 0.3230 - calc_accuracy: 0.6824 - val_loss: 1.0518 - val_calc_accuracy: 0.3745
Epoch 2/40
490/490 - 441s - loss: 0.2290 - calc_accuracy: 0.7789 - val_loss: 0.3967 - val_calc_accuracy: 0.7576
Epoch 3/40
490/490 - 460s - loss: 0.2157 - calc_accuracy: 0.7924 - val_loss: 0.3245 - val_calc_accuracy: 0.7482
Epoch 4/40
490/490 - 466s - loss: 0.1961 - calc_accuracy: 0.8145 - val_loss: 0.3324 - val_calc_accuracy: 0.7825
Epoch 5/40
490/490 - 467s - loss: 0.1706 - calc_accuracy: 0.8510 - val_loss: 0.2425 - val_calc_accuracy: 0.8247
Epoch 6/40
490/490 - 466s - loss: 0.1517 - calc_accuracy: 0.8693 - val_loss: 0.1953 - val_calc_accuracy: 0.8737
Epoch 7/40
490/490 - 468s - loss: 0.1403 - calc_accuracy: 0.8795 - val_loss: 0.2123 - val_calc_accuracy: 0.8590
Epoch 8/40
490/490 - 467s - loss: 0.1272 - calc_accuracy: 0.8920 - val_loss: 0.3169 - val_calc_accuracy: 0.8163
Epoch 9/40
490/490 - 467s - loss: 0.1169 - calc_accuracy: 0.9013 - val_loss: 0.2043 - val_calc_accuracy: 0.8707
Epoch 10/40
490/490 - 469s - loss: 0.1142 - calc_accuracy: 0.9027 - val_loss: 0.1566 - val_calc_accuracy: 0.8961
Epoch 11/40
490/490 - 468s - loss: 0.1100 - calc_accuracy: 0.9054 - val_loss: 0.2985 - val_calc_accuracy: 0.8249
Epoch 12/40
490/490 - 443s - loss: 0.1015 - calc_accuracy: 0.9138 - val_loss: 0.1718 - val_calc_accuracy: 0.8882
Epoch 13/40
490/490 - 441s - loss: 0.0964 - calc_accuracy: 0.9175 - val_loss: 0.1338 - val_calc_accuracy: 0.9149
Epoch 14/40
490/490 - 440s - loss: 0.0895 - calc_accuracy: 0.9217 - val_loss: 0.1263 - val_calc_accuracy: 0.9172
Epoch 15/40
490/490 - 441s - loss: 0.0805 - calc_accuracy: 0.9307 - val_loss: 0.1199 - val_calc_accuracy: 0.9258
Epoch 16/40
490/490 - 441s - loss: 0.0789 - calc_accuracy: 0.9335 - val_loss: 0.1742 - val_calc_accuracy: 0.8890
Epoch 17/40
490/490 - 441s - loss: 0.0720 - calc_accuracy: 0.9340 - val_loss: 0.1575 - val_calc_accuracy: 0.9172
Epoch 18/40
490/490 - 440s - loss: 0.0768 - calc_accuracy: 0.9352 - val_loss: 0.1251 - val_calc_accuracy: 0.9164
Epoch 19/40
490/490 - 442s - loss: 0.0633 - calc_accuracy: 0.9434 - val_loss: 0.1258 - val_calc_accuracy: 0.9184
Epoch 20/40
490/490 - 440s - loss: 0.0645 - calc_accuracy: 0.9439 - val_loss: 0.1221 - val_calc_accuracy: 0.9230

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 21/40
490/490 - 440s - loss: 0.0433 - calc_accuracy: 0.9610 - val_loss: 0.1378 - val_calc_accuracy: 0.9271
Epoch 22/40
490/490 - 439s - loss: 0.0391 - calc_accuracy: 0.9668 - val_loss: 0.1285 - val_calc_accuracy: 0.9309
Epoch 00022: early stopping

 See logs at ../../cache/conv___03_0859___all_sw_coch_preprocessed_v2_param_v22_augm_v0_cleaned_8000___mod9_128ch_bsize32_cuberooted___2011/logs/
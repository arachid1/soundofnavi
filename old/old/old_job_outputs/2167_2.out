Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
File:  conv.train2167
Description:  redo
2021-05-30 20:15:47.888212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-30 20:15:50.050012: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-30 20:15:50.050889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-30 20:15:50.086307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:50.087005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-30 20:15:50.087033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-30 20:15:50.090271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-30 20:15:50.090357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-30 20:15:50.091363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-30 20:15:50.091663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-30 20:15:50.092618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-30 20:15:50.093444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-30 20:15:50.093591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-30 20:15:50.093696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:50.094423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:50.095058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
wandb: Currently logged in as: arachid1 (use `wandb login --relogin` to force relogin)
Tensorflow Version: 2.4.0
Num GPUs Available:  1
-----------------------
Using module located at /main/models/conv/train2167.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v29_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../new_cache/conv__2167__05_2015__v29__redo/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 1, 'SR': 8000, 'BATCH_SIZE': 16, 'LR': 0.0001, 'SHAPE': (1250, 128), 'WEIGHT_DECAY': 0.001, 'LL2_REG': 0, 'EPSILON': 1e-07, 'LABEL_SMOOTHING': 0}
Learning Rate Parameters: {'factor': 0.25, 'patience': 4, 'min_lr': 1e-10}
Early Stopping Patience and Delta: 25, 0%
Six: False and Concat: False
-----------------------
wandb: wandb version 0.10.31 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.30
wandb: Syncing run train2167
wandb: â­ï¸ View project at https://wandb.ai/arachid1/tensorboard-integration
wandb: ðŸš€ View run at https://wandb.ai/arachid1/tensorboard-integration/runs/kohqyfdf
wandb: Run data is saved locally in /home/alirachidi/classification_algorithm/trainers/main/wandb/run-20210530_201550-kohqyfdf
wandb: Run `wandb offline` to turn off syncing.
2021-05-30 20:15:54.883698: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-30 20:15:54.883958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:54.884695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2021-05-30 20:15:54.884741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-30 20:15:54.884796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-30 20:15:54.884816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-30 20:15:54.884837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-30 20:15:54.884857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-30 20:15:54.884877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-30 20:15:54.884897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-30 20:15:54.884915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-30 20:15:54.885005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:54.885756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:54.886374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-05-30 20:15:54.886413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-30 20:15:55.585145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-30 20:15:55.585189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-05-30 20:15:55.585196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-05-30 20:15:55.585449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:55.586192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:55.586913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-30 20:15:55.587642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer gru_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
2021-05-30 20:16:38.606248: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-30 20:16:38.608529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-05-30 20:16:47.623836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-30 20:16:48.328617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11

Original number of folders: 453
With concat = False and six = False, size of training set: 4196...
...and size of validation set: 1088
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1250, 128)]  0                                            
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, 1250, 64)     37248       input_1[0][0]                    
__________________________________________________________________________________________________
gru (GRU)                       (None, 1250, 32)     15552       input_1[0][0]                    
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 1250, 64)     0           gru_2[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu (LeakyReLU)         (None, 1250, 32)     0           gru[0][0]                        
__________________________________________________________________________________________________
gru_3 (GRU)                     (None, 1250, 128)    74496       leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, 1250, 128)    62208       leaky_re_lu[0][0]                
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 1250, 128)    0           gru_3[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 1250, 128)    0           gru_1[0][0]                      
__________________________________________________________________________________________________
add (Add)                       (None, 1250, 128)    0           leaky_re_lu_3[0][0]              
                                                                 leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
gru_4 (GRU)                     (None, 1250, 128)    99072       add[0][0]                        
__________________________________________________________________________________________________
gru_6 (GRU)                     (None, 1250, 64)     37248       add[0][0]                        
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 1250, 128)    0           gru_4[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 1250, 64)     0           gru_6[0][0]                      
__________________________________________________________________________________________________
gru_5 (GRU)                     (None, 1250, 32)     15552       leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
gru_7 (GRU)                     (None, 1250, 32)     9408        leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 1250, 32)     0           gru_5[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 1250, 32)     0           gru_7[0][0]                      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1250, 32)     0           leaky_re_lu_5[0][0]              
                                                                 leaky_re_lu_7[0][0]              
                                                                 gru[0][0]                        
__________________________________________________________________________________________________
dense (Dense)                   (None, 1250, 64)     2112        add_1[0][0]                      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1250, 32)     1056        add_1[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 1250, 64)     0           dense[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 1250, 32)     0           dense_2[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1250, 64)     0           leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1250, 32)     0           leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1250, 16)     1040        dropout[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1250, 16)     528         dropout_1[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 1250, 16)     0           dense_1[0][0]                    
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 1250, 16)     0           dense_3[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 1250, 16)     0           leaky_re_lu_9[0][0]              
                                                                 leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1250, 16)     272         add_2[0][0]                      
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 1250, 16)     0           dense_4[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1250, 16)     0           leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
flatten (Flatten)               (None, 20000)        0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            20001       flatten[0][0]                    
==================================================================================================
Total params: 375,793
Trainable params: 375,793
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/80
263/263 - 4020s - loss: 0.6034 - accuracy: 0.2741 - val_loss: 0.5212 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
TARGET: 1
target metric(test f1): 0.333843797856049
inside not defaulting
Saving model...
Epoch 2/80
263/263 - 4013s - loss: 0.5785 - accuracy: 0.2741 - val_loss: 0.5195 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
TARGET: 1
target metric(test f1): 0.333843797856049
inside not defaulting
The validation tracker metric at 0.333843797856049 hasn't increased by 0 in 1 epochs
Epoch 3/80
263/263 - 4018s - loss: 0.5696 - accuracy: 0.2741 - val_loss: 0.5260 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
TARGET: 1
target metric(test f1): 0.333843797856049
inside not defaulting
The validation tracker metric at 0.333843797856049 hasn't increased by 0 in 2 epochs
Epoch 4/80
263/263 - 4020s - loss: 0.5677 - accuracy: 0.2741 - val_loss: 0.5115 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
TARGET: 1
target metric(test f1): 0.333843797856049
inside not defaulting
The validation tracker metric at 0.333843797856049 hasn't increased by 0 in 3 epochs
Epoch 5/80
263/263 - 4028s - loss: 0.5584 - accuracy: 0.2741 - val_loss: 0.5351 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
TARGET: 1
target metric(test f1): 0.333843797856049
inside not defaulting
Lr has been adjusted to 2.499999936844688e-05
The validation tracker metric at 0.333843797856049 hasn't increased by 0 in 4 epochs
Epoch 6/80
263/263 - 4034s - loss: 0.5545 - accuracy: 0.2741 - val_loss: 0.5259 - val_accuracy: 0.2004
Confusion matrix: 
 [[  0 870]
 [  0 218]]
Validation f1: 33.38
Validation accuracy: 20.04
Validation recall: 100.00
Validation precision: 20.04
Validation AUC: 0.6001838235294118
Validation class accuracies: [0.0, 1.0]
local_gc_exec.sh: line 6:  3538 Killed                  python -m models.$MODULE_NAME --train-file $LOCAL_TRAIN_FILE --job-dir $LOCAL_JOB_DIR --params "$PARAMS" --augm-params "$AUGM_PARAMS"

 See logs at ../../new_cache/conv__2167__05_2015__v29__redo/logs//home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))

Category:  coch
Dataset:  all_sw_coch_preprocessed_v2_param_v20_augm_v0_cleaned_8000.pkl
File:  conv.train2006
Description:  final_63_channels
2021-03-10 11:40:44.266005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-10 11:40:46.317611: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-10 11:40:46.318643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-03-10 11:40:46.357337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.358008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-10 11:40:46.358037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-10 11:40:46.361744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-10 11:40:46.361823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-10 11:40:46.363032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-10 11:40:46.363376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-10 11:40:46.364524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-10 11:40:46.365508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-10 11:40:46.365675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-10 11:40:46.365791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.366496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.367067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-10 11:40:46.369231: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-10 11:40:46.369413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.370052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
2021-03-10 11:40:46.370076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-10 11:40:46.370115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-10 11:40:46.370132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-10 11:40:46.370147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-03-10 11:40:46.370162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-03-10 11:40:46.370188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-03-10 11:40:46.370203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-03-10 11:40:46.370218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-10 11:40:46.370309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.370979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:46.371593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-10 11:40:46.371632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-03-10 11:40:47.053638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-10 11:40:47.053691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-03-10 11:40:47.053701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-03-10 11:40:47.053993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:47.054748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:47.055407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-03-10 11:40:47.056086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
Tensorflow Version: 2.4.0
Num GPUs Available:  1
yo
-----------------------
Using module located at /main/models/conv/train2006.py
Using train_file located at ../../data/datasets/all_sw_coch_preprocessed_v2_param_v20_augm_v0_cleaned_8000.pkl
Using logs_path located at ../../cache/conv___03_1140___all_sw_coch_preprocessed_v2_param_v20_augm_v0_cleaned_8000___final_63_channels___2006/logs/
-----------------------
Collecting Variables...
Model Parameters: {'N_CLASSES': 2, 'SR': 8000, 'BATCH_SIZE': 32, 'LR': 0.001, 'SHAPE': (64, 1250, 3), 'WEIGHT_DECAY': 0.0001, 'LL2_REG': 0, 'EPSILON': 1e-07}
Learning Rate Parameters: {'factor': 0.5, 'patience': 5, 'min_lr': 1e-05}
Early Stopping Patience: 7
-----------------------
Size of training set: 13917
Size of validation set: 3479
Model: "conv2d"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 64, 1250, 3) 0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 64, 1250, 3)  12          input_1[0][0]                    
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 64, 1250, 16) 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 64, 1250, 16) 64          batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 64, 1250, 3)  0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 64, 1250, 16) 2320        conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 64, 1250, 16) 6416        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 64, 1250, 16) 64          max_pooling2d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64, 1250, 48) 0           conv2d_1[0][0]                   
                                                                 conv2d_3[0][0]                   
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 32, 625, 48)  0           concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 625, 48)  192         average_pooling2d[0][0]          
__________________________________________________________________________________________________
dropout (Dropout)               (None, 32, 625, 48)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
inverted_residual (InvertedResi (None, 32, 625, 32)  35840       dropout[0][0]                    
__________________________________________________________________________________________________
inverted_residual_1 (InvertedRe (None, 32, 625, 32)  20864       inverted_residual[0][0]          
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 16, 312, 32)  0           inverted_residual_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 16, 312, 32)  128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 16, 312, 32)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
inverted_residual_2 (InvertedRe (None, 16, 312, 64)  27136       dropout_1[0][0]                  
__________________________________________________________________________________________________
inverted_residual_3 (InvertedRe (None, 16, 312, 64)  66304       inverted_residual_2[0][0]        
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 8, 156, 64)   0           inverted_residual_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 156, 64)   256         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 8, 156, 64)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
inverted_residual_4 (InvertedRe (None, 8, 156, 128)  91136       dropout_2[0][0]                  
__________________________________________________________________________________________________
inverted_residual_5 (InvertedRe (None, 8, 156, 128)  230912      inverted_residual_4[0][0]        
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 4, 78, 128)   0           inverted_residual_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 4, 78, 128)   512         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 4, 78, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
inverted_residual_6 (InvertedRe (None, 4, 78, 256)   329728      dropout_3[0][0]                  
__________________________________________________________________________________________________
inverted_residual_7 (InvertedRe (None, 4, 78, 256)   855040      inverted_residual_6[0][0]        
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 2, 39, 256)   0           inverted_residual_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 2, 39, 256)   1024        average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 2, 39, 256)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
inverted_residual_8 (InvertedRe (None, 2, 39, 512)   1249280     dropout_4[0][0]                  
__________________________________________________________________________________________________
inverted_residual_9 (InvertedRe (None, 2, 39, 512)   3282944     inverted_residual_8[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 512)          0           inverted_residual_9[0][0]        
__________________________________________________________________________________________________2021-03-10 11:40:48.152237: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-10 11:40:48.152281: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-10 11:40:48.152322: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2021-03-10 11:40:48.152559: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64
2021-03-10 11:40:48.153467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-03-10 11:40:48.331622: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-03-10 11:40:48.334218: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-03-10 11:40:48.670517: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-03-10 11:40:48.672271: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz
2021-03-10 11:40:51.990784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-03-10 11:40:52.357850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-03-10 11:40:52.724667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-03-10 11:40:56.546449: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-03-10 11:40:56.546508: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-03-10 11:40:57.830799: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-03-10 11:40:57.833956: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-03-10 11:40:57.880342: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 2004 callback api events and 2000 activity events. 
2021-03-10 11:40:57.925635: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.

dense (Dense)                   (None, 2)            1026        global_average_pooling2d[0][0]   
==================================================================================================
Total params: 6,201,262
Trainable params: 6,159,752
Non-trainable params: 41,510
__________________________________________________________________________________________________
GPU(s): [LogicalDevice(name='/device:GPU:0', device_type='GPU')]
Epoch 1/35
435/435 - 338s - loss: 0.4497 - calc_accuracy: 0.6472 - val_loss: 0.7705 - val_calc_accuracy: 0.4064
Epoch 2/35
435/435 - 322s - loss: 0.3408 - calc_accuracy: 0.7315 - val_loss: 0.4209 - val_calc_accuracy: 0.7248
Epoch 3/35
435/435 - 326s - loss: 0.3169 - calc_accuracy: 0.7485 - val_loss: 0.3372 - val_calc_accuracy: 0.7504
Epoch 4/35
435/435 - 327s - loss: 0.3001 - calc_accuracy: 0.7647 - val_loss: 0.3047 - val_calc_accuracy: 0.7711
Epoch 5/35
435/435 - 321s - loss: 0.2850 - calc_accuracy: 0.7789 - val_loss: 0.2910 - val_calc_accuracy: 0.7739
Epoch 6/35
435/435 - 327s - loss: 0.2718 - calc_accuracy: 0.7904 - val_loss: 0.3595 - val_calc_accuracy: 0.7197
Epoch 7/35
435/435 - 326s - loss: 0.2649 - calc_accuracy: 0.7919 - val_loss: 0.4605 - val_calc_accuracy: 0.6052
Epoch 8/35
435/435 - 326s - loss: 0.2522 - calc_accuracy: 0.8072 - val_loss: 0.2385 - val_calc_accuracy: 0.8220
Epoch 9/35
435/435 - 323s - loss: 0.2401 - calc_accuracy: 0.8126 - val_loss: 0.2594 - val_calc_accuracy: 0.8017
Epoch 10/35
435/435 - 324s - loss: 0.2311 - calc_accuracy: 0.8215 - val_loss: 0.2463 - val_calc_accuracy: 0.8141
Epoch 11/35
435/435 - 325s - loss: 0.2202 - calc_accuracy: 0.8326 - val_loss: 0.2544 - val_calc_accuracy: 0.8046
Epoch 12/35
435/435 - 325s - loss: 0.2148 - calc_accuracy: 0.8375 - val_loss: 0.2565 - val_calc_accuracy: 0.8119
Epoch 13/35
435/435 - 325s - loss: 0.2025 - calc_accuracy: 0.8471 - val_loss: 0.2224 - val_calc_accuracy: 0.8430
Epoch 14/35
435/435 - 327s - loss: 0.1960 - calc_accuracy: 0.8513 - val_loss: 0.2043 - val_calc_accuracy: 0.8483
Epoch 15/35
435/435 - 325s - loss: 0.1826 - calc_accuracy: 0.8635 - val_loss: 0.3050 - val_calc_accuracy: 0.8011
Epoch 16/35
435/435 - 326s - loss: 0.1775 - calc_accuracy: 0.8668 - val_loss: 0.2248 - val_calc_accuracy: 0.8307
Epoch 17/35
435/435 - 326s - loss: 0.1637 - calc_accuracy: 0.8748 - val_loss: 0.2232 - val_calc_accuracy: 0.8469
Epoch 18/35
435/435 - 327s - loss: 0.1574 - calc_accuracy: 0.8831 - val_loss: 0.3422 - val_calc_accuracy: 0.7572
Epoch 19/35
435/435 - 323s - loss: 0.1441 - calc_accuracy: 0.8921 - val_loss: 0.3289 - val_calc_accuracy: 0.7604

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 20/35
435/435 - 325s - loss: 0.1115 - calc_accuracy: 0.9184 - val_loss: 0.1973 - val_calc_accuracy: 0.8696
Epoch 21/35
435/435 - 324s - loss: 0.0969 - calc_accuracy: 0.9288 - val_loss: 0.2141 - val_calc_accuracy: 0.8666
Epoch 22/35
435/435 - 327s - loss: 0.0855 - calc_accuracy: 0.9385 - val_loss: 0.2151 - val_calc_accuracy: 0.8684
Epoch 23/35
435/435 - 326s - loss: 0.0764 - calc_accuracy: 0.9453 - val_loss: 0.2307 - val_calc_accuracy: 0.8597
Epoch 24/35
435/435 - 324s - loss: 0.0657 - calc_accuracy: 0.9518 - val_loss: 0.2708 - val_calc_accuracy: 0.8556
Epoch 25/35
435/435 - 325s - loss: 0.0651 - calc_accuracy: 0.9524 - val_loss: 0.2201 - val_calc_accuracy: 0.8813
Epoch 26/35
435/435 - 324s - loss: 0.0581 - calc_accuracy: 0.9567 - val_loss: 0.2450 - val_calc_accuracy: 0.8809
Epoch 27/35
435/435 - 326s - loss: 0.0513 - calc_accuracy: 0.9629 - val_loss: 0.2759 - val_calc_accuracy: 0.8579
Epoch 28/35
435/435 - 325s - loss: 0.0490 - calc_accuracy: 0.9655 - val_loss: 0.2704 - val_calc_accuracy: 0.8685
Epoch 29/35
435/435 - 325s - loss: 0.0435 - calc_accuracy: 0.9684 - val_loss: 0.2790 - val_calc_accuracy: 0.8736
Epoch 30/35
435/435 - 323s - loss: 0.0373 - calc_accuracy: 0.9733 - val_loss: 0.2797 - val_calc_accuracy: 0.8752

Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 31/35
435/435 - 326s - loss: 0.0281 - calc_accuracy: 0.9814 - val_loss: 0.2708 - val_calc_accuracy: 0.8856
Epoch 32/35
435/435 - 326s - loss: 0.0217 - calc_accuracy: 0.9856 - val_loss: 0.2710 - val_calc_accuracy: 0.8856
Epoch 33/35
435/435 - 327s - loss: 0.0200 - calc_accuracy: 0.9872 - val_loss: 0.2860 - val_calc_accuracy: 0.8850
Epoch 34/35
435/435 - 325s - loss: 0.0208 - calc_accuracy: 0.9868 - val_loss: 0.2903 - val_calc_accuracy: 0.8830
Epoch 35/35
435/435 - 328s - loss: 0.0157 - calc_accuracy: 0.9905 - val_loss: 0.3189 - val_calc_accuracy: 0.8809
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.4.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  UserWarning,

 See logs at ../../cache/conv___03_1140___all_sw_coch_preprocessed_v2_param_v20_augm_v0_cleaned_8000___final_63_channels___2006/logs/
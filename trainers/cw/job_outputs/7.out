Tensorflow Version: 2.4.0
Num GPUs Available:  1
Collecting Variables...
All variables have been collected.
-----------------------
Job id is 1.
- Loading Perch.
3278 Perch audios have been loaded.
- Loading Icbhi.
725 Icbhi audios have been loaded.
- Loading Antwerp.
131 Antwerp audios have been loaded.
- Preparing Perch.
862 Perch groups of audio chunks (by filename or patients) have been prepared.
- Preparing Icbhi.
112 Icbhi groups of audio chunks (by filename or patients) have been prepared.
- Preparing Antwerp.
15 Antwerp groups of audio chunks (by filename or patients) have been prepared.
--- Samples are being split into training/val groups and de-grouped by patient ---
--- Perch training dataset went from 0 to 7947 elements, with 4692 none's, 122 crakles, 372 wheezes and 112 both ---
--- Perch Validation dataset contains 1887 elements, with 1102 none, 24 crackles, 108 wheezes and 24 both ---
--- Icbhi training dataset went from 0 to 4398 elements, with 1655 none's, 1436 crakles, 619 wheezes and 616 both ---
--- Icbhi Validation dataset contains 983 elements, with 498 none, 336 crackles, 72 wheezes and 60 both ---
--- Antwerp training dataset went from 0 to 1213 elements, with 217 none's, 32 crakles, 896 wheezes and 68 both ---
--- Antwerp Validation dataset contains 234 elements, with 46 none, 20 crackles, 10 wheezes and 158 both ---
tensor([0.5115], device='cuda:0')
cuda:0
tensor([0.7594], device='cuda:0')
STFT kernels created, time used = 0.0124 seconds
Parameter containing:
tensor([[ 0.0000e+00,  1.0410e+01,  2.0974e+01,  ...,  3.8633e+03,
          3.9311e+03,  4.0000e+03],
        [-1.5625e+01, -5.2153e+00,  5.3492e+00,  ...,  3.8476e+03,
          3.9155e+03,  3.9844e+03],
        [-3.1250e+01, -2.0840e+01, -1.0276e+01,  ...,  3.8320e+03,
          3.8999e+03,  3.9687e+03],
        ...,
        [-3.9688e+03, -3.9583e+03, -3.9478e+03,  ..., -1.0548e+02,
         -3.7621e+01,  3.1250e+01],
        [-3.9844e+03, -3.9740e+03, -3.9634e+03,  ..., -1.2111e+02,
         -5.3246e+01,  1.5625e+01],
        [-4.0000e+03, -3.9896e+03, -3.9790e+03,  ..., -1.3673e+02,
         -6.8871e+01, -2.4414e-04]], device='cuda:0', requires_grad=True)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1000)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name          | Type                | Params
-------------------------------------------------------
0  | spec_layer    | STFT                | 0     
1  | mel_layer     | MelScaleBis         | 33.8 K
2  | depth_layer_1 | InvertedResidual_nn | 73.2 K
3  | AVGPOOL1      | AvgPool2d           | 0     
4  | BN1           | BatchNorm2d         | 256   
5  | DP1           | Dropout             | 0     
6  | depth_layer_3 | InvertedResidual_nn | 73.2 K
7  | AVGPOOL2      | AvgPool2d           | 0     
8  | BN2           | BatchNorm2d         | 256   
9  | DP2           | Dropout             | 0     
10 | classifier    | Linear              | 258   
-------------------------------------------------------
182 K     Trainable params
0         Non-trainable params
182 K     Total params
0.729     Total estimated model params size (MB)
tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]])
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.72it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/4166 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s] Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.30it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.30it/s, loss=0.444, v_num=1]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:06, 25.00it/s, loss=0.444, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.71it/s, loss=0.444, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.71it/s, loss=0.422, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:59<01:04, 33.34it/s, loss=0.422, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.83it/s, loss=0.422, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.83it/s, loss=0.402, v_num=1]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.69it/s, loss=0.402, v_num=1]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 118.49it/s][AEpoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.65it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687]
                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.63it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]           Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.41, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.472, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:54, 27.76it/s, loss=0.472, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.88it/s, loss=0.472, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.88it/s, loss=0.464, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:56<01:00, 35.70it/s, loss=0.464, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.06it/s, loss=0.464, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.06it/s, loss=0.381, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:16<00:03, 51.97it/s, loss=0.381, v_num=1, val_loss=0.428, val_acc=0.687, train_loss=0.419, train_acc=0.704]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 118.44it/s][AEpoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.89it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.419, train_acc=0.704]
                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.88it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]           Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:   0%|          | 0/4166 [00:12<?, ?it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.27it/s, loss=0.455, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.26it/s, loss=0.44, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709] Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:42<02:14, 23.54it/s, loss=0.44, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.93it/s, loss=0.44, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.93it/s, loss=0.377, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:02<01:07, 32.01it/s, loss=0.377, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.10it/s, loss=0.377, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.10it/s, loss=0.342, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:16<00:03, 52.02it/s, loss=0.342, v_num=1, val_loss=0.506, val_acc=0.672, train_loss=0.400, train_acc=0.709]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 118.69it/s][AEpoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.94it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.400, train_acc=0.709]
                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.93it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]           Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:   0%|          | 0/4166 [00:19<?, ?it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:12, 43.39it/s, loss=0.423, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:12, 43.39it/s, loss=0.384, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:03, 25.62it/s, loss=0.384, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.82it/s, loss=0.384, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.82it/s, loss=0.333, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:59<01:03, 33.88it/s, loss=0.333, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.01it/s, loss=0.333, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.01it/s, loss=0.454, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.90it/s, loss=0.454, v_num=1, val_loss=0.480, val_acc=0.704, train_loss=0.393, train_acc=0.714]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 119.35it/s][AEpoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.86it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.393, train_acc=0.714]
                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.85it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]           Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.12it/s, loss=0.336, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.12it/s, loss=0.394, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.22it/s, loss=0.394, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.73it/s, loss=0.394, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.73it/s, loss=0.347, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:05<01:10, 30.56it/s, loss=0.347, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.87it/s, loss=0.347, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.87it/s, loss=0.395, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.76it/s, loss=0.395, v_num=1, val_loss=0.402, val_acc=0.714, train_loss=0.383, train_acc=0.718]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 117.32it/s][AEpoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.68it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.383, train_acc=0.718]
                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.66it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]           Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:   0%|          | 0/4166 [00:11<?, ?it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.28it/s, loss=0.373, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.28it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:41<02:11, 24.08it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.77it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.77it/s, loss=0.424, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:01<01:06, 32.51it/s, loss=0.424, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.87it/s, loss=0.424, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.87it/s, loss=0.325, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]Epoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.72it/s, loss=0.325, v_num=1, val_loss=0.444, val_acc=0.681, train_loss=0.371, train_acc=0.725]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 115.28it/s][AEpoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.58it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.371, train_acc=0.725]
                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.55it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]           Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:   0%|          | 0/4166 [00:17<?, ?it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.22it/s, loss=0.378, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.22it/s, loss=0.335, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:37<01:58, 26.71it/s, loss=0.335, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:46<00:49, 43.44it/s, loss=0.335, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:46<00:49, 43.44it/s, loss=0.309, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:57<01:02, 34.82it/s, loss=0.309, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.58it/s, loss=0.309, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.58it/s, loss=0.348, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]Epoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.44it/s, loss=0.348, v_num=1, val_loss=0.460, val_acc=0.699, train_loss=0.362, train_acc=0.731]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 117.98it/s][AEpoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.42it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.362, train_acc=0.731]
                                                              [AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.39it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]           Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:12, 43.39it/s, loss=0.331, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:12, 43.39it/s, loss=0.328, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:33<01:44, 30.23it/s, loss=0.328, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.96it/s, loss=0.328, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.96it/s, loss=0.318, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.71it/s, loss=0.318, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.11it/s, loss=0.318, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 44.11it/s, loss=0.406, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]Epoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:16<00:03, 52.00it/s, loss=0.406, v_num=1, val_loss=0.492, val_acc=0.675, train_loss=0.351, train_acc=0.738]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 116.02it/s][AEpoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.84it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.351, train_acc=0.738]
                                                              [AEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.83it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch     8: reducing learning rate of group 0 to 5.0000e-04.
Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]           Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:   0%|          | 0/4166 [00:19<?, ?it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.32it/s, loss=0.299, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.32it/s, loss=0.344, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:04, 25.35it/s, loss=0.344, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.77it/s, loss=0.344, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.77it/s, loss=0.341, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:59<01:04, 33.64it/s, loss=0.341, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.99it/s, loss=0.341, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.99it/s, loss=0.257, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]Epoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.90it/s, loss=0.257, v_num=1, val_loss=0.415, val_acc=0.699, train_loss=0.347, train_acc=0.743]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 119.15it/s][AEpoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.85it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.347, train_acc=0.743]
                                                              [AEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.84it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]           Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.415, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.285, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:53, 27.90it/s, loss=0.285, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.63it/s, loss=0.285, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.63it/s, loss=0.358, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<01:00, 35.81it/s, loss=0.358, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.83it/s, loss=0.358, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.83it/s, loss=0.331, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]Epoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.65it/s, loss=0.331, v_num=1, val_loss=0.497, val_acc=0.698, train_loss=0.332, train_acc=0.753]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 116.68it/s][AEpoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.57it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.332, train_acc=0.753]
                                                              [AEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.54it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]           Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:   0%|          | 0/4166 [00:11<?, ?it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.21it/s, loss=0.367, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.21it/s, loss=0.365, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:41<02:12, 23.96it/s, loss=0.365, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.74it/s, loss=0.365, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.73it/s, loss=0.258, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:01<01:06, 32.39it/s, loss=0.258, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.90it/s, loss=0.258, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.90it/s, loss=0.332, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]Epoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.75it/s, loss=0.332, v_num=1, val_loss=0.440, val_acc=0.701, train_loss=0.324, train_acc=0.758]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 117.81it/s][AEpoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:23<00:03, 47.68it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.758]
                                                              [AEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:23<00:00, 49.66it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]           Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:   0%|          | 0/4166 [00:17<?, ?it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.09it/s, loss=0.308, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.09it/s, loss=0.35, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754] Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:37<01:59, 26.43it/s, loss=0.35, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.51it/s, loss=0.35, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.51it/s, loss=0.28, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:57<01:02, 34.58it/s, loss=0.28, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.73it/s, loss=0.28, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.73it/s, loss=0.287, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]Epoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.60it/s, loss=0.287, v_num=1, val_loss=0.449, val_acc=0.705, train_loss=0.324, train_acc=0.754]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 116.74it/s][AEpoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.52it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.324, train_acc=0.754]  
                                                              [AEpoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.49it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch    12: reducing learning rate of group 0 to 2.5000e-04.
Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]           Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.03it/s, loss=0.3, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.03it/s, loss=0.372, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:33<01:46, 29.67it/s, loss=0.372, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.372, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.276, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.39it/s, loss=0.276, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.79it/s, loss=0.276, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.79it/s, loss=0.409, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]Epoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.54it/s, loss=0.409, v_num=1, val_loss=0.434, val_acc=0.705, train_loss=0.319, train_acc=0.759]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 116.84it/s][AEpoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.48it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.319, train_acc=0.759]
                                                              [AEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.45it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]           Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:   0%|          | 0/4166 [00:19<?, ?it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.16it/s, loss=0.283, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 43.16it/s, loss=0.34, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766] Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:04, 25.35it/s, loss=0.34, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.55it/s, loss=0.34, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:45<00:49, 43.55it/s, loss=0.277, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:59<01:04, 33.65it/s, loss=0.277, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.86it/s, loss=0.277, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.86it/s, loss=0.298, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]Epoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.69it/s, loss=0.298, v_num=1, val_loss=0.493, val_acc=0.705, train_loss=0.310, train_acc=0.766]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 116.53it/s][AEpoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.59it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.310, train_acc=0.766]
                                                              [AEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.56it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]           Epoch 14:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 42.98it/s, loss=0.306, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:23<01:13, 42.98it/s, loss=0.27, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771] Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:51, 28.27it/s, loss=0.27, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:46<00:49, 43.39it/s, loss=0.27, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:46<00:49, 43.39it/s, loss=0.328, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:05<01:10, 30.59it/s, loss=0.328, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.67it/s, loss=0.328, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:08<00:26, 43.67it/s, loss=0.277, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]Epoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:17<00:03, 51.52it/s, loss=0.277, v_num=1, val_loss=0.449, val_acc=0.709, train_loss=0.308, train_acc=0.771]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 117.96it/s][AEpoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:24<00:03, 47.49it/s, loss=0.237, v_num=1, val_loss=0.456, val_acc=0.710, train_loss=0.308, train_acc=0.771]
                                                              [AEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.46it/s, loss=0.237, v_num=1, val_loss=0.456, val_acc=0.710, train_loss=0.304, train_acc=0.774]Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:24<00:00, 49.28it/s, loss=0.237, v_num=1, val_loss=0.456, val_acc=0.710, train_loss=0.304, train_acc=0.774]
/home/alirachidi/classification_algorithm/trainers/cw/models/train7.py:72: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.train_losses)), self.train_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train7.py:75: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_losses)), self.val_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train7.py:78: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_accuracies)), self.val_accuracies)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
../cache/cw/train7/1

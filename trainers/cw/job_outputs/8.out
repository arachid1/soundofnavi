Tensorflow Version: 2.4.0
Num GPUs Available:  1
Collecting Variables...
All variables have been collected.
-----------------------
Job id is 1.
- Loading Perch.
3278 Perch audios have been loaded.
- Loading Icbhi.
725 Icbhi audios have been loaded.
- Loading Antwerp.
131 Antwerp audios have been loaded.
- Preparing Perch.
862 Perch groups of audio chunks (by filename or patients) have been prepared.
- Preparing Icbhi.
112 Icbhi groups of audio chunks (by filename or patients) have been prepared.
- Preparing Antwerp.
15 Antwerp groups of audio chunks (by filename or patients) have been prepared.
--- Samples are being split into training/val groups and de-grouped by patient ---
--- Perch training dataset went from 0 to 7947 elements, with 4692 none's, 122 crakles, 372 wheezes and 112 both ---
--- Perch Validation dataset contains 1887 elements, with 1102 none, 24 crackles, 108 wheezes and 24 both ---
--- Icbhi training dataset went from 0 to 4398 elements, with 1655 none's, 1436 crakles, 619 wheezes and 616 both ---
--- Icbhi Validation dataset contains 983 elements, with 498 none, 336 crackles, 72 wheezes and 60 both ---
--- Antwerp training dataset went from 0 to 1213 elements, with 217 none's, 32 crakles, 896 wheezes and 68 both ---
--- Antwerp Validation dataset contains 234 elements, with 46 none, 20 crackles, 10 wheezes and 158 both ---
tensor([0.9507], device='cuda:0')
cuda:0
tensor([0.7036], device='cuda:0')
STFT kernels created, time used = 0.0122 seconds
Parameter containing:
tensor([[ 0.0000e+00,  1.0410e+01,  2.0974e+01,  ...,  3.8633e+03,
          3.9311e+03,  4.0000e+03],
        [-1.5625e+01, -5.2153e+00,  5.3492e+00,  ...,  3.8476e+03,
          3.9155e+03,  3.9844e+03],
        [-3.1250e+01, -2.0840e+01, -1.0276e+01,  ...,  3.8320e+03,
          3.8999e+03,  3.9687e+03],
        ...,
        [-3.9688e+03, -3.9583e+03, -3.9478e+03,  ..., -1.0548e+02,
         -3.7621e+01,  3.1250e+01],
        [-3.9844e+03, -3.9740e+03, -3.9634e+03,  ..., -1.2111e+02,
         -5.3246e+01,  1.5625e+01],
        [-4.0000e+03, -3.9896e+03, -3.9790e+03,  ..., -1.3673e+02,
         -6.8871e+01, -2.4414e-04]], device='cuda:0', requires_grad=True)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1000)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name          | Type                | Params
-------------------------------------------------------
0  | spec_layer    | STFT                | 0     
1  | mel_layer     | MelScaleBis         | 33.8 K
2  | depth_layer_1 | InvertedResidual_nn | 73.2 K
3  | AVGPOOL1      | AvgPool2d           | 0     
4  | BN1           | BatchNorm2d         | 256   
5  | DP1           | Dropout             | 0     
6  | depth_layer_3 | InvertedResidual_nn | 73.2 K
7  | AVGPOOL2      | AvgPool2d           | 0     
8  | BN2           | BatchNorm2d         | 256   
9  | DP2           | Dropout             | 0     
10 | classifier    | Linear              | 258   
-------------------------------------------------------
185 K     Trainable params
0         Non-trainable params
185 K     Total params
0.742     Total estimated model params size (MB)
tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]])
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.41it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/4166 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s] Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.76it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.76it/s, loss=0.398, v_num=1]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:06, 25.00it/s, loss=0.398, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.21it/s, loss=0.398, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.21it/s, loss=0.327, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:09<01:15, 28.57it/s, loss=0.327, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.327, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.374, v_num=1]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.37it/s, loss=0.374, v_num=1]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 110.79it/s][AEpoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.89it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662]
                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.67it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]           Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.70it/s, loss=0.443, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.70it/s, loss=0.371, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:56, 27.24it/s, loss=0.371, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.07it/s, loss=0.371, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.07it/s, loss=0.417, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:06<01:12, 29.98it/s, loss=0.417, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.24it/s, loss=0.417, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.24it/s, loss=0.403, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.29it/s, loss=0.403, v_num=1, val_loss=0.529, val_acc=0.662, train_loss=0.418, train_acc=0.702]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.79it/s][AEpoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.79it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.418, train_acc=0.702]
                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.56it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]           Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.83it/s, loss=0.431, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.83it/s, loss=0.473, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:43<02:16, 23.13it/s, loss=0.473, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.30it/s, loss=0.473, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.30it/s, loss=0.423, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.62it/s, loss=0.423, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.46it/s, loss=0.423, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.46it/s, loss=0.39, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707] Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.50it/s, loss=0.39, v_num=1, val_loss=0.504, val_acc=0.676, train_loss=0.400, train_acc=0.707]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 110.20it/s][AEpoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.98it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.400, train_acc=0.707]
                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.76it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.400, train_acc=0.707]Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.76it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]           Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.65it/s, loss=0.354, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.65it/s, loss=0.364, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:07, 24.87it/s, loss=0.364, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.11it/s, loss=0.364, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.11it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:10<01:16, 28.49it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.20it/s, loss=0.358, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.20it/s, loss=0.331, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.28it/s, loss=0.331, v_num=1, val_loss=0.444, val_acc=0.693, train_loss=0.396, train_acc=0.716]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.74it/s][AEpoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.78it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.396, train_acc=0.716]  
                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.55it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]           Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.65it/s, loss=0.3, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.65it/s, loss=0.438, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:56, 27.26it/s, loss=0.438, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.12it/s, loss=0.438, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.12it/s, loss=0.548, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:06<01:12, 29.99it/s, loss=0.548, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.33it/s, loss=0.548, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.33it/s, loss=0.394, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.35it/s, loss=0.394, v_num=1, val_loss=0.420, val_acc=0.702, train_loss=0.389, train_acc=0.716]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.49it/s][AEpoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.83it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.389, train_acc=0.716]
                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.60it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.389, train_acc=0.716]Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.60it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]           Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.75it/s, loss=0.333, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.75it/s, loss=0.432, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:43<02:17, 23.10it/s, loss=0.432, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.19it/s, loss=0.432, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.19it/s, loss=0.32, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722] Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.60it/s, loss=0.32, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.32it/s, loss=0.32, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.32it/s, loss=0.357, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]Epoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.38it/s, loss=0.357, v_num=1, val_loss=0.456, val_acc=0.711, train_loss=0.378, train_acc=0.722]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.12it/s][AEpoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.85it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.378, train_acc=0.722]
                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.63it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]           Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:   0%|          | 0/4166 [00:19<?, ?it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.72it/s, loss=0.387, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.72it/s, loss=0.423, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:06, 25.05it/s, loss=0.423, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.09it/s, loss=0.423, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.09it/s, loss=0.336, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:09<01:15, 28.60it/s, loss=0.336, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.25it/s, loss=0.336, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.25it/s, loss=0.444, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]Epoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.28it/s, loss=0.444, v_num=1, val_loss=0.465, val_acc=0.701, train_loss=0.371, train_acc=0.726]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.90it/s][AEpoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.78it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.371, train_acc=0.726]
                                                              [AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.56it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]           Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.71it/s, loss=0.343, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.70it/s, loss=0.346, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:55, 27.46it/s, loss=0.346, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.17it/s, loss=0.346, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.17it/s, loss=0.289, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:06<01:11, 30.11it/s, loss=0.289, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.289, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.332, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]Epoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.37it/s, loss=0.332, v_num=1, val_loss=0.395, val_acc=0.690, train_loss=0.365, train_acc=0.732]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 108.76it/s][AEpoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.82it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.365, train_acc=0.732]
                                                              [AEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.60it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.365, train_acc=0.732]Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.60it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]           Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.90it/s, loss=0.328, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.90it/s, loss=0.382, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:43<02:16, 23.23it/s, loss=0.382, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.28it/s, loss=0.382, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.28it/s, loss=0.374, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.73it/s, loss=0.374, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.40it/s, loss=0.374, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.40it/s, loss=0.319, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]Epoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.45it/s, loss=0.319, v_num=1, val_loss=0.472, val_acc=0.694, train_loss=0.358, train_acc=0.731]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.19it/s][AEpoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.91it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.358, train_acc=0.731]  
                                                              [AEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.69it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]           Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:   0%|          | 0/4166 [00:19<?, ?it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.81it/s, loss=0.3, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.81it/s, loss=0.271, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:06, 25.12it/s, loss=0.271, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.17it/s, loss=0.271, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.17it/s, loss=0.365, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:09<01:15, 28.65it/s, loss=0.365, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.37it/s, loss=0.365, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.37it/s, loss=0.397, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]Epoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.42it/s, loss=0.397, v_num=1, val_loss=0.385, val_acc=0.700, train_loss=0.352, train_acc=0.736]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.81it/s][AEpoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.90it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.352, train_acc=0.736]
                                                              [AEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.68it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]           Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.81it/s, loss=0.334, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.81it/s, loss=0.301, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:55, 27.35it/s, loss=0.301, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.301, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.268, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:06<01:12, 30.05it/s, loss=0.268, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.268, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.34it/s, loss=0.321, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]Epoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.35it/s, loss=0.321, v_num=1, val_loss=0.459, val_acc=0.674, train_loss=0.345, train_acc=0.742]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 110.28it/s][AEpoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.86it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.345, train_acc=0.742]
                                                              [AEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.64it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.345, train_acc=0.742]Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.64it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]           Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.97it/s, loss=0.327, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.96it/s, loss=0.322, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:43<02:16, 23.11it/s, loss=0.322, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.28it/s, loss=0.322, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.28it/s, loss=0.476, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.61it/s, loss=0.476, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.38it/s, loss=0.476, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.38it/s, loss=0.312, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]Epoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.44it/s, loss=0.312, v_num=1, val_loss=0.432, val_acc=0.703, train_loss=0.341, train_acc=0.739]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 109.51it/s][AEpoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.91it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.341, train_acc=0.739]
                                                              [AEpoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.69it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]           Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.73it/s, loss=0.368, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.73it/s, loss=0.328, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:06, 24.96it/s, loss=0.328, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.328, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.295, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:10<01:15, 28.54it/s, loss=0.295, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.32it/s, loss=0.295, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.32it/s, loss=0.261, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]Epoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.36it/s, loss=0.261, v_num=1, val_loss=0.476, val_acc=0.681, train_loss=0.336, train_acc=0.747]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 107.63it/s][AEpoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.78it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.336, train_acc=0.747] 
                                                              [AEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.56it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch    13: reducing learning rate of group 0 to 5.0000e-04.
Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]           Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:22, 38.55it/s, loss=0.39, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:22, 38.55it/s, loss=0.288, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:36<01:55, 27.35it/s, loss=0.288, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.09it/s, loss=0.288, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.09it/s, loss=0.302, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:06<01:12, 30.05it/s, loss=0.302, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.27it/s, loss=0.302, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.27it/s, loss=0.281, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]Epoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.33it/s, loss=0.281, v_num=1, val_loss=0.426, val_acc=0.696, train_loss=0.331, train_acc=0.754]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 110.35it/s][AEpoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.84it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.331, train_acc=0.754]
                                                              [AEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.62it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]           Epoch 14:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:   0%|          | 0/4166 [00:13<?, ?it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.79it/s, loss=0.274, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:25<01:21, 38.79it/s, loss=0.366, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:43<02:16, 23.13it/s, loss=0.366, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.366, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:51<00:55, 39.20it/s, loss=0.455, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:03<01:08, 31.63it/s, loss=0.455, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.28it/s, loss=0.455, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:16<00:29, 39.28it/s, loss=0.372, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]Epoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:26<00:03, 46.33it/s, loss=0.372, v_num=1, val_loss=0.408, val_acc=0.716, train_loss=0.315, train_acc=0.761]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:07<00:00, 110.55it/s][AEpoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:33<00:03, 42.85it/s, loss=0.285, v_num=1, val_loss=0.449, val_acc=0.728, train_loss=0.315, train_acc=0.761]
                                                              [AEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.62it/s, loss=0.285, v_num=1, val_loss=0.449, val_acc=0.728, train_loss=0.312, train_acc=0.765]Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:33<00:00, 44.47it/s, loss=0.285, v_num=1, val_loss=0.449, val_acc=0.728, train_loss=0.312, train_acc=0.765]
/home/alirachidi/classification_algorithm/trainers/cw/models/train8.py:72: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.train_losses)), self.train_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train8.py:75: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_losses)), self.val_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train8.py:78: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_accuracies)), self.val_accuracies)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
../cache/cw/train8/1

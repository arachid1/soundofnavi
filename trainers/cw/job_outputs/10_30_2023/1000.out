Tensorflow Version: 2.8.0
Num GPUs Available:  0
Collecting Variables...
All variables have been collected.
../cache/
cw
train1000
Description:  effnet: kfold, mel, no normalizing, 1 optimizer w adaptive lr, overlap threshold = 0.3,
-----------------------
- Loading Icbhi.
17 Icbhi audios have been loaded.
- Preparing Icbhi.
10 Icbhi groups of audio chunks (by filename or patients) have been prepared.
--- Samples are being split into training/val groups and de-grouped by patient ---
--- Icbhi training dataset went from 0 to 36 elements, with 22 none's, 12 crakles, 1 wheezes and 1 both ---
--- Icbhi Validation dataset contains 32 elements, with 17 none, 6 crackles, 4 wheezes and 5 both ---
Job id is 1.
[]
[LogicalDevice(name='/device:CPU:0', device_type='CPU')]
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 efficientnetb1 (Functional)  (None, 3, 16, 1280)      6575239   
                                                                 
 global_average_pooling2d (G  (None, 1280)             0         
 lobalAveragePooling2D)                                          
                                                                 
 dense (Dense)               (None, 100)               128100    
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_1 (Dense)             (None, 50)                5050      
                                                                 
 dropout_1 (Dropout)         (None, 50)                0         
                                                                 
 dense_2 (Dense)             (None, 2)                 102       
                                                                 
=================================================================
Total params: 6,708,491
Trainable params: 6,646,436
Non-trainable params: 62,055
_________________________________________________________________
weights before
[<tf.Variable 'kernel:0' shape=(80, 2) dtype=float32, numpy=
array([[3.682e-02, 1.919e+02],
       [3.682e-02, 9.594e+01],
       [4.909e-02, 1.919e+02],
       [6.136e-02, 1.919e+02],
       [7.363e-02, 1.919e+02],
       [8.590e-02, 9.594e+01],
       [9.817e-02, 9.594e+01],
       [9.817e-02, 9.594e+01],
       [1.104e-01, 9.594e+01],
       [1.227e-01, 9.594e+01],
       [1.350e-01, 9.594e+01],
       [1.473e-01, 9.594e+01],
       [1.595e-01, 9.594e+01],
       [1.841e-01, 9.594e+01],
       [1.963e-01, 9.594e+01],
       [2.086e-01, 9.594e+01],
       [2.209e-01, 1.919e+02],
       [2.332e-01, 9.594e+01],
       [2.454e-01, 9.594e+01],
       [2.700e-01, 9.594e+01],
       [2.823e-01, 9.594e+01],
       [2.945e-01, 9.594e+01],
       [3.191e-01, 9.594e+01],
       [3.313e-01, 9.594e+01],
       [3.559e-01, 6.396e+01],
       [3.682e-01, 9.594e+01],
       [3.927e-01, 6.396e+01],
       [4.172e-01, 9.594e+01],
       [4.295e-01, 6.396e+01],
       [4.541e-01, 6.396e+01],
       [4.786e-01, 6.396e+01],
       [5.031e-01, 6.396e+01],
       [5.277e-01, 6.396e+01],
       [5.522e-01, 6.396e+01],
       [5.768e-01, 6.396e+01],
       [6.013e-01, 6.396e+01],
       [6.259e-01, 6.396e+01],
       [6.504e-01, 6.396e+01],
       [6.750e-01, 4.797e+01],
       [7.118e-01, 4.797e+01],
       [7.363e-01, 4.797e+01],
       [7.731e-01, 4.797e+01],
       [7.977e-01, 4.797e+01],
       [8.345e-01, 4.797e+01],
       [8.713e-01, 4.797e+01],
       [8.958e-01, 4.797e+01],
       [9.327e-01, 4.797e+01],
       [9.695e-01, 3.838e+01],
       [1.006e+00, 3.838e+01],
       [1.055e+00, 3.838e+01],
       [1.092e+00, 3.838e+01],
       [1.129e+00, 3.838e+01],
       [1.178e+00, 3.198e+01],
       [1.215e+00, 3.198e+01],
       [1.264e+00, 3.838e+01],
       [1.313e+00, 3.198e+01],
       [1.362e+00, 3.198e+01],
       [1.411e+00, 3.198e+01],
       [1.460e+00, 2.741e+01],
       [1.509e+00, 2.741e+01],
       [1.559e+00, 3.198e+01],
       [1.620e+00, 2.741e+01],
       [1.681e+00, 2.741e+01],
       [1.730e+00, 2.399e+01],
       [1.792e+00, 2.399e+01],
       [1.865e+00, 2.399e+01],
       [1.927e+00, 2.399e+01],
       [1.988e+00, 2.399e+01],
       [2.062e+00, 2.132e+01],
       [2.135e+00, 2.132e+01],
       [2.197e+00, 1.919e+01],
       [2.283e+00, 1.919e+01],
       [2.356e+00, 2.132e+01],
       [2.430e+00, 1.919e+01],
       [2.516e+00, 1.919e+01],
       [2.602e+00, 1.744e+01],
       [2.688e+00, 1.744e+01],
       [2.773e+00, 1.599e+01],
       [2.872e+00, 1.744e+01],
       [2.970e+00, 1.599e+01]], dtype=float32)>, <tf.Variable 'leaf/learnable_pooling/kernel:0' shape=(1, 1, 80, 1) dtype=float32, numpy=
array([[[[0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4],
         [0.4]]]], dtype=float32)>, <tf.Variable 'leaf/PCEN/alpha:0' shape=(80,) dtype=float32, numpy=
array([0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96,
       0.96, 0.96, 0.96], dtype=float32)>, <tf.Variable 'leaf/PCEN/delta:0' shape=(80,) dtype=float32, numpy=
array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)>, <tf.Variable 'leaf/PCEN/root:0' shape=(80,) dtype=float32, numpy=
array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)>, <tf.Variable 'leaf/PCEN/EMA/smooth:0' shape=(80,) dtype=float32, numpy=
array([0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,
       0.04, 0.04, 0.04], dtype=float32)>]
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 efficientnetb1 (Functional)  (None, 3, 16, 1280)      6575239   
                                                                 
 global_average_pooling2d_1   (None, 1280)             0         
 (GlobalAveragePooling2D)                                        
                                                                 
 dense_3 (Dense)             (None, 100)               128100    
                                                                 
 dropout_2 (Dropout)         (None, 100)               0         
                                                                 
 dense_4 (Dense)             (None, 50)                5050      
                                                                 
 dropout_3 (Dropout)         (None, 50)                0         
                                                                 
 dense_5 (Dense)             (None, 2)                 102       
                                                                 
=================================================================
Total params: 6,708,491
Trainable params: 6,646,436
Non-trainable params: 62,055
_________________________________________________________________
/home/alirachidi/classification_algorithm/trainers/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py:310: RuntimeWarning: divide by zero encountered in true_divide
  return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))
Traceback (most recent call last):
  File "/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py", line 471, in <module>
    visualize(data, leaf_model9_model_efnet1, weights_path, epoch_number)
  File "/home/alirachidi/classification_algorithm/trainers/cw/models/train1000.py", line 222, in visualize
    teacher._load(weights_path, epoch_number)
  File "/home/alirachidi/classification_algorithm/trainers/modules/models/leaf_model9_model_efnet1.py", line 350, in _load
    self._frontend.load_weights(source + "_frontend_{}.h5".format(epoch))
  File "/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/keras/saving/hdf5_format.py", line 729, in load_weights_from_hdf5_group
    f'Layer count mismatch when loading weights from file. '
ValueError: Layer count mismatch when loading weights from file. Model expected 3 layers, found 4 saved layers.

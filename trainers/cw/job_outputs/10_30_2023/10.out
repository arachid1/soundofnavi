Tensorflow Version: 2.4.0
Num GPUs Available:  1
Collecting Variables...
All variables have been collected.
-----------------------
Job id is 1.
- Loading Perch.
3278 Perch audios have been loaded.
- Loading Icbhi.
725 Icbhi audios have been loaded.
- Loading Antwerp.
131 Antwerp audios have been loaded.
- Preparing Perch.
862 Perch groups of audio chunks (by filename or patients) have been prepared.
- Preparing Icbhi.
112 Icbhi groups of audio chunks (by filename or patients) have been prepared.
- Preparing Antwerp.
15 Antwerp groups of audio chunks (by filename or patients) have been prepared.
--- Samples are being split into training/val groups and de-grouped by patient ---
--- Perch training dataset went from 0 to 7947 elements, with 4692 none's, 122 crakles, 372 wheezes and 112 both ---
--- Perch Validation dataset contains 1887 elements, with 1102 none, 24 crackles, 108 wheezes and 24 both ---
--- Icbhi training dataset went from 0 to 4398 elements, with 1655 none's, 1436 crakles, 619 wheezes and 616 both ---
--- Icbhi Validation dataset contains 983 elements, with 498 none, 336 crackles, 72 wheezes and 60 both ---
--- Antwerp training dataset went from 0 to 1213 elements, with 217 none's, 32 crakles, 896 wheezes and 68 both ---
--- Antwerp Validation dataset contains 234 elements, with 46 none, 20 crackles, 10 wheezes and 158 both ---
tensor([0.5853], device='cuda:0')
cuda:0
tensor([0.6606], device='cuda:0')
STFT kernels created, time used = 0.0118 seconds
Parameter containing:
tensor([[ 0.0000e+00,  1.0410e+01,  2.0974e+01,  ...,  3.8633e+03,
          3.9311e+03,  4.0000e+03],
        [-1.5625e+01, -5.2153e+00,  5.3492e+00,  ...,  3.8476e+03,
          3.9155e+03,  3.9844e+03],
        [-3.1250e+01, -2.0840e+01, -1.0276e+01,  ...,  3.8320e+03,
          3.8999e+03,  3.9687e+03],
        ...,
        [-3.9688e+03, -3.9583e+03, -3.9478e+03,  ..., -1.0548e+02,
         -3.7621e+01,  3.1250e+01],
        [-3.9844e+03, -3.9740e+03, -3.9634e+03,  ..., -1.2111e+02,
         -5.3246e+01,  1.5625e+01],
        [-4.0000e+03, -3.9896e+03, -3.9790e+03,  ..., -1.3673e+02,
         -6.8871e+01, -2.4414e-04]], device='cuda:0', requires_grad=True)
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1000)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name          | Type                | Params
-------------------------------------------------------
0  | spec_layer    | STFT                | 0     
1  | mel_layer     | MelScaleBis         | 33.8 K
2  | depth_layer_1 | InvertedResidual_nn | 73.2 K
3  | AVGPOOL1      | AvgPool2d           | 0     
4  | BN1           | BatchNorm2d         | 256   
5  | DP1           | Dropout             | 0     
6  | depth_layer_3 | InvertedResidual_nn | 73.2 K
7  | AVGPOOL2      | AvgPool2d           | 0     
8  | BN2           | BatchNorm2d         | 256   
9  | DP2           | Dropout             | 0     
10 | classifier    | Linear              | 258   
-------------------------------------------------------
182 K     Trainable params
0         Non-trainable params
182 K     Total params
0.729     Total estimated model params size (MB)
tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]])
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/alirachidi/classification_algorithm/trainers/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Validation sanity check: 100%|██████████| 2/2 [00:01<00:00,  1.75it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/4166 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s] Epoch 0:  24%|██▍       | 1000/4166 [00:23<01:13, 43.08it/s]Epoch 0:  24%|██▍       | 1000/4166 [00:23<01:13, 43.08it/s, loss=0.41]Epoch 0:  24%|██▍       | 1000/4166 [00:39<02:06, 25.00it/s, loss=0.41]Epoch 0:  48%|████▊     | 2000/4166 [00:45<00:49, 43.61it/s, loss=0.41]Epoch 0:  48%|████▊     | 2000/4166 [00:45<00:49, 43.61it/s, loss=0.469]Epoch 0:  48%|████▊     | 2000/4166 [00:59<01:04, 33.34it/s, loss=0.469]Epoch 0:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.74it/s, loss=0.469]Epoch 0:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.74it/s, loss=0.378]Epoch 0:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.60it/s, loss=0.378]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 106.32it/s][AEpoch 0:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.16it/s, loss=0.358, val_loss=0.413, val_acc=0.689]
                                                              [AEpoch 0: 100%|██████████| 4166/4166 [01:24<00:00, 49.11it/s, loss=0.358, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.358, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]           Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.358, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.358, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  24%|██▍       | 1000/4166 [00:22<01:12, 43.55it/s, loss=0.358, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  24%|██▍       | 1000/4166 [00:22<01:12, 43.55it/s, loss=0.347, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  24%|██▍       | 1000/4166 [00:35<01:51, 28.45it/s, loss=0.347, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  48%|████▊     | 2000/4166 [00:45<00:49, 43.96it/s, loss=0.347, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  48%|████▊     | 2000/4166 [00:45<00:49, 43.96it/s, loss=0.449, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  48%|████▊     | 2000/4166 [01:05<01:10, 30.70it/s, loss=0.449, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  72%|███████▏  | 3000/4166 [01:08<00:26, 44.08it/s, loss=0.449, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  72%|███████▏  | 3000/4166 [01:08<00:26, 44.08it/s, loss=0.347, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]Epoch 1:  96%|█████████▌| 4000/4166 [01:16<00:03, 51.95it/s, loss=0.347, val_loss=0.413, val_acc=0.689, train_loss=0.421, train_acc=0.699]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 105.78it/s][AEpoch 1:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.43it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.421, train_acc=0.699]
                                                              [AEpoch 1: 100%|██████████| 4166/4166 [01:24<00:00, 49.40it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]           Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  24%|██▍       | 1000/4166 [00:23<01:13, 43.20it/s, loss=0.407, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  24%|██▍       | 1000/4166 [00:23<01:13, 43.20it/s, loss=0.348, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  24%|██▍       | 1000/4166 [00:40<02:09, 24.51it/s, loss=0.348, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  48%|████▊     | 2000/4166 [00:45<00:49, 43.55it/s, loss=0.348, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  48%|████▊     | 2000/4166 [00:45<00:49, 43.55it/s, loss=0.424, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  48%|████▊     | 2000/4166 [01:00<01:05, 32.89it/s, loss=0.424, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.81it/s, loss=0.424, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.81it/s, loss=0.456, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]Epoch 2:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.64it/s, loss=0.456, val_loss=0.456, val_acc=0.676, train_loss=0.399, train_acc=0.713]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 104.12it/s][AEpoch 2:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.11it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.399, train_acc=0.713]
                                                              [AEpoch 2: 100%|██████████| 4166/4166 [01:24<00:00, 49.06it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]           Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  24%|██▍       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.334, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  24%|██▍       | 1000/4166 [00:23<01:13, 43.29it/s, loss=0.322, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  24%|██▍       | 1000/4166 [00:35<01:53, 27.87it/s, loss=0.322, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  48%|████▊     | 2000/4166 [00:45<00:49, 43.81it/s, loss=0.322, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  48%|████▊     | 2000/4166 [00:45<00:49, 43.81it/s, loss=0.389, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  48%|████▊     | 2000/4166 [00:55<01:00, 35.79it/s, loss=0.389, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  72%|███████▏  | 3000/4166 [01:08<00:26, 44.01it/s, loss=0.389, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  72%|███████▏  | 3000/4166 [01:08<00:26, 44.01it/s, loss=0.463, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]Epoch 3:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.88it/s, loss=0.463, val_loss=0.485, val_acc=0.684, train_loss=0.393, train_acc=0.717]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 104.71it/s][AEpoch 3:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.33it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.393, train_acc=0.717] 
                                                              [AEpoch 3: 100%|██████████| 4166/4166 [01:24<00:00, 49.30it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]           Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:   0%|          | 0/4166 [00:11<?, ?it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  24%|██▍       | 1000/4166 [00:23<01:14, 42.66it/s, loss=0.33, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  24%|██▍       | 1000/4166 [00:23<01:14, 42.66it/s, loss=0.39, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  24%|██▍       | 1000/4166 [00:41<02:10, 24.18it/s, loss=0.39, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  48%|████▊     | 2000/4166 [00:46<00:49, 43.39it/s, loss=0.39, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  48%|████▊     | 2000/4166 [00:46<00:49, 43.39it/s, loss=0.369, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  48%|████▊     | 2000/4166 [01:01<01:06, 32.60it/s, loss=0.369, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.73it/s, loss=0.369, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.72it/s, loss=0.398, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]Epoch 4:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.59it/s, loss=0.398, val_loss=0.473, val_acc=0.672, train_loss=0.385, train_acc=0.721]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 104.88it/s][AEpoch 4:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.09it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.385, train_acc=0.721]
                                                              [AEpoch 4: 100%|██████████| 4166/4166 [01:24<00:00, 49.05it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch     5: reducing learning rate of group 0 to 5.0000e-04.
Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]           Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  24%|██▍       | 1000/4166 [00:23<01:13, 43.12it/s, loss=0.334, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  24%|██▍       | 1000/4166 [00:23<01:13, 43.12it/s, loss=0.456, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  24%|██▍       | 1000/4166 [00:36<01:55, 27.47it/s, loss=0.456, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  48%|████▊     | 2000/4166 [00:45<00:49, 43.67it/s, loss=0.456, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  48%|████▊     | 2000/4166 [00:45<00:49, 43.67it/s, loss=0.379, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  48%|████▊     | 2000/4166 [00:56<01:01, 35.46it/s, loss=0.379, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.81it/s, loss=0.379, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.81it/s, loss=0.349, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]Epoch 5:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.65it/s, loss=0.349, val_loss=0.416, val_acc=0.704, train_loss=0.378, train_acc=0.724]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 104.22it/s][AEpoch 5:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.12it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.378, train_acc=0.724]
                                                              [AEpoch 5: 100%|██████████| 4166/4166 [01:24<00:00, 49.08it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]           Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:   0%|          | 0/4166 [00:11<?, ?it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  24%|██▍       | 1000/4166 [00:23<01:13, 43.07it/s, loss=0.391, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  24%|██▍       | 1000/4166 [00:23<01:13, 43.07it/s, loss=0.333, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  24%|██▍       | 1000/4166 [00:41<02:11, 24.10it/s, loss=0.333, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  48%|████▊     | 2000/4166 [00:45<00:49, 43.51it/s, loss=0.333, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  48%|████▊     | 2000/4166 [00:45<00:49, 43.51it/s, loss=0.294, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  48%|████▊     | 2000/4166 [01:01<01:06, 32.52it/s, loss=0.294, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.75it/s, loss=0.294, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.75it/s, loss=0.301, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]Epoch 6:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.55it/s, loss=0.301, val_loss=0.420, val_acc=0.698, train_loss=0.359, train_acc=0.732]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 106.41it/s][AEpoch 6:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.12it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.359, train_acc=0.732]
                                                              [AEpoch 6: 100%|██████████| 4166/4166 [01:24<00:00, 49.08it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]           Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  24%|██▍       | 1000/4166 [00:23<01:13, 43.14it/s, loss=0.384, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  24%|██▍       | 1000/4166 [00:23<01:13, 43.14it/s, loss=0.324, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  24%|██▍       | 1000/4166 [00:36<01:55, 27.33it/s, loss=0.324, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  48%|████▊     | 2000/4166 [00:45<00:49, 43.71it/s, loss=0.324, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  48%|████▊     | 2000/4166 [00:45<00:49, 43.71it/s, loss=0.379, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  48%|████▊     | 2000/4166 [00:56<01:01, 35.34it/s, loss=0.379, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.80it/s, loss=0.379, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.80it/s, loss=0.346, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]Epoch 7:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.63it/s, loss=0.346, val_loss=0.430, val_acc=0.698, train_loss=0.350, train_acc=0.734]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 106.01it/s][AEpoch 7:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.17it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.350, train_acc=0.734] 
                                                              [AEpoch 7: 100%|██████████| 4166/4166 [01:24<00:00, 49.13it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]           Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:   0%|          | 0/4166 [00:11<?, ?it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  24%|██▍       | 1000/4166 [00:23<01:13, 43.23it/s, loss=0.41, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  24%|██▍       | 1000/4166 [00:23<01:13, 43.23it/s, loss=0.441, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  24%|██▍       | 1000/4166 [00:41<02:12, 23.94it/s, loss=0.441, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  48%|████▊     | 2000/4166 [00:45<00:49, 43.66it/s, loss=0.441, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  48%|████▊     | 2000/4166 [00:45<00:49, 43.66it/s, loss=0.389, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  48%|████▊     | 2000/4166 [01:01<01:06, 32.37it/s, loss=0.389, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.82it/s, loss=0.389, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]Epoch 8:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.82it/s, loss=0.36, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743] Epoch 8:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.68it/s, loss=0.36, val_loss=0.440, val_acc=0.700, train_loss=0.344, train_acc=0.743]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 102.10it/s][AEpoch 8:  96%|█████████▌| 4000/4166 [01:25<00:03, 47.06it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.344, train_acc=0.743]
                                                              [AEpoch 8: 100%|██████████| 4166/4166 [01:25<00:00, 49.01it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch     9: reducing learning rate of group 0 to 2.5000e-04.
Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]           Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:   0%|          | 0/4166 [00:16<?, ?it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  24%|██▍       | 1000/4166 [00:23<01:13, 43.13it/s, loss=0.342, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  24%|██▍       | 1000/4166 [00:23<01:13, 43.13it/s, loss=0.247, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  24%|██▍       | 1000/4166 [00:36<01:56, 27.20it/s, loss=0.247, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  48%|████▊     | 2000/4166 [00:45<00:49, 43.81it/s, loss=0.247, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  48%|████▊     | 2000/4166 [00:45<00:49, 43.81it/s, loss=0.328, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  48%|████▊     | 2000/4166 [00:56<01:01, 35.23it/s, loss=0.328, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.97it/s, loss=0.328, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.97it/s, loss=0.311, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]Epoch 9:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.86it/s, loss=0.311, val_loss=0.417, val_acc=0.704, train_loss=0.339, train_acc=0.745]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 105.78it/s][AEpoch 9:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.36it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.339, train_acc=0.745]
                                                              [AEpoch 9: 100%|██████████| 4166/4166 [01:24<00:00, 49.32it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]           Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:   0%|          | 0/4166 [00:12<?, ?it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  24%|██▍       | 1000/4166 [00:23<01:13, 43.16it/s, loss=0.313, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  24%|██▍       | 1000/4166 [00:23<01:13, 43.16it/s, loss=0.303, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  24%|██▍       | 1000/4166 [00:42<02:13, 23.65it/s, loss=0.303, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  48%|████▊     | 2000/4166 [00:45<00:49, 43.64it/s, loss=0.303, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  48%|████▊     | 2000/4166 [00:45<00:49, 43.64it/s, loss=0.337, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  48%|████▊     | 2000/4166 [01:02<01:07, 32.11it/s, loss=0.337, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.76it/s, loss=0.337, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.76it/s, loss=0.427, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]Epoch 10:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.53it/s, loss=0.427, val_loss=0.424, val_acc=0.704, train_loss=0.328, train_acc=0.754]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 105.21it/s][AEpoch 10:  96%|█████████▌| 4000/4166 [01:25<00:03, 47.06it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.328, train_acc=0.754]
                                                              [AEpoch 10: 100%|██████████| 4166/4166 [01:25<00:00, 49.01it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]           Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:   0%|          | 0/4166 [00:17<?, ?it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  24%|██▍       | 1000/4166 [00:23<01:13, 43.01it/s, loss=0.342, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  24%|██▍       | 1000/4166 [00:23<01:13, 43.01it/s, loss=0.322, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  24%|██▍       | 1000/4166 [00:37<01:57, 26.83it/s, loss=0.322, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  48%|████▊     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.322, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  48%|████▊     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.306, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  48%|████▊     | 2000/4166 [00:57<01:02, 34.92it/s, loss=0.306, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.73it/s, loss=0.306, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.73it/s, loss=0.329, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]Epoch 11:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.59it/s, loss=0.329, val_loss=0.406, val_acc=0.722, train_loss=0.323, train_acc=0.757]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 104.74it/s][AEpoch 11:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.09it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.323, train_acc=0.757]
                                                              [AEpoch 11: 100%|██████████| 4166/4166 [01:24<00:00, 49.05it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]           Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:   0%|          | 0/4166 [00:12<?, ?it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  24%|██▍       | 1000/4166 [00:23<01:13, 42.96it/s, loss=0.346, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  24%|██▍       | 1000/4166 [00:23<01:13, 42.96it/s, loss=0.281, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  24%|██▍       | 1000/4166 [00:42<02:13, 23.63it/s, loss=0.281, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  48%|████▊     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.281, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  48%|████▊     | 2000/4166 [00:45<00:49, 43.49it/s, loss=0.318, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  48%|████▊     | 2000/4166 [01:02<01:07, 32.10it/s, loss=0.318, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.74it/s, loss=0.318, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.74it/s, loss=0.273, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]Epoch 12:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.61it/s, loss=0.273, val_loss=0.435, val_acc=0.713, train_loss=0.319, train_acc=0.762]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 106.33it/s][AEpoch 12:  96%|█████████▌| 4000/4166 [01:24<00:03, 47.16it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.319, train_acc=0.762] 
                                                              [AEpoch 12: 100%|██████████| 4166/4166 [01:24<00:00, 49.12it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]           Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:   0%|          | 0/4166 [00:17<?, ?it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  24%|██▍       | 1000/4166 [00:23<01:13, 42.94it/s, loss=0.21, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  24%|██▍       | 1000/4166 [00:23<01:13, 42.94it/s, loss=0.275, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  24%|██▍       | 1000/4166 [00:37<01:58, 26.68it/s, loss=0.275, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  48%|████▊     | 2000/4166 [00:45<00:49, 43.54it/s, loss=0.275, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  48%|████▊     | 2000/4166 [00:45<00:49, 43.54it/s, loss=0.28, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759] Epoch 13:  48%|████▊     | 2000/4166 [00:57<01:02, 34.79it/s, loss=0.28, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.71it/s, loss=0.28, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.71it/s, loss=0.296, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]Epoch 13:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.49it/s, loss=0.296, val_loss=0.462, val_acc=0.707, train_loss=0.318, train_acc=0.759]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 105.93it/s][AEpoch 13:  96%|█████████▌| 4000/4166 [01:25<00:03, 47.05it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.318, train_acc=0.759]
                                                              [AEpoch 13: 100%|██████████| 4166/4166 [01:25<00:00, 49.00it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]           Epoch 14:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:   0%|          | 0/4166 [00:12<?, ?it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  24%|██▍       | 1000/4166 [00:23<01:13, 43.00it/s, loss=0.432, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  24%|██▍       | 1000/4166 [00:23<01:13, 43.00it/s, loss=0.257, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  24%|██▍       | 1000/4166 [00:42<02:14, 23.56it/s, loss=0.257, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  48%|████▊     | 2000/4166 [00:45<00:49, 43.59it/s, loss=0.257, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  48%|████▊     | 2000/4166 [00:45<00:49, 43.59it/s, loss=0.276, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  48%|████▊     | 2000/4166 [01:02<01:07, 32.02it/s, loss=0.276, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.71it/s, loss=0.276, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  72%|███████▏  | 3000/4166 [01:08<00:26, 43.71it/s, loss=0.338, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]Epoch 14:  96%|█████████▌| 4000/4166 [01:17<00:03, 51.52it/s, loss=0.338, val_loss=0.398, val_acc=0.716, train_loss=0.313, train_acc=0.766]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|██████████| 776/776 [00:07<00:00, 102.11it/s][AEpoch 14:  96%|█████████▌| 4000/4166 [01:25<00:03, 46.92it/s, loss=0.299, val_loss=0.410, val_acc=0.704, train_loss=0.313, train_acc=0.766]
                                                              [AEpoch 14: 100%|██████████| 4166/4166 [01:25<00:00, 48.87it/s, loss=0.299, val_loss=0.410, val_acc=0.704, train_loss=0.310, train_acc=0.765]Epoch 14: 100%|██████████| 4166/4166 [01:25<00:00, 48.68it/s, loss=0.299, val_loss=0.410, val_acc=0.704, train_loss=0.310, train_acc=0.765]
/home/alirachidi/classification_algorithm/trainers/cw/models/train10.py:72: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.train_losses)), self.train_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train10.py:75: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_losses)), self.val_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train10.py:78: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_accuracies)), self.val_accuracies)
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
../cache/cw/train10/1

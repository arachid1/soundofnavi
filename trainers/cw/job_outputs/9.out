Tensorflow Version: 2.4.0
Num GPUs Available:  1
Collecting Variables...
All variables have been collected.
-----------------------
Job id is 1.
- Loading Perch.
3278 Perch audios have been loaded.
- Loading Icbhi.
725 Icbhi audios have been loaded.
- Loading Antwerp.
131 Antwerp audios have been loaded.
- Preparing Perch.
862 Perch groups of audio chunks (by filename or patients) have been prepared.
- Preparing Icbhi.
112 Icbhi groups of audio chunks (by filename or patients) have been prepared.
- Preparing Antwerp.
15 Antwerp groups of audio chunks (by filename or patients) have been prepared.
--- Samples are being split into training/val groups and de-grouped by patient ---
--- Perch training dataset went from 0 to 7947 elements, with 4692 none's, 122 crakles, 372 wheezes and 112 both ---
--- Perch Validation dataset contains 1887 elements, with 1102 none, 24 crackles, 108 wheezes and 24 both ---
--- Icbhi training dataset went from 0 to 4398 elements, with 1655 none's, 1436 crakles, 619 wheezes and 616 both ---
--- Icbhi Validation dataset contains 983 elements, with 498 none, 336 crackles, 72 wheezes and 60 both ---
--- Antwerp training dataset went from 0 to 1213 elements, with 217 none's, 32 crakles, 896 wheezes and 68 both ---
--- Antwerp Validation dataset contains 234 elements, with 46 none, 20 crackles, 10 wheezes and 158 both ---
tensor([0.3974], device='cuda:0')
cuda:0
tensor([0.1177], device='cuda:0')
STFT kernels created, time used = 0.0121 seconds
Parameter containing:
tensor([[ 0.0000e+00,  1.0410e+01,  2.0974e+01,  ...,  3.8633e+03,
          3.9311e+03,  4.0000e+03],
        [-1.5625e+01, -5.2153e+00,  5.3492e+00,  ...,  3.8476e+03,
          3.9155e+03,  3.9844e+03],
        [-3.1250e+01, -2.0840e+01, -1.0276e+01,  ...,  3.8320e+03,
          3.8999e+03,  3.9687e+03],
        ...,
        [-3.9688e+03, -3.9583e+03, -3.9478e+03,  ..., -1.0548e+02,
         -3.7621e+01,  3.1250e+01],
        [-3.9844e+03, -3.9740e+03, -3.9634e+03,  ..., -1.2111e+02,
         -5.3246e+01,  1.5625e+01],
        [-4.0000e+03, -3.9896e+03, -3.9790e+03,  ..., -1.3673e+02,
         -6.8871e+01, -2.4414e-04]], device='cuda:0', requires_grad=True)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
/home/alirachidi/anaconda3/envs/LungSoundClass/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1000)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name          | Type                | Params
-------------------------------------------------------
0  | spec_layer    | STFT                | 0     
1  | mel_layer     | MelScaleBis         | 33.8 K
2  | depth_layer_1 | InvertedResidual_nn | 73.2 K
3  | AVGPOOL1      | AvgPool2d           | 0     
4  | BN1           | BatchNorm2d         | 256   
5  | DP1           | Dropout             | 0     
6  | depth_layer_3 | InvertedResidual_nn | 73.2 K
7  | AVGPOOL2      | AvgPool2d           | 0     
8  | BN2           | BatchNorm2d         | 256   
9  | DP2           | Dropout             | 0     
10 | classifier    | Linear              | 258   
-------------------------------------------------------
185 K     Trainable params
0         Non-trainable params
185 K     Total params
0.742     Total estimated model params size (MB)
tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]])
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.53it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/4166 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s] Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.50it/s]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.50it/s, loss=0.4, v_num=1]Epoch 0:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:39<02:06, 25.00it/s, loss=0.4, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.15it/s, loss=0.4, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.15it/s, loss=0.394, v_num=1]Epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:59<01:04, 33.34it/s, loss=0.394, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.39it/s, loss=0.394, v_num=1]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.39it/s, loss=0.341, v_num=1]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.24it/s, loss=0.341, v_num=1]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 125.37it/s][AEpoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.42it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667]
                                                              [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.64it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 0:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]           Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.53it/s, loss=0.417, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.53it/s, loss=0.415, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:51, 28.49it/s, loss=0.415, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.18it/s, loss=0.415, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.18it/s, loss=0.371, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<00:59, 36.30it/s, loss=0.371, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.371, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.334, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]Epoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.31it/s, loss=0.334, v_num=1, val_loss=0.490, val_acc=0.667, train_loss=0.419, train_acc=0.696]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 123.13it/s][AEpoch 1:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.40it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.419, train_acc=0.696]
                                                              [AEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.62it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 1:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]           Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:04, 48.75it/s, loss=0.443, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:04, 48.75it/s, loss=0.441, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:07, 24.88it/s, loss=0.441, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.27it/s, loss=0.441, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.27it/s, loss=0.445, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.23it/s, loss=0.445, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.445, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.338, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]Epoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.34it/s, loss=0.338, v_num=1, val_loss=0.491, val_acc=0.698, train_loss=0.398, train_acc=0.713]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 124.48it/s][AEpoch 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.48it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.398, train_acc=0.713]
                                                              [AEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.70it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 2:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]           Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.47it/s, loss=0.374, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.47it/s, loss=0.395, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.26it/s, loss=0.395, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.27it/s, loss=0.395, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.27it/s, loss=0.377, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<00:59, 36.11it/s, loss=0.377, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.377, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.371, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]Epoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.31it/s, loss=0.371, v_num=1, val_loss=0.424, val_acc=0.691, train_loss=0.391, train_acc=0.716]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 124.64it/s][AEpoch 3:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.46it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.391, train_acc=0.716] 
                                                              [AEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.67it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 3:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]           Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.70it/s, loss=0.36, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.70it/s, loss=0.338, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:30<01:36, 32.75it/s, loss=0.338, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.28it/s, loss=0.338, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.28it/s, loss=0.29, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719] Epoch 4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.04it/s, loss=0.29, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.29, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.404, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]Epoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.31it/s, loss=0.404, v_num=1, val_loss=0.431, val_acc=0.701, train_loss=0.378, train_acc=0.719]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 125.40it/s][AEpoch 4:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.48it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.378, train_acc=0.719]
                                                              [AEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.70it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 4:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]           Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.23it/s, loss=0.357, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.22it/s, loss=0.287, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:53, 27.99it/s, loss=0.287, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 48.87it/s, loss=0.287, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 48.87it/s, loss=0.433, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<01:00, 35.89it/s, loss=0.433, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.19it/s, loss=0.433, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.19it/s, loss=0.495, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]Epoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.06it/s, loss=0.495, v_num=1, val_loss=0.434, val_acc=0.711, train_loss=0.371, train_acc=0.721]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 124.28it/s][AEpoch 5:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:15<00:03, 53.23it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.371, train_acc=0.721]
                                                              [AEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.44it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 5:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]           Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.41it/s, loss=0.331, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.41it/s, loss=0.349, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:08, 24.65it/s, loss=0.349, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.10it/s, loss=0.349, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.10it/s, loss=0.346, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.02it/s, loss=0.346, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.31it/s, loss=0.346, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.31it/s, loss=0.292, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]Epoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.14it/s, loss=0.292, v_num=1, val_loss=0.462, val_acc=0.690, train_loss=0.362, train_acc=0.723]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 124.14it/s][AEpoch 6:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:15<00:03, 53.29it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.362, train_acc=0.723]
                                                              [AEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.51it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch     7: reducing learning rate of group 0 to 5.0000e-04.
Epoch 6:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]           Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.49it/s, loss=0.332, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.49it/s, loss=0.36, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730] Epoch 7:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.17it/s, loss=0.36, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.14it/s, loss=0.36, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.14it/s, loss=0.339, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<01:00, 36.03it/s, loss=0.339, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.37it/s, loss=0.339, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.37it/s, loss=0.359, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]Epoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.23it/s, loss=0.359, v_num=1, val_loss=0.459, val_acc=0.711, train_loss=0.355, train_acc=0.730]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 123.33it/s][AEpoch 7:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.34it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.355, train_acc=0.730]
                                                              [AEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.55it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 7:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]           Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.56it/s, loss=0.271, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.56it/s, loss=0.307, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:08, 24.68it/s, loss=0.307, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.18it/s, loss=0.307, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.18it/s, loss=0.296, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.05it/s, loss=0.296, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.31it/s, loss=0.296, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.31it/s, loss=0.333, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]Epoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.14it/s, loss=0.333, v_num=1, val_loss=0.432, val_acc=0.688, train_loss=0.339, train_acc=0.742]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 125.21it/s][AEpoch 8:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:15<00:03, 53.33it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.339, train_acc=0.742]
                                                              [AEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.54it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 8:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]           Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.40it/s, loss=0.503, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.39it/s, loss=0.304, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.17it/s, loss=0.304, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 48.98it/s, loss=0.304, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 48.98it/s, loss=0.322, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<01:00, 36.04it/s, loss=0.322, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.29it/s, loss=0.322, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.29it/s, loss=0.221, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]Epoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.10it/s, loss=0.221, v_num=1, val_loss=0.422, val_acc=0.700, train_loss=0.334, train_acc=0.740]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 123.80it/s][AEpoch 9:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:15<00:03, 53.25it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.334, train_acc=0.740]
                                                              [AEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.46it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 9:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]           Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.44it/s, loss=0.308, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.44it/s, loss=0.338, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:07, 24.76it/s, loss=0.338, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.11it/s, loss=0.338, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.11it/s, loss=0.443, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.12it/s, loss=0.443, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.43it/s, loss=0.443, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.43it/s, loss=0.372, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]Epoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.25it/s, loss=0.372, v_num=1, val_loss=0.443, val_acc=0.707, train_loss=0.329, train_acc=0.748]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 123.23it/s][AEpoch 10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.35it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.329, train_acc=0.748]
                                                              [AEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.57it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 10:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]           Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.41it/s, loss=0.326, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.41it/s, loss=0.271, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.26it/s, loss=0.271, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.21it/s, loss=0.271, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.21it/s, loss=0.235, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<00:59, 36.11it/s, loss=0.235, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.235, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.45it/s, loss=0.361, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]Epoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.28it/s, loss=0.361, v_num=1, val_loss=0.462, val_acc=0.711, train_loss=0.325, train_acc=0.748]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 124.09it/s][AEpoch 11:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.41it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.325, train_acc=0.748]
                                                              [AEpoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.63it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 11:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]           Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.52it/s, loss=0.362, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.52it/s, loss=0.372, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:40<02:08, 24.67it/s, loss=0.372, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.22it/s, loss=0.372, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.22it/s, loss=0.258, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [01:00<01:05, 33.04it/s, loss=0.258, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.39it/s, loss=0.258, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.39it/s, loss=0.251, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]Epoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.23it/s, loss=0.251, v_num=1, val_loss=0.454, val_acc=0.712, train_loss=0.323, train_acc=0.751]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 126.03it/s][AEpoch 12:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.44it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.323, train_acc=0.751]
                                                              [AEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.66it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch    13: reducing learning rate of group 0 to 2.5000e-04.
Epoch 12:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]           Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:   0%|          | 0/4166 [00:15<?, ?it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.55it/s, loss=0.247, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.55it/s, loss=0.286, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:35<01:52, 28.04it/s, loss=0.286, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:43, 49.23it/s, loss=0.286, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.23it/s, loss=0.227, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:55<01:00, 35.93it/s, loss=0.227, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.227, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.46it/s, loss=0.327, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]Epoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.32it/s, loss=0.327, v_num=1, val_loss=0.458, val_acc=0.699, train_loss=0.319, train_acc=0.753]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 125.14it/s][AEpoch 13:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:14<00:03, 53.49it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.319, train_acc=0.753]
                                                              [AEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:14<00:00, 55.70it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 13:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]           Epoch 14:   0%|          | 0/4166 [00:00<?, ?it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:   0%|          | 0/4166 [00:10<?, ?it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.60it/s, loss=0.291, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:20<01:05, 48.60it/s, loss=0.29, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757] Epoch 14:  24%|â–ˆâ–ˆâ–       | 1000/4166 [00:30<01:37, 32.40it/s, loss=0.29, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.15it/s, loss=0.29, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:40<00:44, 49.15it/s, loss=0.311, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2000/4166 [00:50<00:55, 39.32it/s, loss=0.311, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.35it/s, loss=0.311, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3000/4166 [01:00<00:23, 49.35it/s, loss=0.333, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]Epoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:08<00:02, 58.18it/s, loss=0.333, v_num=1, val_loss=0.436, val_acc=0.731, train_loss=0.313, train_acc=0.757]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/776 [00:00<?, ?it/s][A
Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:06<00:00, 123.92it/s][AEpoch 14:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4000/4166 [01:15<00:03, 53.32it/s, loss=0.273, v_num=1, val_loss=0.489, val_acc=0.716, train_loss=0.313, train_acc=0.757]
                                                              [AEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.54it/s, loss=0.273, v_num=1, val_loss=0.489, val_acc=0.716, train_loss=0.309, train_acc=0.764]Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4166/4166 [01:15<00:00, 55.30it/s, loss=0.273, v_num=1, val_loss=0.489, val_acc=0.716, train_loss=0.309, train_acc=0.764]
/home/alirachidi/classification_algorithm/trainers/cw/models/train9.py:72: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.train_losses)), self.train_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train9.py:75: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_losses)), self.val_losses)
/home/alirachidi/classification_algorithm/trainers/cw/models/train9.py:78: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  plt.plot(torch.range(1, len(self.val_accuracies)), self.val_accuracies)
main/models/conv/modules/main/global_helpers.py:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
../cache/cw/train9/1
